A Conceptual Security Framework
for Cloud Computing Issues
Shadi A. Aljawarneh, Jordan University of Science and Technology, Irbid, Jordan
Muneer Bani Yassein, Jordan University of Science and Technology, Irbid, Jordan
ABSTRACT
In this article, perspectives from Cloud computing practitioners are shown in order to address clients
concerns and bring about awareness of the measures that put in place to ensure software security of
the client services running in the Cloud. In addition, the authors have investigated the impacts of a
number of the existing approaches and techniques to put a systematic survey of the current software
security issues in the Cloud environment. Based on such perspectives and survey, a generic framework
conceptually is designed to outline the possible current solutions of software security issues in
the Cloud and to present a preferred software security approach to investigate the Cloud research
community. As a potential enhancement on the proposed Cloud software security framework, the
concepts of fuzzy systems might be used to solve a large numbers of issues in the Cloud security on
different framework levels.
Keywords
Availability, Cloud Computing, Encryption, Fuzzy Systems, PAAS, SAAS, Software Security
1. INTRODUCTION
Cloud computing is a new concept in the era of technology. This concept adds new paradigms,
techniques and approaches to computing science. In Cloud, software and its data are created and
maintained virtually for the users and only accessible via a particular Cloud’s software, platform or
infrastructure (Aljawarneh, 2011). Before 2005, clients imagined renting resources, information and
software in order to operate, run and enhance their devices and programs. Currently, it is possible to
rent whatever resources you like so that this dream is now realized. In general, Cloud has four basic
characteristics:
1. Scalability: Cloud opts to use scalable architecture. Scalability means that hardware units are
added to bring more resources to the Cloud system (David, et al., 2015). However, this feature is
in trade-off with the software security. Therefore, scalability might ease to depict the Cloud and
it might increase criminals who would access the Cloud storage and Datacenters illegitimately
(Aljawarneh, 2011). Vaquero et al (Vaquero, et al., 2012) aimed to make the reader’s acquaintance
with this problem in distributed systems: user-oriented service-level scalability. Scalability issues
are analysed from the Infrastructure as a Service (IaaS) and the Platform as a Service (PaaS)
point of view, as they deal with different functions and abstraction levels (Vaquero, et al., 2012).
2. Availability: The services, platform and data are accessible at any time and place. Cloud exposes
potentially to greater software security threats, principally when the Cloud is based on the Internet
rather than an organization’s own platform (David, et al., 2015).
3. Automatic Backup: Day after day, a lot of manufacturers of electronic devices rely on the model
of Cloud computing and they are progressively more including this paradigm in their products
12
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
13
since it brings the characteristics of communication and automatic backup of the information
(Sessions, 2009).
4. Adding value and additional services to the user such as the ability to synchronise among friends
on social networking sites such as Facebook and friends on phones registered the same names
in the Palm phones (Aljawarneh, 2011).
Currently, academic world requires sharing, distributing, integrating and changing information,
linking applications and other resources within and among organizations (Wang, Zhang, & Cao,
2009). Due to openness, virtualization and distribution interconnection, software security becomes
a crucial challenge in order to ensure the integrity, confidentially and authenticity of digitized data
in Clouds (Aljawarneh, et al., 2010; Aljawarneh, et al., 2015).
In this paper, we have attempted to put the readers in the current state of software security
issues and levels in Cloud by presenting a generic framework that might assist in the protection of
their Cloud services and Datacenters. This paper provides a survey of software security tools and
techniques in the area of Cloud Computing. It analyses the major vendors solutions and practitioners
approaches, and then provides a general layered framework aimed at providing organizations with a
roadmap of the different perspectives from which software security issues in Cloud-based systems
can be faced. Such paper contribution plays an unquestionable central role in the adoption of Cloudbased solutions by organizations.
Software security is the main issue that might be faced the practitioners of Cloud applications
and systems. The owners of data might be concerned because the data and coupled with software
are not under their control but rather possessed by the Cloud. In addition, the data owner may not be
aware of where the data is geographically located at any particular time. So our research statement
in this study is to question how to secure the data contained in the Cloud (Aljawarneh, et al., 2015).
The rest of the paper is organized as follows. Section 2 states six reasons of increasing client’s
suspicions during the use of Cloud services and describes the current Cloud software security tools.
Section 3 describes the scenarios of the Cloud threats. In Section 4, we have conceptually presented
a generic framework consisting of components and levels in the Clouds. Thus we have reviewed the
existing solutions and discussed a number of practitioners’ perspectives correlated to the client’s
suspicions against using Cloud software security. A case study about the health software security has
been discussed in Section 5. Finally, we have drawn the conclusions and future work.
2. REASONS BEHIND CLOUD’S CLIENTS CONCERNS
This section describes a number of common reasons that led to raise the concerns among the clients
who use Cloud services and applications. The frequent reasons are as follows:
1. Some clients question about this: what happens if someone (such as manager, owner, maintainer
and others) halt organization’s servers for work or they faced foremost problems preventing
them from working? But the legitimacy is that regardless of the capacity and capabilities of
the organization that manages these servers, the potential collapse of the system is taken place
in everywhere and at any moment, and then this meltdown happens (Sessions, 2009). Thus,
the second question, could the Cloud computing fail? The answer of this question is outside of
the scope of this paper. This answer involves more systematic studies from different views and
perspectives.
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
14
2. Reputable organizations attempted to mitigate client concerns by confirming that the Cloud model
is secure, the Cloud services are protected, the information in Datacenters and hosted servers are
encrypted and the communication channel between the client and the Cloud resources is secure
and then it is protected from any sort of attack. However, some criminals claimed that the Cloud
resources are penetrated much more easily than the non-Cloud environment (Aljawarneh, 2011).
Sony company claimed that the level of encryption is not strong enough (Armerding, 2012).
3. Should the Cloud software security threats and vulnerabilities be predictable? It would be effective,
but often clients and software security practitioners cannot predict what the next vulnerability
will be. Once it is possible to predict the software security vulnerabilities, the practitioners can
control and prevent the threats.
4. Due to a lack of control over Cloud services, platform and/or infrastructure, academics and
practitioners stated that software security is a major challenge in the Cloud. In Cloud computing,
the data will be virtualized across different host machines and accessed on the Web (Yan, et
al., 2015; Wang, et al., 2015). From business point of view, the Cloud provides a channel to the
service or platform in which it could operate (David, et al., 2015). Arthur (Arthur, 2010) renamed
the Cloud computing as a ‘Careless Computing’ because the Cloud clients will not control their
own data and software and then there is no monitoring over the Cloud providers and subsequently
the data owner and maintainer may not recognize where data is geographically located at any
particular time.
However, several organizations have adopted and used Cloud applications and services including
Microsoft Azure Services Platform, Web Services, Google and open source Cloud systems such as
Sun Open Cloud Platform for academics, clients and administrative purposes (David, et al., 2015).
Yet, some organizations have not realized the substantial software security issues of Cloud. Some of
these organizations adopted some readily available software security and protection tools to secure
their systems, services and platforms.
Today, Amazon uses Cloud platform for introducing a number of web services for clients. Amazon
constructed a platform called Amazon Web Services (AWS) in order to secure the access for web
services (Aljawarneh, 2011). The AWS presented a protection level to face the traditional software
security issues in the Cloud (Rimal, 2009). In the meanwhile, physical access to AWS Datacenters
is limited controlled since the data owner may be aware of where the data is geographically located
at any particular time. Authorised staff has to log-in in two authentication phases with restricted
number of times for accessing AWS and AWS Datacenters at maximum (Rimal, 2009). Note that
Amazon only offers restricted Datacenter access and information to people who have an officially
authorized business need for these privileges. If the business need for these privileges is revoked,
then the access is stopped, even though if employees continue to be an employee in Amazon or AWS
(Rimal, 2009). However, one of the weaknesses of the AWS is the dynamic data, which is generated
from the AWS, and could be listened to and penetrated by users.
Microsoft presented a new secure system, which includes five main services forming the core
of the operating system: (i) Windows Azure, which is the main part of the system and is specialised
for hosting services and data storage; (ii) Microsoft SQL Services, which is a part of the relevant
databases for these services developed and hosted by the system; (iii) Microsoft. NET Services, which
is an application framework; (iv) Live Services, share photos and synchronize with computers and
portable devices; and (v) Microsoft SharePoint Services and Microsoft Dynamics CRM Services for
business content management (Calder, 2011).
Fiore and Aloisio (Fiore, & Aloisio, 2011) proposed a new Cloud software security technique
to measure the legitimacy of Cloud resources and the trustiness or trustworthiness in Cloud database
management using the metadata and privilege-based access control. Such technique has several
benefits to ensure integrity and trustworthy of Cloud resources by using everything-as-a-service
(XaaS) mechanism.
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
15
In support of XaaS, there are a variety of operating systems (e.g., Unix and Windows), software
packages (e.g., DBMS and SAP), and Cloud resources existing in such platforms (Kotiyal, et al., 2012).
Each such platform has diverse mechanisms of authentication and authorization. In the range of Cloud
infrastructures, packages, and platforms, a Cloud resource accessed prior in one platform cannot be
accessed by means of the same user in another platform, and vice versa. Cloud Datacenters facilitated
by the features stated above validate that the resource feeder is in the Cloud servers. Even though the
authentication service checks the authenticity of feeder, this does not ensure that a resource posted
by the feeder is free from authentication spoofing, virus attacks, or plagiarism. It is widespread that
an information gap exists between the creator and the feeder of a Cloud resource (Yan, et al., 2015).
Arshad et al (Arshad, et al., 2012) presented efforts to address one of the significant issues with
respect to software security of Clouds, i.e., intrusion detection and severity analysis. An abstract model
for integrated intrusion detection and severity analysis for Clouds is proposed to facilitate minimal
intrusion response time while preserving the overall software security of the Cloud infrastructures.
3. SCENARIO OF CLOUD THREATS
Basically there are six fields of software security vulnerabilities in Cloud computing: (a) data at
end-to-end points, (b) data in the communication channel, (c) authentication, (d) separation between
clients, (e) legal issues, and (f) incident response (Takabi, Joshi, & Ahn, 2010).
One scenario of Cloud threats is that software security principles in the Cloud can be lost
(Cappelli, Trzeciak, & Moore, 2006); for example, criminals might penetrate the Cloud in many
forms. An insider adversary, who gains physical access to Datacenters, is able to destroy any type
of static content in the root of a web server. It is not only physical access to Datacenter that can
corrupt data, but malicious web manipulation tool can penetrate servers and Datacenter machines.
Once they are installed malicious tool can monitor, intercept, and tamper online transactions in a
trusted organization. The result naturally allows a criminal full root access to Datacenter and web
server applications. As soon as such access has been established, the integrity of data or software is
in question (Aljawarneh, 2011; Virvilis, 2015).
There are several software security products (e.g. Antivirus, Firewalls, gateways, and scanners)
to add extra level of software security for Cloud applications and systems but they are not sufficient
as each one of them has only specific purpose and hence, they are called ad-hoc software security
tools. For example, Network firewalls provide protection only at the host and network level (Jiang, et
al., 2013). There are, however, five reasons for why these software security defenses cannot be only
used to secure systems (Jiang, et al., 2013):
1. They cannot prevent malicious attacks that perform illegitimate transactions, because they are
designed to prevent vulnerabilities of signatures and specific ports.
2. They cannot manipulate form operations such as asking the user to submit certain information
or validate false data because they cannot distinguish between the original request-response
conversation and the tampered conversation.
3. They do not track conversations and do not secure the session information. For example, they
cannot track when session information in cookies is exchanged over an HTTP request-response
model.
4. They provide no protection against web application/services attacks since these are launched
on port 80 (default for web sites) which has to remain open to allow normal operations of the
business.
5. Previously, a firewall could suppose that an adversary could only be on the outside. Currently, with
Cloud, an attack might originate from the inside as well, where firewall can offer no protection.
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
16
Figure 1 illustrates the data storage and Datacenters, which are possibly targeted by the criminals.
According to the computer forensics, the distrusted servers and Datacenters are the target of crime
(Wang, et al., 2015). Therefore, the question that needs to be answered is that whether or not data
is safe and secure?
Data confidentiality might be compromised either from insider user threats or outsider user
threats (Zhang, et al., 2010). For instance, insider user threats might maliciously come from: Cloud
operator/provider, Cloud client, or malicious third party. The threat of insiders accessing client data take
place within the Cloud is larger as each models can offer the need for multiple users: i) SaaS – Cloud
clients and administrators, ii) PaaS – Application developers and iii) IaaS – Third party consultants
4. THE PROPOSED GENERIC FRAMEWORK
In this section, we have outlined the proposed generic framework that can act like maps that give
coherence to empirical inquiry. Because conceptual frameworks are potentially so close to empirical
inquiry, they take different forms depending upon the research question that indicated in this article.
The proposed framework consists of three elements as shown in Figure 2:
Figure 1. Cloud Computing Software security
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
17
1. A survey of the existing solutions to identify the some common software security issues, solutions,
and their strengths, weaknesses and limitations.
2. A number of perspectives come from Cloud software security practitioners to explain the key
Cloud software security issues in the firms around world.
3. A classification of Cloud software security levels which are based on the survey and the
perspectives.
Thus, we survey a number of the current solutions in the Cloud software security to outline a
coherence framework. This section includes the existing solutions and their strengths, processes and
weaknesses.
An approach was introduced in (Kotiyal, et al., 2012) suggested the use of five level securities;
which is based on authentication, confidentiality, and integrity to the data stored and accessed by
the cloud user at Datacenters. Authenticity is provided by encryption/ decryption of MAC code and
generation/comparison of hashed password. Use of hashed password limits the requirement of securing
password at all the components and over the network. The authenticity of Datacenter is provided
through the encrypted e-mail carrying the password. The confidentiality and integrity is provided
through hashed password and MD5 digest, which make login process to Datacenters through five
levels. The authentication scheme is based on hashed password storage between cloud provider and
cloud client. Furthermore, the data confidentiality and integrity is provided through MD5 cryptosystem
hash technique. However, the authentication schema limited the access to predefined IP or MAC
address of cloud client, which make the access to the data is restricted to one location. In addition,
the cloud client can access to the Datacenter only from one location.
The authors in (Naik, & Sanyal, 2013) presented a wide variety of methods that can be included
to protect and secure the cloud computing. To secure connection between CC and CP, an encryption
algorithms, and if the connection is through wireless devices, the connection can be secured using
Wired Equivalent privacy (WEP), SSID for each access point and MAC address filtering. In the
meanwhile, there were no any implementation or performance results of efficiency WEP OR SSID
through wireless devices.
In (Nimje, 2013) an approach was adopted through using DNA cryptographic for the optimization
of data software security in cloud software security. DNA encryption is based on Micro array
Figure 2. Components of the proposed framework
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
18
technology as follows: (i) DNA structure has two strands by taking one or more input DNA strands
it can be considered to be the plaintext message; (ii) appending to them one or more randomly
constructed “secret key” strands; and (iii) resulting “tagged plaintext” DNA strands are hidden by
mixing them within many other additional “distracter” DNA strands which might also be constructed
by random assembly. On the other hand, the decryption process (Recovery of plaintext from cipher
text) includes the following steps: (i) given knowledge of the “secret key” strands; and (ii) resolution
of DNA strands can be decrypted by a number of possible known recombinant DNA separation
methods: Plaintext message strands may be separated out by hybridization with the complements of
the “secret key” strands might be placed in solid support on magnetic beads or on a prepared surface.
The DNA cryptography approach is not constraint to specific encryption and decryption algorithms.
However, such approach is still mostly a theoretical concept and still not implemented.
In (Fremantle, & Scott, 2015), the authors proposed an approach that is based on three
cryptographic techniques (such as Key Policy Attribute-based, Encryption, Proxy Re-Encryption,
and Lazy re-encryption) to secure data in cloud Datacenters. Such approach is based on Key Policy
Attribute-Based Encryption to secure the connection between cloud client and provider based on
combination of four algorithms (namely: Setup Attributes, Encryption, Secret key generation, and
Decryption). The Proxy Re-Encryption (PRE) is a cryptographic primitive in which a semi-trusted,
A PRE scheme allows the proxy, given the proxy re-encryption key to translate cipher texts under
public key into cipher texts under public key and vise versa. Finally the lazy re-encryption technique
and allowing Cloud Servers to aggregate computation tasks of multiple operations such as updating
secret keys and updating cloud clients attributes. However, the implications of KP-ABE scheme may
not be entirely realistic, because the approach assumes the existence of a single trusted party who
monitors all attributes and issuing all decryption keys between cloud client and provider.
In (Mathew, 2012), the authors introduced a framework to a secure client cloud environment
through the use of VPN to access network of cloud provider. The proposed framework allows cloud
providers to check for cloud client’s authentication, make sure that clients are authorized. Once the
cloud providers are confident about the clients’ credentials their data will be encrypted and stored.
The whole framework is based on agreed software security policy between cloud clients and providers
to be implemented through use of VPN.
In (Bugiel, 2011) architecture was proposed, which consists of two clouds (twins), a Trusted Cloud
and a Commodity Cloud, where software security-critical operations are performed by the Trusted
Cloud. However, who certify the cloud provider to be trusted in order to be used by cloud client?
The authors in (Suresh, & Prasad, 2012) presented set of software security algorithms, which
can be implemented to overcome software security issues and software security attacks in cloud
computing. In order to protect data transmission between cloud client and provider is by encrypting
data using RSA. Messages between CC and CP is encrypted with the public key can only be decrypted
using the private key. User data include encryption prior to storage, user authentication procedures
prior to storage or retrieval, and building secure channels for data transmission. Authors also describe
how MD5 and AES algorithms in order to secure Datacenters. However, the need for a third party
in important to distribute keys between CC and CP. There is no implementation model that proves
or justify that the three algorithms can calm the fears of cloud clients.
The authors in (Porwal, et al., 2012) presented an approach to secure data in private cloud without
distressing the network layers and protecting the data from illegal users into the server. The data is
secured in server based on users’ choice of software security method so that data is given high secure
priority. Meanwhile, such model suggested the transferred data in private cloud must encrypt in the
on top of the transport layer instead of using IPSec or SSL. This layer is used to encrypt and decrypt
data between client and servers. Accordingly, each time a data is transferred by the cloud client it
is first secured by definite authentication protocols and saved at the server end. Therefore, the data
will be stored in a secured manner at server end. Those who want to gain the data they should be
connected or have access through same framework to view the data.
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
19
To present a more reliable generic framework, we present a number of perspectives by Cloud
software security practitioners to calm clients’ concerns about Cloud Computing.
First Perspective: Keeping information assurance architectures secure and confidential such as details
of how the model-driven software security policies should be enforced in the Cloud systems.
For Instance, the UK Cabinet office published a number of Government Cloud documents but
did not publish the Information Assurance documents. However, Lang (Lang, & Schreiner,
2009) stated that the governments Cloud documents should publish the Information Assurance
documents for the following reasons:
◦ There is no need to create a public Cloud if the documents are confidential and sensitive
and creating a public Government Cloud will not make sense.
◦ Building public or even private Government Cloud is highly expensive. This involves many
servers, Datacenters, services and human powers.
Second Perspective: To date, financial organizations are not willing to adopt public Cloud, because
it would be risky as explained before. But it is possible to use the private Cloud in the financial
organizations.
Third Perspective: The Cloud is a long term consideration so that it needs to know who clients
are dealing with. Therefore, a vendor should understand the client organization and then the
organization realizes the solution under consideration (Subashini, & Kavitha, 2011). For example,
if the proposed applications and services access any sensitive information at any point of the
client’s experience, then the information and the application should be protected. Martin Fisher,
Director of Information Software security at WellStar Health System, explained that “The key
thing when you start talking about private Cloud or whoever, is making sure that in whatever
contract you have, you one: have a right to audit; and two: that the vendor or provider has an
obligation to respond in the event of a declared incident,” (Subashini, & Kavitha, 2011).
Mestas (Software Architect at 3DEV Business & Consulting SAC, USA) forum stated that the
current big picture is mixed of IT infrastructures, including Cloud and non-Cloud systems, for many
companies for many years. Mestas further expounded (Greenhow, Robelia, & Hughes, 2009):
• “Talking about the Cloud space, public Clouds versus private Clouds, many organizations will
likely end up with a mixed IT environment that includes both types of Cloud as well as nonCloud systems and applications, in this approach Hybrid Clouds will be the more widely model
adopted for many enterprises, considering that not all assets can be placed in public Clouds.”
• “The private portion of the Hybrid Cloud must be compliance with the Software security
Standards of the organization and fulfil the interns SLAs, establish software security mechanism
(federation, infrastructure hardening) to integrate with the public portion of the Cloud under
an integration approach or establish a matrix for classify the information that can be published
into the public space.”
In all these study cases, the Hybrid Cloud software security may be little less than other. It is
an accurate that Cloud adoption will widely start from Hybrid unless software security controls and
DR of a Cloud service is proven.
Based on the Cloud system practitioners, researchers and the existing solutions, the proposed
generic framework classifies the Cloud software security issues into the following categories as
illustrated in Figure 3.
Figure 3 shows the levels of Cloud software security that should be considered in the current
and future solutions. In addition, we have to distinguish between these levels and so each level
could have different approach or technique targeted for each level. In other words, the solution of 
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
20
level 1 could not be fitted to other levels. For example, the software security settings of Datacenters
are different from the software security settings of Data transmission. In addition, this framework
addresses another software security level which is not normally considered in the academia, namely
the software security of the Internet Service Provider (ISP). This level is specialized in issues of web
hosting software security and ISP gateways issues.
In addition, there is a difference in the protocol that might be used in each level. These levels
are divided into two types of levels: physical and logical levels. Consequently, the communication
between them needs a way that can understand the data flow between them.
As shown in Figure 3, much research has concentrated to some levels such as remote system
software security, application software security, data transmission software security. Many Cloud
software security tools are developed to add extra level of protection to these levels. However, some
levels are taken a little attention in research such as Datacenter software security level and Hypervisor
software security level. It should be noted that the research attention has been indicated in relation
to the academic survey and Cloud software security practitioners.
As a potential enhancement on the proposed Cloud software security framework, the concepts
of fuzzy systems might be used to solve a large numbers of issues in the Cloud software security on
different levels. However, this requires publishing the source code that associated with the software
security levels’ proposals on the proposed framework (Alcala-Fdez, & Alonso, 2015). Nowadays,
it is possible to facilitate the use of fuzzy systems because the software of software security tools is
commercially distributed but most software is available as free and open source software, reducing such
issues and providing several benefits such as faster error detection, and the innovative applications.
In the proposed framework, we could add the type of software security tools’ software such as
type, library, toolbox, and suite. In addition, the fuzzy languages of software security tools should
be considered in such framework in order to improve the reusability of the developed fuzzy cloud
software security framework.
We have employed the fuzzy based analyzer to distinguish between trusted and malicious
behavior of transaction by distributing the certificates only to the trusted transaction and avoiding
the untrusted transaction. As a note the fuzzy logic based functions are not exact results. Fuzzy logic
variables could have trust values between 0 and 1. In the presented framework, trust decision is based
Figure 3. The proposed framework elements and Cloud software security categories
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
21
on fuzzy logic. If the evaluated trust is greater than or equal to the threshold trust, then that particular
transaction is called as a trustworthy, else it will be treated as untrustworthy and excluded from all
future transaction operations.
5. CASE STUDY: LINKING THE MEDICAL CENTERS
BETWEEN JORDAN AND AUSTRALIA
E-Health software security is a vital problem to be overcome if the web is to develop further. So
that the understanding how to secure healthcare data and communication is the first step in truly
building a connected network, Cloud and/or Cloudlet and inspiring confidence between patients and
healthcare centers. Currently health caregivers, health institutions, healthcare centers and insurance
companies have all had to share information (such as patient registration form, health history with
any trusted provider, and digital health images) related to a patient’s care. This sharing was often
unsecure. For example patients, nurses, doctors, technicians and health organizations might notice
the illegal alteration or illegal copying of confidential digital objects (such as audio, images, video,
documents and others) after the authentication scheme has been performed. However at this stage,
the destruction of objects has already taken place.
In this case study, the proposed framework, which assists to ensure the health information and
communication, is secure, is applied on healthcare centers in Australia and Jordan. Note that there are
number of approaches to professional development, including consultation, coaching, lesson study,
mentoring, reflective supervision and technical assistance. In such study, the mentoring approach
is recommended because a number of proposed experiments will be conducted and so healthcare
information that are distributed through Cloud storages and repositories between the health centers in
Jordan and Australia will be monitored to check any illegal alteration on digital objects is occurred.
A consultation approach might be used in order to assist an individual or group to address immediate
concerns by following a systematic problem-solving process. Furthermore, a workshop could be
suggested to discuss the results and evaluation this type of professional development either the target
clients in Australia or Jordan.
There are many more challenges in Jordanian Health Development such as e-health software
security that need to be solved not only by the government but also community. Therefore, this case
study has been considered into account.
Based on the proposed framework, use of seven level securities; which are relied on authentication,
confidentiality, and integrity to the health information stored and accessed by the users of the health
centers such as Doctors, Nurses, Health officers, government officers, technicians and patients in
Australia and Jordan at the Datacenters. The secure Datacenters are geography distributed between
Cloud Database Servers in Jordan and Australia. Authenticity is offered by the encryption/ decryption
of MAC code and generation/comparison of hashed password. Use of hashed password limits the
requirement of securing password at all the components and over the Cloud. The authenticity of Health
Datacenter is provided through the encrypted e-mail carrying the password. The confidentiality and
integrity is provided through hashed password and SHA-256 digest, which make login process to
Datacenters through seven levels. The authentication scheme is based on hashed password storage
between Cloud Service Provider (CSP) and Cloud Client. Furthermore, the data confidentiality and
integrity is provided through SHA-256 cryptosystem hash technique. This process is recommended to
be applied for the seven level securities from top level of the proposed framework to the down level.
As a result, the patients can virtually receive the health services in a secure manner with high
quality.
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
22
6. CONCLUSION
The existing Cloud services might face various software security issues at the Cloud models level.
One main challenge is that the lack of control over the Cloud Datacenters. Furthermore, software
security is not integrated into the service development process.
Indeed, the traditional software security tools alone would not be able to resolve the recent
software security issues and so it will be helpful to incorporate software security components upfront
into the development methodology of Cloud system. In this paper, a number of Cloud practitioners’
perspectives are presented to calm the clients’ fears against the Cloud concerns. We present a
conceptual framework of three components that assist to indicate the levels of Cloud software security
that should be taken into account by researchers and practitioners. This paper has faced an important
issue, and provided a wide analysis of available solutions, as well as a useful fuzzy framework, helping
readers to orient themselves in the field of Cloud software security.
Consequently, it is recommended that the governments should keep their information assurance
architectures secure and confidential. Moreover, financial organizations are not willing to adopt public
Cloud because it will be risky. However, such organizations may adopt the use of the private Cloud
instead. As a part of future work, we will reveal/validate the effectiveness of proposed system via
some case studies or available date sets. Also we will include details about the performance analysis/
implementation of proposed work with existing studies. Finally the proposed framework could be more
secure, reliable and aids to add extra level of software security in military and financial operations
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
23
REFERENCES
Alcala-Fdez, J., & Alonso, J. (2015). A Survey of Fuzzy Systems Software: Taxonomy. Current Research Trends
and Prospects.
Aljawarneh, S. (2011). Cloud Security Engineering: Avoiding Security Threats the Right Way. International
Journal of Cloud Applications and Computing, 1(2), 64–70. doi:10.4018/ijcac.2011040105
Aljawarneh, S., Alkhateeb, F., & Al Maghayreh, E. (2010). A semantic data validation service for web
applications. Journal of Theoretical and Applied Electronic Commerce Research, 5(1), 39–55. doi:10.4067/
S0718-18762010000100005
Aljawarneh, S., Alshargabi, B., Hayajneh, M. A., & Imam, A. (2015). Integration of E-learning and Cloud
Computing Platform Through Software Engineering. Recent Patents on Computer Science, 8(2), 100–105. doi
:10.2174/2213275908666150706174305
Armerding, T. (2012). The 15 worst data security breaches of the 21st Century. COS Security and Risk.
Arshad, J., Townend, P., & Xu, J. (2012). An abstract model for integrated intrusion detection and severity
analysis for clouds. Cloud Computing Advancements in Design, Implementation, and Technologies, 1.
Arthur, C. (2010). Google’s ChromeOS means losing control of data, warns GNU founder Richard Stallman.
The Guardian Tuesday, 14.
Bugiel, S., Nürnberger, S., Sadeghi, A. R., & Schneider, T. (2011, January). Twin clouds: Secure cloud computing
with low latency. In Communications and Multimedia Security (pp. 32–44). Springer Berlin Heidelberg.
doi:10.1007/978-3-642-24712-5_3
Calder, B., Wang, J., Ogus, A., Nilakantan, N., Skjolsvold, A., McKelvie, S., & Haridas, J. et  al. (2011,
October). Windows Azure Storage: a highly available cloud storage service with strong consistency.
Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles (pp. 143-157). ACM.
doi:10.1145/2043556.2043571
Cappelli, D. M., Trzeciak, R. F., & Moore, A. B. (2006). Insider Threats in the SLDC: Lessons Learned From
Actual Incidents of Fraud: Theft of Sensitive Information, and IT Sabotage (Presentation).
David, G., & Anbuselvi, R. (2015, February). An architecture for Cloud computing in Higher Education.
Proceedings of the 2015 International Conference on Soft-Computing and Networks Security (ICSNS) (pp. 1-6).
IEEE. doi:10.1109/ICSNS.2015.7292432
Fiore, S., & Aloisio, G. (2011). Grid and cloud database management. Springer Science & Business Media.
doi:10.1007/978-3-642-20045-8
Fremantle, P., & Scott, P. (2015). A security survey of middleware for the Internet of Things. PeerJ PrePrints,
3, e1521.
Greenhow, C., Robelia, B., & Hughes, J. E. (2009). Learning, teaching, and scholarship in a digital age
Web 2.0 and classroom research: What path should we take now? Educational Researcher, 38(4), 246–259.
doi:10.3102/0013189X09336671
Jadeja, Y., & Modi, K. (2012, March). Cloud computing-concepts, architecture and challenges. Proceedings
of the 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET) (pp.
877-880). IEEE. doi:10.1109/ICCEET.2012.6203873
Janssen, M., & Joha, A. (2011). Challenges for adopting cloud-based software as a service (saas) in the public
sector. In ECIS.
Jiang, W., Li, Z., Jia, J., & Liu, D. (2013, September). Evaluating E-Commerce System Security Using Fuzzy
Multi-criterion Decision-Making. Proceedings of the 2013 IEEE Seventh International Conference on Semantic
Computing (ICSC) (pp. 438-443). IEEE.
Kotiyal, B., Saxena, P., Goudar, R. H., & Jogdand, R. M. (2012). A 5-Level Security Approach for Data Storage
in Cloud. International Journal of Computer Applications, 54, 29-34.
International Journal of Intelligent Information Technologies
Volume 12 • Issue 2 • April-June 2016
24
Lang, R. S. U., & Schreiner, R. (2009). Top SOA Security Concerns & OpenPMF Model-Driven Security.
ObjectSecurity white-paper.
Mathew, A. (2012). Security And Privacy Issues Of Cloud Computing; Solutions And Secure Framework.
International Journal of Multidisciplinary Research, 2(4).
Naik, P., & Sanyal, S. (2013). Increasing Security in Cloud Environment. arXiv preprint arXiv:1301.0315.
Nimje, A. R. (2013). Cryptography. In Cloud-Security Using DNA (Genetic). Techniques.
Porwal, A., Maheshwari, R., Pal, B. L., & Kakhani, G. (2012). An Approach for Secure Data Transmission in
Private Cloud. International Journal of Soft Computing and Engineering.
Rimal, B. P., Choi, E., & Lumb, I. (2009, August). A taxonomy and survey of cloud computing systems.
Proceedings of the Fifth International Joint Conference on INC, IMS and IDC NCM’09 (pp. 44-51). IEEE.
doi:10.1109/NCM.2009.218
Sessions, L. F. (2009). “You Looked Better on MySpace”: Deception and authenticity on the Web 2.0. First
Monday, 14(7). doi:10.5210/fm.v14i7.2539
Subashini, S., & Kavitha, V. (2011). A survey on security issues in service delivery models of cloud computing.
Journal of Network and Computer Applications, 34(1), 1–11. doi:10.1016/j.jnca.2010.07.006
Suresh, K. S., & Prasad, K. V. (2012). Security issues and Security algorithms in Cloud Computing. International
Journal of Advanced Research in Computer Science and Software Engineering, 2(10).
Takabi, H., Joshi, J. B., & Ahn, G. J. (2010). Security and privacy challenges in cloud computing environments.
IEEE Security and Privacy, 8(6), 24–31. doi:10.1109/MSP.2010.186
Vaquero, L. M., Cáceres, J., & Morán, D. (2012). The challenge of service level scalability for the cloud. Cloud
Computing Advancements in Design, Implementation, and Technologies, 37.
Virvilis, N., Mylonas, A., Tsalis, N., & Gritzalis, D. (2015). Security Busters: Web browser security vs. rogue
sites. Computers & Security, 52, 90–105. doi:10.1016/j.cose.2015.04.009
Wang, B., Zheng, Y., Lou, W., & Hou, Y. T. (2015). DDoS attack protection in the era of cloud computing and
Software-Defined Networking. Computer Networks, 81, 308–319. doi:10.1016/j.comnet.2015.02.026
Wang, H., Zhang, Y., & Cao, J. (2009). Effective collaboration with information sharing in virtual universities.
IEEE Transactions on Knowledge and Data Engineering, 21(6), 840–853.
Yan, Z., Li, X., & Kantola, R. (2015). Controlling Cloud Data Access Based on Reputation. Mobile Networks
and Applications, 2015, 1–12.
Zhang, X., Wuwong, N., Li, H., & Zhang, X. (2010, June). Information security risk management framework for
the cloud computing environments. Proceedings of the 2010 IEEE 10th International Conference on Computer
and Information Technology (CIT) (pp. 1328-1334). IEEE. doi:10.1109/CIT.2010.501
J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204
www.elsevier.com/locate/jpdc
Countering security threats in service-oriented on-demand grid computing
using sandboxing and trusted computing techniques
Matthew Smith, Thomas Friese, Michael Engel, Bernd Freisleben∗
Department of Mathematics and Computer Science, University of Marburg, Hans-Meerwein-Strasse, D-35032 Marburg, Germany
Received 17 December 2005; received in revised form 31 March 2006; accepted 10 April 2006
Available online15 June 2006
Abstract
In this paper, an analysis of security threats within service-oriented on-demand Grid computing environments is presented. The analysis is
based on identifying three levels of trust relationships and three types of Grid applications in on-demand computing; the trust relationships
involve interactions among resource providers, middleware producers, solution producers, and users. The paper presents solutions for addressing
the threats inherent to these three increasingly demanding levels. The solutions involve applying sandbox-based approaches using virtual machine
technology and jailing mechanisms to ensure trust for the first two levels of on-demand Grid computing, as well as Trusted Computing Platform
Alliance (TCPA) technology for the third level of on-demand Grid computing. A brief taxonomy of the presented solutions is introduced.
© 2006 Elsevier Inc. All rights reserved.
Keywords: Grid security; On-demand computing; Service-orientation; Sandboxing; Virtualization; Trusted computing
1. Introduction
The Grid computing paradigm is aimed at providing resources (such as compute power, data, access to special appliances and even people) as easy as electricity is provided through
the electrical power Grid. Organizations or inter-organizational
communities willing to share their computational resources typically create a centrally planned Grid, where dedicated Grid
administrators manage the nodes and the offered Grid services.
The service-oriented Grid computing paradigm [10,9]
offers the potential to provide a fine-grained virtualization of
the available resources to significantly increase the versatility
of a Grid. For instance, all idle workstations of a company may
be combined into a dynamically formed ad hoc Grid [30] to
handle computational peak loads, thus extending the maximum
 This work is partially supported by the German Ministry of Education and
Research (BMBF) (D-Grid Initiative, In-Grid Project), Siemens AG (Corporate
Technology, München) and IBM (Eclipse Innovation Grant). ∗ Corresponding author.
E-mail addresses: matthew@informatik.uni-marburg.de (M. Smith),
friese@informatik.uni-marburg.de (T. Friese),
engel@informatik.uni-marburg.de (M. Engel),
freisleb@informatik.uni-marburg.de (B. Freisleben).
0743-7315/$ - see front matter © 2006 Elsevier Inc. All rights reserved.
doi:10.1016/j.jpdc.2006.04.009
computational power of the company without further expense.
This brings the service-oriented Grid a step closer to fulfilling
IBM’s vision of on-demand computing [12]. In the on-demand
computing paradigm, required processor cycles, services or
rarely used resources can be “out-sourced” to organizations offering computational power, services or the required resources.
For this it is desirable to be able to rent resources in a flexible
fashion, with only minimal administrative overhead. It must be
possible to acquire and configure the needed resources without
requiring an administrator to personally oversee and facilitate
each and every transaction.
In this paper, we analyze security issues of on-demand Grid
computing, present a corresponding threat model and discuss
the challenges with respect to authentication, authorization,
delegation and single sign-on, secure communication, auditing,
safety, and confidentiality. The actors involved in the threat
examination are: resource providers (owners of compute
nodes), middleware producers (owners of middleware), solution
producers (owners of a software product which runs on a resource provider’s node) and users (users of the solution producers’ products). Three different levels of on-demand Grid computing are identified, based on different levels of trust between
the resource providers, middleware producer, solution producers and users. The first level deals with threats posed between
1190 M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204
different users and solution producers, the second deals with
the threats posed to the resource provider by the solution producers and the third deals with the threats posed to the users
and solution producers by the resource provider. To deal with
the first threat level, three different solutions are presented. The
first approach is a Java sandboxing approach that deals with
pure Java WSRF [19] based service-oriented grid applications.
The second approach is a fine-grained jailing solution which is
also capable of dealing with WSRF-based Java services with
native code components. The third approach is a coarse-grained
sandboxing solution based on the Xen virtualization technology
which deals with monolithic native code applications. To deal
with the second threat level, it is shown how the solutions from
the first level can be utilized to protect the resource provider
from the solution producers. Also, three different integration
options are presented to deal with the different security and
usability requirements of the second level of on-demand Grid
computing. To deal with the security issues posed by the third
level, a hardware-based security solution using Trusted Platform Modules (TPMs) is presented. The security mechanisms
presented in this paper increase the resilience of the Grid environment against both malicious attacks and erroneous code.
Finally, a brief taxonomy of the proposed solutions is presented
to aid in the decision making process, if technologies are to be
selected for an on-demand Grid security system.
The paper is organized as follows. In Section 2, the three
levels of on-demand Grid computing with increasing complexity are introduced. Section 3 presents the on-demand Grid computing threat model. In Section 4, the challenges for on-demand
security are described. Sections 5–7 present solutions for providing security for the three levels of on-demand Grid computing. Section 8 presents a brief taxonomy of the solutions from
the previous sections. Section 9 concludes the paper and outlines areas for future research.
2. On-demand grid computing
To be able to assess the threat model for on-demand Grid
computing we must first define who the actors in this scenario are and the nature of the trust relationships between them.
Before we describe the on-demand scenarios, we discuss the
trust relationships in the traditional Grid usage scenario.
Four actors take part in this scenario:
• Resource provider: Owner of the computational nodes or
other physical resources.
• Middleware producer: Owner of the middleware which is
deployed on the resource provider’s nodes.
• Solution producer: Owner of a software solution and/or information database which is deployed via the middleware
onto the resource provider’s assets.
• User: Owner of input data for a solution producer’s product;
user of the solution producer’s product via the Grid middleware, hosted by the resource provider.
The solution producer hosts his or her software and data as
a number of services on the nodes of the resource provider
where the user can then consume them via the service-oriented
middleware. The resource provider must grant access to both
the solution producer and the user. Access is granted via the
management services of the Grid middleware although in some
cases access is still granted in the form of a remote user account
with which the nodes of the Grid can be accessed, either directly
or via a Head Node or Gatekeeper. While it is possible to
install most custom software in the solution producer’s home
directory, sometimes it is necessary to have root privileges to
install required software. In this case, the resource provider
must either grant the solution producer temporary root access
or perform the needed operations on his behalf.
Fig. 1 shows the trust relationship between the typical actors
found in Grid computing today. The resource provider must
trust the solution producer and the middleware producer not to
misuse the resources offered by the resource provider. Possible forms of misuse are: using the rented nodes to send junk
mail, do a denial of service attack, host illegal content for others to download or steal account information from the resource
provider to hijack other nodes in the system. The solution producer must trust the resource provider and middleware producer
not to misuse the software or database hosted on the resource
provider’s assets. Possible forms of misuse are: stealing the software or the information contained in the database, altering the
software or the information in the database or allowing access
to unauthorized parties. Critically, the solution producer must
trust the resource provider that the accounting and billing data
concerning the services belonging to the solution producer are
stored securely. The user who consumes the service offered by
the solution producer through the resource provider must trust
all other parties not to misuse the data entered into the solution
producer’s product. Possible forms of misuse by the solution
producer are: stealing the input and output data or modifying
the results. Possible forms of misuse by the resource provider
are the same as for the solution producer, as well as: hijacking
the users account to use the solution producer’s product at the
user’s expense. The user must also trust the solution producer
and the resource provider that the accounting and billing data
concerning the users activity are stored securely.
Fig. 1 shows the basic set of actors needed to describe business interactions in a Grid environment. The trust relationships
are currently built by legal contracts between the parties ensuring that misbehaving parties can be sued. Since that only
allows punishment after the fact and mainly works in a business environment, it is currently not uncommon that access
is only granted to persons who know each other personally
and non-IT trust exists between the parties. In some cases, the
solution producer and the resource provider or the user and the
solutions producer are the same person, in which case the trust
requirements are somewhat reduced. In many cases, however,
more than one solution producer or user will be present. In
our experience, there are two common practices in this case.
First, the different users or solution producers operate on noncritical data or software and do not mind if others can see their
assets (quite common in the academic environment). Second,
the resource provider grants only exclusive access to specific
resources, thus creating several separate environments which
behave like the single user/solution producer environment
M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204 1191
Fig. 1. Trust relationships in current Grid computing systems.
shown above. The second solution is not in the interest of any
of the parties, since such a use of the resources ties up the resources completely, no matter if the user is currently using them
at full capacity or not and thus drives up the price the resource
provider must ask for services offered on such a system.
In an on-demand environment, neither of the above practices is acceptable. The solution producer must be able to dynamically acquire resources for critical tasks from a resource
provider to meet user demands in an on-demand fashion, and
the resource provider must be able to maximize the resource
usage over the entire spread of solutions producers and users.
We define three levels of this form of on-demand Grid computing:
Level 1: The first level encompasses the scenario described
above in its most basic form. Multiple users and solution producers operate on the resources of a single resource provider.
There is no trust between the different users or between a user
and the solution producers used by the other users. There is also
no trust between the solution producers or a solution producer
and users of other solution producers. The trust relationship between the user, solution producer and resource provider cooperating with each other is the same as in the traditional usage
scenario. In level 1 all parties trust the middleware producer.
Fig. 2 shows the “no trust” relationship of this level. For the
sake of readability, the “trust” arrows are not depicted. Trust
can be assumed between all parties not connected with a “no
trust” arrow.
Level 2: In the previous level, on-demand computing still requires the resource provider to trust the solution producer for
the reasons mentioned above. This trust is acquired either by
legal or social means. Both these methods restrict the number of customers a resource provider can take on and creates
Fig. 2. On-demand trust relationships: level 1.
a cost overhead for resource usage both in time and money,
since trust must first be established. It is desirable to eliminate
the trust requirement from the resource provider to the solution
producer to facilitate a more flexible and cost effective business model. To enable level 2, on-demand computing requires
security mechanisms to protect the resource provider’s assets
from the solution producers while at the same time granting
the required access rights to the resources the solution producer
and the users need. It is also desirable that the middleware
no longer needs to be fully trusted. While it is unlikely that
the middleware producer has malicious intentions towards the
other parties, erroneous middleware code can lead to system
crashes or security breaches. Since the threats stemming from
the middleware are not of a malicious nature, the grey no-trust
arrows symbolize a less critical requirement. Fig. 3 shows the
“no-trust” relationship of level 2. For the sake of readability,
the “trust” arrows are not depicted. Trust can be assumed between all parties not connected with a “no-trust” arrow.
Level 3: In the previous level, on-demand computing diminishes the need for the resource provider to trust the solution
producer. The solution producer still must trust the resource
provider. This hinders easy and cost effective acquisition of resources from new resource providers since a trust relationship
must first be acquired. Level 3 on-demand computing removes
the trust requirement between solution producers and resource
providers completely by offering security measures protecting the solution producers’ assets not only from other solution
producers and users but also from the resource provider. This
added security also removes the need for the users to trust the
resource provider. Furthermore, the middleware producer no
longer needs to trust the resource provider. This is mainly of interest for commercial middleware solutions where pirate copies
1192 M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204
Fig. 3. On-demand trust relationships: level 2.
Fig. 4. On-demand trust relationships: level 3.
and intellectual property rights are an issue. The only trust requirements left in level 3 are that the users must trust their solution producer and the middleware producer. These final trust
requirements can never be fully removed by technical solutions, since the middleware must enable the solution producer’s
software to read the users’ data and thus both the middleware
producer and the solution producer will be able to make illicit
copies of the software and data passed to them. Fig. 4 shows all
trust relationships in this final level of on-demand computing.
3. On-demand threat model
For the following threat analysis, we consider a shared ondemand service hosting environment. As mentioned above,
there are several users and solution producers involved within
the same shared resource environment active at the same time.
Thus, it must be possible for those entities to acquire and
configure the needed resources without requiring the resource
provider to personally oversee and facilitate each and every
transaction. This creates a number of new security threats beyond the security threats of standard Grid systems. These new
security threats arise from: (1) the greater number of participants, (2) the different usage model [30,31], and (3) emergent
properties from the combined interactions of many transactions resulting in complex, unintended behaviors not found in
individual transactions [37].
In general, one can distinguish between internal and external
attacks. Internal attacks are committed by entities with legitimate access to the system, while external attacks are committed
by entities which do not possess access rights and must therefore break into the system. According to [7], internal attacks
are the most common form of attack. This is a very pertinent
fact for on-demand Grid computing, since in on-demand computing the number of legitimate solution producers and users
is much larger and more dynamic than in traditional systems.
Thus, it is to be expected that the number of internal attacks
will also be much higher and thus even more of a threat in the
on-demand world.
External attacks are made possible by the changing nature
of cluster computing which is an integral component of today’s
Grid systems. Clusters have moved from closed/proprietary
environments in a closed network (particularly in commercial
settings) to open/standard systems that are often exposed to
public networks. External attackers can probe the publicly available resources for vulnerabilities which can then be exploited
[14,16]. This change is furthered by the Grid middleware which
connects multiple cluster sites and exposes them all via a common middleware layer. This change has resulted in exposing
clusters to a variety of point-and-click attack tools that are easily available on the Internet. Furthermore, most Grids run code
from third party partners or software providers. It is almost
impossible for time and money reasons to perform a security
audit on all of this code. This is a major change compared to
traditional clusters running a controlled base of known source
code [21]. This is in line with the security observations done
by SANS [26]. The Top-20 list of security threats for 2005 was
extended by a new category. Traditionally, the security threats
were divided into Windows and Unix operating system threats.
This year, SANS included a cross-platform application threat
category in their security analysis. This reflects the changes in
the general security landscape. The trend away from operating
system specific attacks towards application specific attacks is
an issue of particular relevance for on-demand Grid security,
M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204 1193
since a multitude of third party applications will be running in
this environment, opening a multitude of new attack vectors.
Just as the greater number of legitimate solution producers
enhances the internal threat level, it also has an adverse affect
on the external threat level, for two reasons. First, the amount of
third party code and with that the possible attack vectors is increased with each further solution producer. Second, the amount
of legitimate activity on the resources is increased, making it
more difficult to detect unauthorized access. This is especially
true for a special type of external attack where the external entity steals a legitimate entity’s identity and masquerades as that
user, or where a legitimate user’s session is hijacked.
An IBM security paper [23] examines the trends of attack
from the 1980s up to today, concluding that the client has become the prime target for hackers. Just as the greater number of
users increases the threat of internal attacks, the greater number of users creates a much broader base of attack for external
hackers to hijack compromised client systems.
If the origin of the participants is not factored in, the greater
number of participants alone creates a new quantity of threat
to the on-demand Grid computing environment but not a new
quality. The new level of threat described above can be dealt
with using traditional security mechanisms, if the significant
amount of extra work can be invested into the execution of the
security protocols.
A new quality of threat is introduced by two factors of ondemand Grid computing. First, as the solution producers need
greater privileges to efficiently install their applications, there
must be mechanisms in place to make sure these privileges are
not misused. We label these threats “privilege threats”. Second,
in an on-demand environment the closed world assumption,
typically true in traditional Grid environments, is no longer
true. Users from different organizations can potentially rent
resources from the same on-demand resource provider, making
it critical that the resource provider enforces a strict separation
between all participants. We label these threats “shared use
threats”.
Privilege threats arise from the fact that solution producers
must be able to administer their system without a central administrator who is trusted by all participants and can perform a
security audit on all code submitted into the system. However, if
solution producers are allowed to install and configure custom
software as needed in an on-demand fashion, it is also possible
that malware such as spam-bots, root-kits, etc. can be installed.
This ability to install software freely opens the door for easy
execution of the threats in the shared use threats category.
For shared use threats we distinguish between three types
of attacks: resource attacks, data attacks and meta-data attacks.
The resource and data attacks are further subdivided into attacks
against the resource provider or solution producer/user. While
the attacks against the resource provider are also relevant for
standard Grid computing systems, they are particularly relevant
for shared user systems since more data (such as passwords and
certificates) can be gathered if more than one user is present in
the system. We do not list any attacks against the middleware,
since the middleware does not represent a resource which can
be abused in itself. Attacks against the middleware are used to
gain access to the hosting node, services or service data and
as such fall into the categories for those attacks. We also do
not list any attacks stemming from the middleware producer
since we assume that the middleware is supplied by a neutral
party and is either quality assured by a large corporation or
stems from a large open source community project and there is
no motivation for attacks. Examples for each of the resulting
attack scenarios are presented in the following:
• Resource attack against the resource provider: Illegal use of
CPU cycles, network bandwidth or other physical resources
fall into this category. For instance, a malicious entity may
install a spam-bot that is used to send unsolicited bulk emails from the hosting network node. A number of denial
of service attacks also fall into this category.
• Resource attack against other solution producer/users: Illegal use of software or physical resources controlled by
other solution producers or users fall into this category.
A malicious entity may invoke programs from other solution producers directly without authorization or use software
licenses for third party software that belongs to other users.
Alternatively, a malicious entity could masquerade as a certain user and consume his or her rented CPU cycles.
• Data attack against the resource provider: Illegal access to
or modification of data owned by the resource provider falls
into this category. A malicious entity may extract or alter
security critical data from the underlying operating system
or hosting environment, such as the system password files
or certificate files. Faking log entries also falls into this category. One critical attack which falls into this category is
the malicious faking of accounting and billing data stored
by the resource provider. Since on-demand computing relies
on payment for rented resources, an attack which threatens
the correctness and safety of the billing and accounting data
is a serious threat to the entire system.
• Data attack against other solution producers/users: Illegal
access to or modification of data owned by other solution
producers or users fall into this category. A malicious entity
may read temporary data or results produced by other users
as well as input data used by them. If, for example, a pharmaceutical company uses a Grid node for computations in
the design phase of a new drug, a competitor may deploy
a malicious service that extracts the experimental data used
as input of the computation or the resulting outputs. One
critical attack which falls into this category is the malicious
faking of accounting and billing data stored by the solution
producer. Since on-demand computing relies on payment for
used services, an attack which threatens the correctness and
safety of the billing and accounting data is a serious threat
to the solution producer.
• Meta-data attack: A malicious program can use operating
system commands like PS or middleware specific information services to acquire information about competitor’s work.
In the automotive industry, many small jobs, for instance,
can indicate parameter studies in an early phase of development for a new car model, while a single large job can be
the final simulation of the entire car. Information like this
1194 M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204
Fig. 5. Threat hierarchy.
can prove invaluable for competitors when mission critical
decisions need to be made concerning release dates for their
own new car model or in takeover bids.
Both of the resource attacks can be subdivided into illegal
access to resources and denial of service against the local system through excessive resource consumption. Note that participation in a distributed denial of service attack counts as illegal
resource access since the host is only used to harm other systems by illegally using the network interface, whereas recursively starting new threads is a denial of service attack against
the hosting system. An overview of the threat type hierarchy is
shown in Fig. 5 which connects the threat types (grey boxes)
with the entities executing them and the entities endangered
by them. The attacks can be executed directly through weaknesses of the middleware or through the installed services which
then in turn exploit weaknesses of the underlying operating
system.
4. Challenges for on-demand security
There are several challenges for security in an on-demand
Grid computing environment:
Authentication ensures that an entity is a valid user before
access to resources is granted. In cluster computing, authentication is often done with passwords a user enters on request. In
Grid computing, certificates (mostly X.509) are used instead of
passwords. It must be ensured that passwords/certificates can
be tied to a legal person, so it is possible to take legal action in
case of misuse of an account. To get a user certificate, it is necessary for a Registration Authority (RA) to personally confirm
the identity of the requesting entity and then get the certificate
signed by a Certificate Authority (CA).
The private end-entity certificates are usually held by the
end-entity themselves. While passwords can be learnt by heart
and do not need to be saved to disk, certificates must be stored
in digital form. This creates a security risk since the CA that
signs the certificate has no means to enforce key hygiene on
the side of the end-entity. Thus, even if a certificate is signed
by a trustworthy CA, there is no way the CA can guarantee
that the certificate was not stolen after signing. A recent IBM
security study found that 80% of Windows clients have spyware infestations and 30% already have back doors [25], thus
opening the door for identity theft. Certificate theft usually goes
undetected for a long time as there is no physical lack of the
stolen object on the owner’s side. The problem of storing certificates on unsecured end-entity machines can be solved by
the introduction of credential stores which store the certificates
on behalf of the end-entity. The end-entity uses a password to
access the remote certificates. This system combines the benefits of humanly learnable passwords with the certificate trust
framework. Of course, it only makes sense if the passwords are
not stored on the end-entity machine. Such credential stores
are of course tempting targets for attack since they contain a
lot of valuable data at a single point. However, poorly managed credentials have caused uncountable security incidents
while, to the best of our knowledge, not a single centrally maintained authentication server has been compromised in the past
decade [34].
Even in traditional Grid systems, certificate and password
hygiene is a problem. In on-demand computing, this problem
is amplified by the number of participants in the system. In a
closed world scenario, a system administrator who knows his
users can monitor his Grid resource (i.e., a Cluster, Radio Telescope or High Performance Computer) and identify unusual behaviour and check for identity theft on a manual basis. Even in
level 1 of on-demand Grid computing this is no longer possible.
Not only is the number of users which need to be monitored
potentially too high, but a single administrator cannot know the
normal behaviour of users who only use his resources in an
on-demand fashion. In [38], a system is proposed that automatically identifies a user by analyzing the command patterns in a
user’s audit trail. Such a system can warn a local administrator
if unusual command patterns are found for a known user and to
a certain extent even issue a warning if an unknown user is executing a command which falls into an attack cluster category.
Such a system could prove invaluable to the on-demand Grid
computing community since it is capable of assisting in the
detection of certificate theft across organizational boundaries.
Cooperating resource providers could combine their knowledge
of attack patterns and thus gain a broader basis for detecting
malicious behavior in unknown users. On the other side, users
could let resource providers access their command pattern in-
M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204 1195
formation to protect themselves against identity theft and the
bills which follow.
Authorization ensures that every authenticated user can only
access the resources that he or she is allowed to. Most of the
attacks described in Resource attack against the resource
provider and Resource attack against other solution producer/users executed by users can be stopped by sufficiently
tight authorization enforcement. In cluster computing, authorization is usually done via user rights of the local operating
system which are configured by the local administrator manually. In the Grid environment, there has been a rapid evolution
in the past years of different authorization technologies (Gridmap files used by Globus [36], VOMS [1], CAS [20], PERMIS
[5]) which unfortunately do not inter-operate. For on-demand
Grid computing it is important that a standardized approach
is adapted by the resource providers so that the solution producers can create requirement requests which encapsulate the
needed resources and access rights needed by the software
solution and the users who consume the solution. Such a standardized framework allows solution producers to find resource
providers whose security policies match the required access
rights of their application. Another issue is the revocation of
access rights. In current Grid systems, the target revocation
delay is 10–60 min [34]. In an on-demand environment, it is
desirable to have much lower delays not only because resource
providers can avoid their resources being abused but also for
users who would have to pay the bill. Currently, Certificate Revocation Lists (CRL) are used to revoke access rights throughout a Grid environment, however practical implementations of
this system do not meet even the current delay target. In [17],
Online Certificate Status Protocols (OCSPs) are proposed to
allow the timely revocation of user rights. Just as with authentication, the resource providers would do well to combine their
authorization framework to cooperatively be able to respond
quicker to newly identified attacks and attackers.
All of the above requirements can be handled using standard Grid authorization frameworks and enough man power to
handle the requests for resources as they come in. It is then
up to the resource provider to ensure that users do not get the
chance to execute programs that they do not have sufficient access rights for. With a competent and dedicated administrator
this procedure is not too difficult. However, as stated above, in
on-demand Grid computing, the solution producers and their
software potentially require significant (possibly root) access
to the system to be able to execute their on-demand business.
In complex software systems it is already next to impossible to
impose a full security audit on the code before installation, in
the on-demand environment it is not feasible at all. It is therefore very difficult to ensure that solution producers do not illegally access other solution producers’ or users’ assets which are
hosted within the same operating system. This is, however, a requirement of level 1 on-demand computing as there is no trust
relationship between the different solution producers and users.
To ensure that the resources of different solution producers and
users are protected from unauthorized access, an automatic and
secure sandboxing system is required to separate the different
solution producers from each other and only allow legitimate
users to access their chosen solution producer’s software and
data. Since this is one of the more critical issues of on-demand
Grid computing, we will deal with this topic in more detail
in the next section where such a sandboxing system will be
presented.
Delegation and single sign-on allows the system to carry
out a range of functions on behalf of the user who only has
to log on to the system once. This is one of the major requirements of Grid computing and is an extension of the authentication and authorization process which is dealt with by
systems like MyProxy [18]. It can be distilled down to the
problem of online key management and bootstrapping in a distributed environment. All the problems described above are
valid here as well as the new security risks introduced by the
proxy delegation system used to enable the single sign-on.
Naturally, the more credentials which are stored online to facilitate single sign-on, the easier it becomes to steal a user’s
identity. Once an attacker gains access to a user’s bootstrapping mechanism, it becomes very easy to move through an
on-demand system, as there are less personal checks in place.
The bootstrapping mechanism must therefore be highly protected. Possibilities are one-time passwords based on a shared
secret passed in an out-of-band fashion or the use of biometric
data. CryptoCard [8] or SecureID- [28] based systems can also
beutilized.
Secure communication guarantees integrity, confidentiality
and non-repudiation of data communication. This fortunately
is an area where we do not see a significant change in the security requirements for on-demand Grid computing. Apart from
a possible higher volume of traffic, the systems developed to
secure communications in the web can be used without modification in the on-demand scenario.
Auditing allows resource providers and solution producers
to see what actions were done when and by whom (authorized
and unauthorized). While auditing is not directly a mechanism
to secure a system, it is nevertheless a vital component in the
overall security architecture, since it is the source of proof for
possible defence or legal actions. It is also often a target for
attackers who want to cover their tracks or harm other users of
the system by manufacturing fictitious usage logs. The latter is
particularly pertinent in an on-demand scenario, because audit
data are the basis for billing. Most of the requirements for auditing in an on-demand scenario are identical to the traditional
auditing requirements. One significant difference is that in a
traditional system the resource provider usually is the only entity authorized to access audit data. In the on-demand scenario,
the solution producers are likely to require access to the audit
data pertinent to their solution. It must be ensured that there
are automated mechanisms to allow them that access while at
the same time protecting the audit data from other solution
producers.
Accounting and billing: Accounting is a special form of auditing where resource and service usage is logged for billing
purposes. Like auditing, accounting and billing is not a security service itself but a system which has to be secured. Since
in on-demand Grid computing, resources and services are hired
on a case-by-case basis, accounting and billing is vital part of
1196 M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204
the Grid environment. Most of the requirements for accounting
and billing in an on-demand scenario are identical to the traditional accounting and billing requirements. One significant
difference is that in a traditional system the resource provider
usually is the only entity authorized to access accounting data
and billing services. In the on-demand scenario, the solution
producers are likely to require access to the accounting data
and billing services pertinent to their solution. It must be ensured that there are automated mechanisms to allow them that
access while at the same time protecting the data and services
from other solution producers.
Safety of data is the concern of fail-safe short term and
long-term preservation of user data even in the presence of
catastrophic failure of individual system components, such as
operating system crashes and storage media failure. External
storage is often separated into two categories in large Grid
systems: working areas that provide relatively fast access to
moderate data volumes for use by current tasks, and longterm storage systems such as tape libraries for backup and
data retention. In an on-demand Grid environment, the discovery and selection of suitable storage media for long time
archival is a challenging task. Often, data safety has to be
achieved by collaborative replication of data or by using data
archival services provided by third parties. In any case, it is
important that long time storage of data can be limited to
trusted data stores or data are only stored in encrypted form
in order to keep storage providers and unauthorized third parties from accessing long time archives. Certain applications
will require systems to be selectable by the degree of guarantee these systems can give with respect to fault tolerance for
managed data.
Confidentiality ensures that private data (including metadata concerning their Grid activity) of all participants are
protected from all unauthorized entities. This is the area where
on-demand Grid computing is most challenging. The large
number of users and solution producers create the need for
very tight data security, otherwise commercial use will be
very restricted. Standard data access controls offered by the
operating system can be configured to protect users’ files
from other users, but if an attacker gains root access to the
system, the data can be accessed nevertheless. Furthermore,
meta-information can be gathered via commands like ps or
via Grid monitoring tools, while commercial cluster management systems restrict the use of such tools on a tool-by-tool
and command-by-command basis, but the ability of solution
producers to install custom software in the systems makes it
next to impossible to protect meta-data within a standard operating system. To ensure that the confidentiality requirements
of on-demand customers are met, an automatic and secure
sandboxing system is required to separate the different solution
producers from each other, the different users from each other
and only allow legitimate user to access their chosen solution
producer’s software and data. We already identified the need
for a sandboxing system for authorization enforcement. The
same sandboxing system also enforces confidentiality. Since
authorization and confidentiality are most critical issues of ondemand Grid computing, we will deal with this topic in more
detail in the next section where such a sandboxing system will
be introduced.
5. Level 1 on-demand security
Current work on security issues in WSRF-based Grids focuses on the enforcement of access restrictions and protection
of message exchanges in transit. Implementations of the WSRF
specifications do not address issues concerning intra-engine service security, since providing such mechanisms is not enforced
or encouraged. Therefore, it is possible for various service implementations from different solution producers to access services and data from other solution producers and users. In level
1 on-demand Grid computing we require a system in which different solution producers and their users can work on a single
shared resource safely. Their software and data must remain
confidential and only authorized access may be granted.
Enforcing security policies in shared Grid environments is a
complex task for system administrators. In an on-demand Grid
environment, these tasks grow even more complex since the
lifetime of deployed compute jobs (and, potentially, related user
IDs) may be limited to the jobs’ run-time. Thus, administrators
neither gain sufficient experience with the expected behavior of
tasks nor are they able to rely on a fixed software configuration
of the system, since newly deployed jobs may bring new dependencies for shared libraries and third-party software along
with them.
We must now differentiate between three types of Grid applications which currently are in use in service-oriented Grid
environments. The first type is the most modern: a fully serviceoriented Grid application programmed in a secure high level
language like Java or C#. These are the easiest to deal with since
the virtual machine in which these applications run already
has strong security enforcement capabilities built in. However,
many scientific applications in Grid computing are based on
legacy code bases which cannot be ported to Java for cost and
efficiency reasons. These existing legacy solutions are usually
wrapped by a number of Java Grid service implementations
to make the different legacy components available separately
to the service-oriented Grid environment. This creates a major
security problem since the native code cannot be constrained
by the standard Java or C# security facilities. These serviceoriented applications which contain a number of legacy components make up the second type of Grid applications. Finally,
the third type of applications is a monolithic legacy application which is wrapped by a single Grid service but apart from
that has no service-oriented attributes and should be considered as a traditional Grid application. With these applications,
it is often necessary that users are able to directly access the
nodes on which the application runs. These types of Grid applications have all the security problems of the first two types
in addition to the security problems incurred by allowing direct access to the Grid nodes. In the following, we propose a
sandboxing technology to prevent shared use threats for each
of the three types of Grid application tailored to its specific
needs.
M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204 1197
5.1. Type 1 Grid applications
Type 1 Grid applications consist purely of secure programming language-based Grid services. A single Grid application
can consist of a number of different Grid services which do
not necessarily come from the same solution producer. In the
following, we will deal with Apache Axis web service engine
[2] based Grid middleware environments like GT4 [35] and
Java-based Grid services. While simply giving each solution
producer a separate Grid environment would solve the authorization and confidentiality problems, we propose a dynamic
group enabled sandboxing approach within a single Grid service hosting environment to protect Grid services from different
solution producers from each other, since both the management
and resource overhead are unnecessary at this stage.
The sandbox for Java classes within the JVM is defined by a
security manager. Based on a given policy, the security manager
controls access of Java classes to certain resources such as the
file system or network interfaces. The Java security manager
can block file system access for pure Java classes that must use
the file classes of the Java IO packages for file system access.
However, these protection mechanisms are targeted towards
defending the operating system against attacks stemming from
Java programs, not towards defending different sub-programs
within the same JVM from each other.
The threats described in Section 3 lead us to propose the following intra-engine service security requirements for Java Grid
services: a service must be able to be deployed into a private
sandbox if it does not want its classes to be accessed by other
services. Services wishing to form a group in which classes
can be shared require a secure grouping mechanism which
allows all services within the group to share classes but services outside of the group are denied access. Both mechanisms
must function in an on-demand fashion, i.e., normal operation
of the Grid node must not be disrupted. Services already running on the system must be unaffected by the introduction of
new services and new security groups.
In GT4, the intra-engine service attacks described in Section 3 are made possible by the fact that GT4 loads all Grid
services within the same class loader. The basic idea of our solution to this problem is to use the class loader hierarchy that
we have developed for hot service deployment [11] to enable
the dynamic loading and reloading of classes to also provide
intra-engine service security. In its most basic form, each Grid
service is loaded within its own class loader functioning as a
sandbox and as such its classes and resources are private and
cannot be accessed by any other service. If required, these service sandboxes can be grouped together allowing direct access
between trusted services. This ensures that services using singletons cannot be hijacked by malicious services, and foreign
code cannot be inserted into the program flow.
To enable the required secure loading process, the ClassUtils
and JavaProvider classes provided by Axis and used by GT4
needed to be modified so that Grid services are no longer loaded
by Axis, instead a disposable Grid ClassLoader intercepts the
Grid service classes and loads them in a secure environment
which cannot be accessed by other Grid services. Fig. 6 shows a
Fig. 6. Hierarchy of the ClassLoader instances.
snapshot of the complete ClassLoader hierarchy in the system,
after four different Grid services have been instantiated in two
separate security groups. Services A–C are deployed in the
same group and thus can access each others’ class definitions.
Service D is deployed in its own group and thus is protected
from direct code access by any of the other services deployed
on this node.
Through these modifications to Axis, inter-service communication is now confined to using web service calls and thus
ensures that proper authentication between services must be
observed, and the confidentiality of data and code is protected
from other solution producers and users by the sandboxes built
into the middleware. For a more detailed description of the Java
sandboxing techniques, the reader is referred to [31].
5.2. Type 2 Grid applications
Type 2 Grid applications consist of Type 1 Grid services
which also utilize native code components. As above, we will
deal with Apache Axis web service engine-based Grid middleware environments like GT4 and different sandboxing technologies which can be used to confine small native programs in a
sandbox. Our solution allows the hosting of Grid services from
different solution producers containing native code in the same
hosting environment while ensuring that they cannot damage
services belonging to other solution producers.
Our security architecture addresses countermeasures for attacks stemming from native code used in Grid or web services,
that fall into the different classes described in Section 3. The
technique used is process separation and confinement into secure sandboxes in order to allow for a flexible and fine-grained
definition of execution policies in an open multi-solution producer environment.
From an operating system perspective, all file accesses from
the JVM are performed with the user rights of the owner of the
JVM process. Child processes for native code also inherit the
user ID of the JVM process. While a fine-grained and policybased restriction of resource access is possible for pure Java
code by means of a custom security manager, this restriction
of rights is impossible for native parts of a service. The JVM
1198 M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204
Fig. 7. Decoupled process spaces for JNI attached native code, enabling
secure isolation of native code.
cannot keep the code from opening file handles with the permissions inherited from the JVM process.
Java offers two possible ways of using native code. The first
is the creation of a new child process using Runtime.exec
or ProcessBuilder.start, the second is the direct invocation of native method implementations through the Java
Native Interface (JNI) [32].
5.2.1. Confinement of JNI bound implementations
The JNI specification defines the interface between the JVM
and native methods implemented in C/C + +. It enables invocation of native method implementations from Java classes and
callbacks to Java methods from the native code.
The JNI is organized like a C + + virtual function table. It
is passed by reference to the native implementation and managed by the JVM per thread (i.e. a native method may be invoked from different threads and therefore receive different
JNI pointers, invocations from the same thread are guaranteed
to pass along the same pointer). The structure itself contains
a reference to an array of function pointers to implementations of the JNI methods. Besides passing an invocation result
with return, the native method must use those JNI functions
for access to any method or field in Java classes and objects
managed by the JVM. The native methods are compiled into
shared libraries and Java code using native implementations
loads those shared libraries using System.loadLibrary.
Native code is then executed in the process space of the JVM
which leads to the serious threats described before. The native
code cannot be further constrained on a fine-grained per-service
level, only confinement based on the JVM process owner is
possible.
As a solution to this problem we propose the decoupling of
the process spaces by using an automatically generated transparent proxy intercepting all calls to the native implementation,
as shown in Fig. 7. The native component of the service is replaced by a generated proxy that exposes exactly the interface
of the original component. This proxy now receives all the calls
to the native methods from the JVM. Such a call is passed on
to the original native implementation that is instantiated in a
sandboxed process outside of the JVM process.
The process server acts like the JVM to the native method
implementations, it passes a reference to an altered JNI implementation to the original native code. Every reference to the
JVM from the original native code is thereby intercepted by
the custom JNI implementation. The transparent proxy and the
process server communicate by means of standard IPC or RPC
mechanisms, depending on the security and functionality requirements.
5.2.2. Native service sandboxes
A number of different fine-grained sandboxing solutions to
secure the native part of services (i.e. enforcement of access
restrictions to the host operating system and isolation of processes against each other) can be used in our architecture. A balanced decision needs to be made between the cost (i.e. instance
creation time, computational overhead, increased resource consumption) incurred and the strength of security offered by the
chosen method. We will now briefly discuss three different techniques for the fine-grained native code isolation which can be
used for type 2 Grid applications.
Changing the effective user ID of the native process provides
security based on standard file and resource access control of the
operating system. While this method requires no preparation of
the sandbox and imposes virtually no performance overhead, it
offers only very limited security against exploitable weaknesses
in the operating system. A further downside of this approach is
the need for a pool of user accounts that processes are mapped
to by the sandbox manager.
BSD jails are a way to partition a BSD environment into
isolation areas. The jail system call has been developed to
explicitly counter well-known techniques to escape a similar
chroot environment. The overhead created by running a process in a jail is very low. Jailed processes are tagged to belong to a certain jail, the system enforces security by identifying this tag for certain privileged operations, resulting in a
very small overhead for only those calls limited by the jail
environment.
Systrace [22] offers even more fine-grained policy enforcement over processes running under control of systrace. It has
become a very popular tool for privilege control for a number
of BSD variants. It uses system call interposition to enforce security policies for processes run under the control of systrace.
Systrace is implemented in two parts, an addition to the kernel
that intercepts system calls, comparing them to a kernel level
policy map, disabling the call if a negative entry or no entry
at all is present. The kernel level implementation is assisted by
a user-level part that reads and interprets policy specifications
to hand them to the kernel level policy map, report policy enforcement decisions to the user applications and even call GUI
applications for interactive generation of policies. We experienced acceptable performance overhead with a Linux port of
systrace. For a first prototypical implementation of the system,
we employ a combination of chroot and an extended implementation of systrace as they offer the best balance between
overhead and gained level of security. Shared objects and libraries they depend on are either copied or mapped by hard
linking into the system and can be protected by using systrace
to intercept write attempts on the libraries. The (small) memory
overhead is limited to the process and sandbox management
components.
M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204 1199
Using one of the above sandboxing techniques is one way of
protecting services from a solution producer containing native
code from attacks by other solution producers within the same
web service engine. The native part of a service which is sandboxed is linked to the Java part of the service via a transparent proxy, allowing solution producers to deploy their services
without modification into a sandboxed environment.
5.3. Type 3 Grid applications
Unlike type 2 Grid applications which consist of a number
of different native components that are wrapped by a number of Java Grid services interacting with each other, type 3
applications are heavy-weight monolithic constructs which cannot simply be deployed into the service-oriented Grid middleware but must be installed in the underlying operating system.
While the fine-grained service-based sandboxing described in
the previous section can be applied to type 3 Grid applications,
a more coarse-grained sandboxing approach with less configuration requirements is better suited in this case.
A coarse-grained solution for sharing compute resources
on a single physical machine is to use an operating system
virtualization architecture. Next to commercial solutions like
VMware GSX Server and Microsoft Virtual PC, Xen and
OpenVZ [3,33] are free and open source virtualization systems.
Using operating system virtualization, each solution producer
and his users get their own virtual operating system in which
the solution producers software runs completely separated
from other solution producers and their users by the virtual
operating system boundaries. In the following, we will use Xen
as the example virtualization technology for type 3 application
sandboxing.
The resource provider takes care of setting up the physical hardware running the applications. On these systems, the
provider installs the Xen hypervisor software along with a Xen0
(host) Linux instance that is responsible for creating, controlling and destroying the XenU (virtual OS) instances that are to
be deployed on demand. The solution producer creates a Linux
image containing his software and data including all third party
dependencies. This entire image is then deployed onto the resource provider’s node and started as a XenU virtual system.
The JNI proxy method described for type 2 applications can
then be used to access the Grid application by the service wrapping the type 3 application. A further advantage of operating
system virtualization is that solution producers and users can
access the entire system and interact in a traditional manner
outside of the Grid middleware using some remote management system like a remote SSH login. This is extremely useful for large scale legacy applications which need to be ported
into the Grid slowly, allowing solution producers and users direct access to those parts of the application which have not yet
been fully wrapped by Grid services. Through the virtualization of the entire operating system, the solution producers and
users can operate freely within their sandbox without endangering the confidentially of other solution producers’ software
and data.
Fig. 8. Sandbox overview.
Using operating system sandboxing techniques is one way
of protecting large legacy applications of a solution producer
from attacks by other solution producers on a single physical
resource. The native part of an application which is sandboxed is
linked to the Java Grid service via a transparent proxy, allowing
solution producers to deploy their services without modification
into a sandboxed environment. For more information on the
Xen sandboxing techniques please refer to [29].
5.4. Summary of level 1 on-demand security
Using the sandboxing techniques described above, types
1–3 Grid applications can be protected from attacks from other
solution producers and users, without limiting the functionality
of the program or requiring the software to be redesigned. Fig.
8 shows the overview of the different Sandbox techniques and
how they are tied into the Grid environment. Level 1 security
only deals with the threats posed between different solution
producers and users. The resource provider and the middleware producer are trusted entities. This is the first step towards
on-demand Grid computing which offers the needed additional
security for solution producers and users if they are to trust
a shared use environment. The usage model for the resource
provider has not been changed, yet making it easy for them to
adopt on-demand Grid computing.
6. Level 2 on-demand security
In level 1 on-demand Grid computing we require a system
in which different solution producers and their users can work
on a single shared resource safely. One of the major requirements of on-demand computing is that solution producers have
the necessary administrative rights to install their solutions autonomously since the turnaround time of installation where the
resource provider needs involved are too high for on-demand
usage. This requires security mechanisms to be in place to pro-
1200 M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204
tect the resource provider from the privilege class of threats
posed by malicious or erroneous solution producers. Furthermore, the security mechanisms in place for level 1 security are
controlled by the middleware which in level 1 is considered
trusted and safe. In level 2, threats stemming from security
holes in the middleware system are also considered. This section is divided into two subsections, each dealing with one of
the two new requirements.
6.1. Resource provider protection
Up to now, solution producers did not have management access to the resource provider’s node and as such the resource
provider can protect his resources from them using security
mechanism used to protect against users in standard multiuser systems. However, the installation of the solution producers’ software required the resource provider to grant temporary
rights or do the process on behalf of the solution producer.
This hampers the adoption of on-demand computing since it
creates a management bottleneck at the resource provider. A
security mechanism is needed by which solution producers can
be granted administrative rights while at the same time assuring the safety of the resource providers’ and the other solution
producers’ and users’ assets. With some additional configuration work, the sandboxing techniques introduced in level 1 to
protect solution producers and users from each other can also
be used to protect the resource provider from the solution producers.
Type 1 applications are the easiest to protect against since
the Java Virtual Machine in which the Grid services run has
built-in security mechanisms which can be configured to protect
the resource provider from the solution producers’ services.
The secure management service described in [31] is used to
make sure that deployment operations from different solution
producers do not affect each other and sandbox consistency is
maintained.
Type 2 applications consist of service bundles containing
legacy code. The deployment process is the same as for type 1
applications, but the configuration of the native service sandboxes must be performed, as well as the configuration of the
JVM sandbox. For more information on the complexity of
this process, the reader is referred to the sandbox taxonomy in
Section 8.
Type 3 applications are the most challenging since large
legacy application which need complex third party libraries cannot simply be deployed via a service-oriented middleware but
must be installed into the underlying operating system. The OS
sandboxing technique offers a simple and elegant solution to
this problem. Since the solution producer provides a complete
operating system installation along with all required shared libraries, third-party-software, etc. it is no longer necessary for
them to have administrative access to the host system, only
to their private virtual OS. This greatly reduces compatibility
and dependency problems when running Grid applications and
provides the solution producers with full root access for configuration and control of the instance, albeit restricted to their
virtual environment.
Thus, using a virtualization solution implies that many configuration and administration tasks are shifted from the resource
provider to the solution producer. This, in turn, can in many
cases prove to be a win–win-situation: on the one hand, administrators now only have to provide systems running Xen
along with a Xen0 controlling OS instance and network connectivity for the XenU nodes, usually tightly controlled by
a firewalling or packet filtering solution. This allows the resource provider to protect his resources while at the same time
reducing his management burden. Solution producers, on the
other hand, can now provide a complete system environment
in which they have administrative privileges without having to
find destination systems in the Grid that provide exactly the
required software infrastructure. Solution producers now only
have to care about finding a Xen-enabled system with a specific type of CPU and sufficient amounts of main memory and
disk space in order to run their jobs. When we consider Grid
users who do not intend to develop solutions on their own, providing complete OS instances also allows solution producers
to deliver a completely autonomous system installation along
with their specific application without any additionally incurred
cost for operating system licenses. In this case, the on-demand
Grid user simply has to supply the required input data to be
processed.
6.2. Grid integration and middleware trust
Depending on the application and security requirements,
there are different strategies of integrating the sandboxes into
the overall system. The first strategy is the one used in level
1. A full GT4 installation with all management services and
native add-ons is installed in the host operating system from
which the sandboxes are controlled (see Fig. 9(a)). While this
approach allows all the management functionality (including
Virtual Organization (VO) management) of the service-oriented
Grid to be utilized to find, configure and use the sandboxed applications, it also entails that the sandbox strength irrespective
of the chosen technique is only as strong as the security of the
middleware, since if a security flaw in the middleware can be
used to gain access to the hosting environment, the sandboxes
can be controlled and accessed from there. A second problem
is that the decoupling of the native components of the solution
producers’ application from the services into the sandbox is
only transparent for JNI calls in the WS Core of Globus. Any
legacy application directly utilizing native components of GT4
will not function, since the sandbox does not permit access to
the GT4 components lying in the hosting OS.
To decrease the risk posed by security holes in the middleware and allow existing legacy application to continue using
native components of the middleware, the second integration
strategy can be utilized (see Fig. 9(b)). Here, only a minimal
Java core of the middleware is installed in the host environment. Each OS sandbox gets its own instance of the full blown
middleware allowing the native application to directly access
the full middleware. All security problems of the native components of the middleware are sandboxed and cannot be used
to attack other solution producers or the resource provider. The
M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204 1201
Fig. 9. Sandbox integration: (a) full integration, (b) legacy integration and (c) secure integration.
drawback of the second strategy is that for each solution producer, a new instance of the Grid middleware must be started
and managed while still hosting a slim middleware with security risks on the host OS.
To further decrease the risk of middleware security flaws, the
third integration strategy introduces a slim management interface which does nothing but manage the sandboxes in which for
each solution producer a separate Grid middleware instance is
run (see Fig. 9(c)). Unlike the big open source Grid middleware
projects, a slim sandbox management solution could undergo
a security audit proving the security of the solution. However,
the benefits of the Grid middleware and VO management software cannot be utilized until the sandboxes have been found
and configured, creating an additional level of complexity for
the Grid workflow.
6.3. Summary of level 2 on-demand security
Using the sandboxing techniques described above, the resource provider can be protected from types 1–3 Grid applications, while at the same time reducing his management burden.
The security offered by sandboxing solution producers can help
resource provider overcome the emotional hurdle of granting
outsiders a certain amount of administrative rights on their system. Since the resource providers are in control of the sandboxes, they remain in final control while still enabling the next
level of on-demand computing.
The decision which integration strategy is used must be based
on the amount of trust placed in the security of the middleware
and the application requirements on a case-by-case basis. Thus,
no general recommendation can be made.
7. Level 3 on-demand security
The step from level 2 to level 3 on-demand Grid computing
sees the removal of the trust relationship from the user and solution producer towards the resource provider (see Section 2).
This entails that the solution producer and user must be able to
remotely check the integrity of the remote system to ensure that
the solution producer’s software has not been modified and the
data are stored securely. It should be noted here that it is impossible to fully secure a remote system under foreign administrative control, since as the last instance the remote administrator
can unhook the system during operation and then perform any
number of attacks against both software and hardware security
protocols off-line. Given enough time and resources, it is possible to break any encryption which protects the data. Therefore, the goal of level 3 on-demand security is to make the time
and effort so prohibitive that it is no longer a relevant threat to
the solution producers and users. One way to make hacking a
system more complex is to implement the security measures in
hardware, since it is much harder for most attackers to create
workarounds in hardware than it is for them to work around
software security systems. This introduces a new entity to the
trust model: the TPM Producer. Since the security hardware is
used to offer essential security features for level 3 on-demand
computing, it is necessary that users, producers and providers
trust the hardware provider that the security hardware does
what it is supposed to. However, since there are only very few
hardware producers compared to the number of other actors in
the on-demand world, it is possible to build a trust relationship
to the hardware providers, either by reputation 1 or hardware
audit. The Trusted Computing Platform Alliance (TCPA) has
produced open specifications for a security chip (TPM) and related software interfaces which is such a hardware-based security system. In [24], the functionality of the TPM chip is introduced. The chip offers hardware-based public key management
and boot-time system integrity checks. Furthermore, it allows
run-time integrity checking of applications loaded in the TPM
secured OS.
Currently, IBM offers a TPM-enabled Linux [13] as a workin-progress release and not all features of the TPM 1.2 specification are implemented and stable. Nevertheless, we believe
that such a technology is an interesting way of enabling level
3 on-demand security. Apart from the secure boot process, the
1 Security hardware producers are usually large well-known firms such as
Intel, AMD, IBM, etc.
1202 M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204
IBM TPM Linux offers three security modules (Extended Verification Module (EVM), SLIM and IMA) which are of interest
for level 3 security.
After the secure boot operation, the unmodified TPM secured
operating system is up and running. Next, the EVM which
is part of the operating system can be used to check if an
application which is to be loaded has been modified in a similar fashion as the boot modification checks. The EVM module verifies that all files are authentic, unmodified, current, and
not known to be malicious. EVM does not (and cannot) determine if files are correct—that is, that given any (possibly
malicious) input data, they will operate properly. The Simple
Linux Integrity Module (SLIM) deals with this issue, but since
each solution producer operates within his or her own XenU,
any weaknesses within the unmodified application are his or
her concern alone and need not be checked by the resource
provider. However, it does help the solution producer to ensure
that their software conforms to the requirements of the resource
provider.
The Trusted Computing Architecture (TCA) facilitates remote attestation with which the status of the remote operating system and application hosted within can be checked.
The Integrity Measurement Architecture (IMA) extends the
TPM-based attestation into the system run-time, the EVM provides the measurement and the SLIM identifies all executables (programs, scripts) and all system level integrity objects
(config files). It attests the software stack and adjusts protected
hardware storage slots to maintain measurement list integrity
values.
Using this remote attestation facility, it is possible for
solution producers and users to remotely check if resource
providers’ system meets their security requirements. Possible requirements are that software is stored only in encrypted form and is only decrypted into memory when it is
being executed to reduce the risk of the resource provider
stealing the software. Using TCP-enabled network devices,
it will be possible to securely transfer the keys needed to
run an encrypted application directly from one TPM to
another. This gives the solution producer added security
since the TPM chip would have to be hacked by the resource provider to illegally gain access to their software or
data. For more information on this, the reader is referred to
[25].
7.1. Summary of level 3 on-demand security
While the remote attestation feature of TPM-enabled operating systems does not create absolute security for the
solution producers and users, it makes it extremely difficult
for the resource provider to tamper with their software and
data, thus decreasing the need for the solution producers
and users to trust the resource providers. The full capability of TPM hardware security is still unknown since the
product is in an early phase of development. However the
potential for securing untrusted resources is very high and
should be followed closely to fully enable on-demand Grid
computing.
8. Taxonomy
The sandboxing technologies and integration techniques
described in Sections 5 and 6 offer possible ways of securing different Grid applications. In this section, a brief high
level taxonomy will be presented to aid in the decision making process when a sandboxing method needs to be chosen.
Each of the four technologies is evaluated based on the following attributes (see Figs. 10(a)–(d)): user protection—the
level of protection between users and solution producers; system protection—the level of protection for the system against
users and solution producers; acceptance/trust—the subjective
level of acceptance and trust in the technology as gathered
by us in the D-Grid Initiative [4]; Grid integration—how well
can the sandbox be tied into the service-oriented middleware
and link to separate services; as well as I/O efficiency, memory efficiency and computational efficiency. The last three
are based on a combination of our own measurements using
small test programs, engineering applications from the D-Grid
initiative and measurements made in [15,3,6,27]. The value
of each attribute increases from the center to the outside of
the corresponding axis. We differentiate between three types
of sandbox configuration: out-of-the-box, secure configuration and integrated configuration. The first shows the level
of protection and Grid integration which is offered by the
sandbox out-of-the-box. The second shows the level of protection which can be achieved if the sandbox is specifically
configured for the on-demand Grid by an expert. The relative
amount of configuration needed to achieve these results can
be read of the configuration axis. The third shows the amount
of configuration needed to achieve full integration with the
Grid middleware and reflects the work we needed to put in
to implement the integration techniques described in Sections
5 and 6. Since the performance of the different sandboxes is
extremely application specific, this taxonomy should be seen
as a rough guide to help in the decision process.
Since the TPM technology is still in an early phase, no fair
taxonomy can be published. The software needed to access the
TPM functionality is in an alpha state and as such requires a
lot of configuration. Furthermore, the software has not been
optimized yet (it currently takes roughly 20 min to boot a TPM
secured Linux). An evaluation of TPM performance should be
seen as future work.
9. Conclusions
In this paper, we presented an analysis of threats existing
within a shared environment for service-oriented on-demand
Grid computing. Our analysis addressed three different levels of
on-demand Grid computing, based on the number of resource
providers, middleware producers, solution producers and users,
as well as the trust relationships between them. Three types
of Grid applications currently used in service-oriented Grid
environments were distinguished. It was shown in which ways
the security threats for the three application types in the three
different levels can be handled by constructing a set of solutions
that enable security in increasingly demanding levels. While the
M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204 1203
Fig. 10. Sandbox taxonomy: (a) Unix accounts, (b) Java service sandboxes, (c) native service sandboxes and (d) operating systems sandboxes.
first two levels can be tackled by a sandboxing approach based
on Java, JNI jailing or the Xen hypervisor system, handling
the third level requires hardware security mechanisms based on
TCPA technology.
There are several issues for future work. For example, a more
extensive analysis of the performance characteristics of the presented solutions for the three levels in the context of real-world
applications would shed some light on the overhead associated
with the different solutions. Furthermore, an evaluation of the
interplay of the security architecture with other Grid software
development issues, such as the build and deployment process
or VO management, would be an interesting area of further
research.
References
[1] R. Alfieri, R. Cecchini, V. Ciaschini, L. dell’Agnello, Á. Frohner, A.
Gianoli, K. Lörentey, F. Spataro, VOMS, an authorization system for
virtual organizations, in: Proceedings of the European Across Grids
Conference, Lecture Notes in Computer Science, vol. 2970, Santiago de
Compostela, Spain, Springer, Berlin, 2003, pp. 33–40.
[2] Apache Software Foundation, Apache Web Services Project, 2004,
http://ws.apache.org/axis/.
[3] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho, R.
Neugebauer, I. Pratt, A. Warfield, Xen and the art of virtualization,
in: Proceedings of the ACM Symposium on Operating Systems
Principles (SOSP), Bolton Landing, USA, ACM Press, New York, 2003,
pp. 164–177.
[4] BMBF, D-Grid, 2006, http://www.d-grid.de/.
[5] D.W. Chadwick, A. Otenko, E. Ball, Role-based access control with
X.509 attribute certificates, IEEE Internet Comput. 7 (2) (2003) 62–69.
[6] B. Clark, T. Deshane, E. Dow, S. Evanchik, M. Finlayson, J. Herne,
J.N. Matthews, Xen and the art of repeated research, in: Proceedings of
the USENIX 2004 Annual Technical Conference, 2004, pp. 135–144.
[7] Computer Security Institute, CSI/FBI Computer Crime and Security
Survey, 2004.
[8] C.C. Corp, http://www.cryptocard.com.
[9] I. Foster, D. Berry, A. Djaoui, A. Grimshaw, B. Horn, H. Kishimoto, F.
Maciel, A. Savvy, F. Siebenlist, R. Subramaniam, J. Treadwell, J. von
Reich, The Open Grid Services Architecture, Version 1.0, 2004, https://
forge.gridforum.org/projects/ogsa-wg/document/draft-ggf-ogsa-spec/en/.
[10] I. Foster, C. Kesselman, J. Nick, S. Tuecke, The physiology of the grid:
an open grid services architecture for distributed systems integration, in:
Open Grid Service Infrastructure WG, Global Grid Forum, 2002.
[11] T. Friese, M. Smith, B. Freisleben, Hot service deployment in an ad hoc
grid environment, in: Proceedings of the Second International Conference
on Service Oriented Computing, ACM Press, New York, USA, 2004,
pp. 75–83.
1204 M. Smith et al. / J. Parallel Distrib. Comput. 66 (2006) 1189 – 1204
[12] IBM, E-business on demand: the race is on Whitepaper, 2003,
http://www-5.ibm.com/e-business/de/literature/.
[13] IBM Watson Research—Global Security Analysis Lab, TCPA Resources,
http://www.research.ibm.com/gsal/tcpa/.
[14] ITSS, Multiple Unix compromises on campus—stanford ITSS security
alert, 2004.
[15] K. Keahey, K. Doering, I. Foster, From sandbox to playground: dynamic
virtual environments in the grid, in: Fifth International Workshop on
Grid Computing (Grid 2004), 2004.
[16] B. Krebs, Hackers strike advanced computing networks, Washington
Post, 2004.
[17] M. Myers, et al., RFC2560: X.509 Internet Public Key Infrastructure
Online Certificate Status Protocol (OCSP), http://www.ietf.org/rfc/
rfc2560.txt.
[18] J. Novotny, S. Tuecke, V. Welch, An online credential repository for
the grid: MyProxy, in: Proceedings of the 10th IEEE International
Symposium on High Performance Distributed Computing, 2001,
pp. 104–111.
[19] OASIS, Web Services Resource Framework, 2004, http://www.
oasis-open.org/committees/tc_home.php?wg_abbrev=wsrf.
[20] L. Pearlman, V. Welch, I. Foster, C. Kesselman, S. Tuecke, A community
authorization service for group collaboration, in: Proceedings of the
IEEE Third International Workshop on Policies for Distributed Systems
and Networks, Monterey, USA, IEEE Computer Society, Silver Spring,
MD, 2003, pp. 50–59.
[21] M. Pourzandi, D. Gordon, W. Yurcik, G. Koenig, Clusters and security:
distributed security for distributed systems, in: Cluster Security Workshop
at the Fifth IEEE/ACM International Symposium on Cluster Computing
and the Grid (CCGrid), 2005.
[22] N. Provos, Improving host security with system call policies, in:
Proceedings of the 12th USENIX Security Symposium, Washington,
USA, 2003, pp. 257–272.
[23] D. Safford, The need for TCPA, Whitepaper, IBM Research, 2002.
[24] D. Safford, M. Zohar, A Trusted Linux Client (TLC), IBM Research,
2005.
[25] D. Safford, M. Zohar, A. Boulanger, Trusted computing for Linux, IBM
Research, 2005.
[26] SANS Institute, The twenty most critical internet security vulnerabilities,
November 2005, http://www.sans.org/top20/.
[27] S. Santhanam, P. Elango, A. Arpaci-Dusseau, M. Livny, Deploying virtual
machines as sandboxes for the grid, in: Second Workshop on Real, Large
Distributed Systems, 2005, p. 712.
[28] SecureID, http://www.ctrl-key.co.uk/index.htm.
[29] M. Smith, T. Friese, M. Engel, B. Freisleben, G. Koenig, W. Yurcik,
Security issues in on-demand grid and cluster computing, in: 2nd
International Workshop on Cluster Security (in conjunction with the 6th
IEEE International Symposium on Cluster Computing and the Grid);
May 2006.
[30] M. Smith, T. Friese, B. Freisleben, Towards a service-oriented ad hoc
grid, in: Proceedings of the Third International Symposium on Parallel
and Distributed Computing, Cork, Ireland, IEEE Press, New York, 2004,
pp. 201–208.
[31] M. Smith, T. Friese, B. Freisleben, Intra-engine service security for
grids based on WSRF, in: Proceedings of Cluster Computing and Grid,
Cardiff, UK, 2005, pp. 644–653.
[32] Sun Microsystems, Inc., Java Native Interface Specification, 2003.
[33] SWsoft, OpenVZ, 2006, http://openvz.org/.
[34] The EGEE Project, Global security architecture, EU deliverable
DJRA3.1, 2004.
[35] The Globus Project, The Globus Toolkit 4.0 (GT Version 3.9.3), 2004,
http://www-unix.globus.org/toolkit/downloads/development/.
[36] The Globus Project, The Globus Toolkit 4, 2004, http://www.globus.
org/toolkit/.
[37] W. Yurcik, G.A. Koenig, X. Meng, J. Greenseid, Cluster security as
a unique problem with emergent properties: issues and techniques, in:
Proceedings of the Fifth LCI International Conference on Linux Clusters,
2004.
[38] W. Yurcik, C. Liu, A first step toward detecting SSH identity theft in HPC
cluster environments: discriminating masqueraders based on command
behavior, in: Cluster Security Workshop at the Fifth IEEE/ACM
International Symposium on Cluster Computing and the Grid (CCGrid),
2005.
Matthew Smith is a full-time research and
teaching assistant in the Department of Mathematics and Computer Science at the University
of Marburg, Germany. He received his diploma
(M.Sc.) degree in computer science in 2003
from the University of Siegen, Germany. As of
2006, he is part of the Grid Computer Emergency Response Team (Grid CERT) of the German D-Grid Initiative. His research interests include distributed systems, cluster/network/Grid
computing and wireless ad hoc networks. Currently, he is pursuing his Ph.D. with a focus
on security for on-demand service-oriented Grid
computing.
Thomas Friese is a full-time research and teaching assistant in the Department of Mathematics and Computer Science at the University of
Marburg, Germany. He received his diploma
(M.Sc.) degree in computer Science in 2002
from the University of Marburg, Germany. He
participated in several research projects in cooperation with the research division of Siemens
AG, Corporate Technology, Munich, Germany.
His main research interests are peer-to-peer networks and service-oriented Grid computing, and
he currently is pursuing his Ph.D. with a focus
on service-oriented ad hoc Grid computing.
Michael Engel currently is a visiting professor for computer science at Chemnitz Technical
University, Germany. He received his diploma
(M.Sc.) degree in computer science in 2002
from the University of Siegen, Germany and his
Ph.D. degree from the University of Marburg,
Germany, in 2005. His current research interests are in applying modern software development methodologies to operating system code,
virtualized architectures and operating system
introspection.
Bernd Freisleben is a full professor of computer science in the Department of Mathematics
and Computer Science at the University of Marburg, Germany. He received his M.Sc. degree in
computer science from the Pennsylvania State
University, USA, in 1981, and his Ph.D. degree
in computer science from the Darmstadt University of Technology, Germany, in 1985. His research interests include distributed/parallel systems, cluster/network/Grid computing, and middleware for internet application development.

Computers 2014, 3, 1-35; doi:10.3390/computers3010001
computers
ISSN 2073-431X
www.mdpi.com/journal/computers
Article
Cloud Computing Security: A Survey
Issa M. Khalil 1,*, Abdallah Khreishah 2 and Muhammad Azeem 3
1
 Qatar Computing Research Institute (QCRI), Qatar Foundation, Doha, Qatar;
E-Mail: ikhalil@uaeu.ac.ae
2
 Department of Electrical and Computer Engineering, Newark College of Engineering, New Jersey
Institute of Technology, University Heights, Newark, NJ 07102, USA; E-Mail: abdallah@njit.edu
3
 College of Information Technology, United Arab Emirates University, PO Box 15551, Al Ain,
United Arab Emirates; E-Mail: azeemsamma@hotmail.com
* Author to whom correspondence should be addressed; E-Mail: issa.khalil@yahoo.com.
Received: 5 September 2013; in revised form: 14 November 2013 / Accepted: 27 January 2014 /
Published: 3 February 2014
Abstract: Cloud computing is an emerging technology paradigm that migrates current
technological and computing concepts into utility-like solutions similar to electricity and
water systems. Clouds bring out a wide range of benefits including configurable computing
resources, economic savings, and service flexibility. However, security and privacy concerns
are shown to be the primary obstacles to a wide adoption of clouds. The new concepts that
clouds introduce, such as multi-tenancy, resource sharing and outsourcing, create new
challenges to the security community. Addressing these challenges requires, in addition to
the ability to cultivate and tune the security measures developed for traditional computing
systems, proposing new security policies, models, and protocols to address the unique cloud
security challenges. In this work, we provide a comprehensive study of cloud computing
security and privacy concerns. We identify cloud vulnerabilities, classify known security
threats and attacks, and present the state-of-the-art practices to control the vulnerabilities,
neutralize the threats, and calibrate the attacks. Additionally, we investigate and identify the
limitations of the current solutions and provide insights of the future security perspectives.
Finally, we provide a cloud security framework in which we present the various lines of
defense and identify the dependency levels among them. We identify 28 cloud security
threats which we classify into five categories. We also present nine general cloud attacks
along with various attack incidents, and provide effectiveness analysis of the proposed
countermeasures.
OPEN ACCESS
Computers 2014, 3 2
Keywords: cloud computing; cloud security; security vulnerabilities; threats; attacks;
insider attackers
1. Introduction
Cloud computing provides a centralized pool of configurable computing resources and computing
outsourcing mechanisms that enable different computing services to different people in a way similar to
utility-based systems such as electricity, water, and sewage. In electricity, for example, people started to
connect with central grids, supported by power utilities rather than relying on their own electricity
production capabilities. This migration is beneficial in reducing the cost and time of production and in
providing better performance and reliability [1]. Similarly, clouds provide their customers with high
performance and more reliable computing services such as e-mail, instant messaging, and web services
at a lower cost.
Cloud computing does not have a common accepted definition yet [2]. The National Institute of
Standards and Technology (NIST) [3] defined five essential characteristics of cloud computing, namely:
on-demand self-service, broad network access, resource pooling, rapid elasticity or expansion, and
measured service. Also, cloud computing is described as a dynamic and often easily extended platform
to provide transparent virtualized resources to users through the Internet [4]. Cloud computing
architecture consists of three layers: (i) Software as a service (SaaS); (ii) Platform as a service (PaaS)
and (iii) Infrastructure as a service (IaaS) [5]. The clouds are also viewed as five component architectures
that comprise clients, applications, platforms, infrastructure and servers [6]. The current clouds are
deployed in one of four deployment models: (a) public clouds in which the physical infrastructure is
owned and managed by the service provider; (b) community clouds in which the physical infrastructure
is owned and managed by a consortium of organizations; (c) private clouds in which the infrastructure
is owned and managed by a specific organization and (d) hybrid clouds which include combinations of
the previous three models [7]. Figure 1 shows cloud deployment models together with their internal
infrastructure (IaaS, PaaS and SaaS). Cloud deployment models have similar internal infrastructure, but
vary in their policies and user-access levels.
Clouds bring out tremendous benefits for both individuals and enterprises. Clouds support economic
savings, outsourcing mechanisms, resource sharing, any-where any-time accessibility, on-demand
scalability, and service flexibility. Clouds minimize the need for user involvement by masking technical
details such as software upgrades, licenses, and maintenance from its customers. Clouds could also offer
better security advantages over individual server deployments. Since a cloud aggregates resources, cloud
providers charter expert security personnel while typical companies could be limited with a network
administrator who might not be well versed in cyber security issues. Similarly, clouds are more resilient
to Distributed Denial of Service (DDoS) attacks due to the availability of resources and the elasticity of
the architecture. The clouds support mobile computations where Virtual Machines (VMs) migrate from
one physical machine to another. In addition to alleviating dedicated DDoS attacks,
mobile computations help to avoid settings in which a single administrator has exclusive control over
the computation.
 
Computers 2014, 3 3
Figure 1. Cloud deployment models and infrastructure.
The new concepts introduced by the clouds, such as computation outsourcing, resource sharing, and
external data warehousing, increase the security and privacy concerns and create new security
challenges. Moreover, the large scale of the clouds, the proliferation of mobile access devices (e.g.,
smartphones and tablets), and the direct access to cloud infrastructure amplify cloud vulnerabilities and
threats. As clouds become more and more popular, security concerns grow bigger and bigger as they
become more attractive attack targets due to the concentration of digital assets.
Many researchers and practitioners work on identifying cloud threats, vulnerabilities, attacks, and
other security and privacy issues, in addition to providing countermeasures in the form of frameworks,
strategies, recommendations, and service oriented architectures (e.g., [2,8–13]). Additionally, efforts in
other domains such as ad hoc networks have been tuned to address the emerging security problems
in the clouds (e.g., [14-18]). Many researchers (e.g., [1,19–25]) have addressed single attributes of
cloud computing security such as data integrity, authentication vulnerabilities, auditing, etc. Others
(e.g., [3,22–27]) provide surveys that cover specific areas of cloud security concerns and proposed
solutions. In [3,27], the authors briefly and broadly discuss cloud security issues involving data,
applications and virtualization. The authors in [22] discuss similar cloud security issues but with deeper
investigations. In [23,25], the authors present surveys on cloud security requirements such as
confidentiality, integrity, transparency, availability, accountability, and assurance. In [24], the authors
present a survey on the different security issues of the service delivery models of the clouds. In [26], the
authors discuss the security challenges specific to the public clouds. In [28], Hashizume et al. classify
the security issues in the cloud based on the SPI (SaaS, PaaS, IaaS) cloud infrastructure and services
model. The authors provide deeper classification of the fourth category (C4) in our classification model
(Section 2). Additionally, the authors explain fundamental security concepts including vulnerabilities,
threats, and attacks and provide mapping among these concepts. Our work provides a higher classification
level and assumes prior knowledge of the fundamental security concepts. In [29], Zissis et al. evaluate
cloud security requirements. They propose a Trusted Third Party solution that calls upon cryptography
to ensure the authentication, integrity and confidentiality of data and communications. In [30], 
Computers 2014, 3 4
Whaiduzzaman et al. present key management and broad aspects of privacy and security issues in the
domain of vehicular cloud computing.
To successfully address the cloud security issues, we need to understand the compound security
challenges in a holistic way. Specifically, we need to: (i) investigate various cloud security attributes
including vulnerabilities, threats, risks, and attack models; (ii) identify the security requirements
including confidentiality, integrity, availability, transparency, etc.; (iii) identify the involved parties
(clients, service provides, outsiders, insiders) and the role of each party in the attack-defense cycle; and
(iv) understand the impact of security on various cloud deployment models (public, community, private,
hybrid). The main contribution of this paper is that it provides a holistic study of the security issues in
the clouds that cover almost all the cloud components (data centers, computing infrastructure, interfacing
and networking, etc.), network layers (application, transportation, IP, etc.), and cloud stakeholders
(providers, consumers, third party contractors, etc.). In this paper, we provide a comprehensive survey
on the cloud security and privacy concerns that includes: (i) cloud computing security issues
(vulnerabilities, threats, and attacks); (ii) attack classifications; (iii) relations and dependencies among
attacks; (iv) known attacks; (v) comparative analysis of some of well-known countermeasures;
(vi) insights from the current security solutions to identify and address unattended security challenges.
This paper is organized as follows. In Section 0, we describe cloud security categories, issues and
dependencies. We present some of the well-known attacks and countermeasures in Section 0. In Section
0, we present the findings of comparative evaluation of some well-known general cloud computing
solutions. Further discussion on cloud security issues is presented in Section 0. In Section 0, we conclude
the paper.
2. Cloud Security Categories, Issues and Dependencies
As part of this work, we have conducted a survey on the current cloud security issues and the stateof-the-art security solutions. We identify 28 security issues (Table 2) that we categorize into
five classes (Table 1). We have also provided a comparative analysis of the current security solutions
and the state-of-the-art countermeasures.
2.1. Categories and Issues
We classify cloud computing security related issues into the following five categories, which are also
summarized in Table 1. A similar approach to classify the issues is found in [19] but it is limited to small
set of cloud security concerns and only partially covers four categories.
(C1) The Security Standards category deals with regulatory authorities and governing bodies that
define cloud security policies to ensure secure working environment over the clouds. It includes
service level agreements, auditing and other agreements among users, service provider and
other stakeholders.
(C2) The Network category refers to the medium through which the users connect to cloud
infrastructure to perform the desired computations. It includes browsers, network connections
and information exchange through registration. 
Computers 2014, 3 5
(C3) The Access Control category is a user-oriented category and includes identification,
authentication and authorization issues.
(C4) The Cloud Infrastructure category includes security issues within SaaS, PaaS and IaaS and is
particularly related with virtualization environment.
(C5) The Data category covers data integrity and confidentiality issues.
Table 1. Cloud Security Categories.
No. Category Description
C1 Security
Standards
Describes the standards required to take precaution measures in cloud
computing in order to prevent attacks. It governs the policies of cloud
computing for security without compromising reliability and performance.
C2 Network Involves network attacks such as Connection Availability, Denial of Service
(DoS), DDoS, flooding attack, internet protocol vulnerabilities, etc.
C3 Access Control Covers authentication and access control. It captures issues that affect privacy
of user information and data storage.
C4 Cloud
Infrastructure
Covers attacks that are specific to the cloud infrastructure
(IaaS, PaaS and SaaS) such tampered binaries and privileged insiders.
C5 Data Covers data related security issues including data migration, integrity,
confidentiality, and data warehousing.
In Table 2, we map the identified cloud security issues into the suitable categories defined earlier
(Table 1). We have labeled these issues with “I1, I2, …, In” where Ix refers to cloud security issue
number x. Special attention is required towards mutual security standards such as Secure Sockets Layer
(SSL)/Transport Layer Security (TLS), XML signature, XML Encryption Syntax and Processing, and
Key Management Interoperability Protocols. Currently, cloud computing lacks appropriate security
standards (I1) [1]. Even if security standards are defined properly, many security issues are still
associated with compliance risks (I2) due to lack of governess for audits and assessment of corporate
standards [1]. Cloud customers do not have enough knowledge of procedures, processes and practices
of the provider, especially in the areas of identity management and segregation of duties. Organizations
that seek to obtain certifications may be put on risk by denying an audit by cloud customers. One of the
most important aspect of cloud computing security is auditability (I3); however, we do not have an audit
net for cloud service providers [13,31]. If a service provider outsources a service to a third party where
functionality is not transparent, users must be able to inspect the whole process [12]. Security standards
(C1) and governing bodies are part of service level agreements (SLA) (I4) and legal aspects, respectively
which have not been taken into practices for cloud computing [32,33]. SLA defines the relationship
among parties (provider—recipient) and is extremely important for both parties [9]. It includes
identifying/defining the customer’s needs, simplifying complex issues, encouraging dialog in the event
of disputes, providing a framework for understanding, reducing/removing areas of conflict, eliminating
unrealistic expectations. The user may suffer, in case of data loss, if the above factors are not taken into
consideration as he may not be able to put claims on service providers. These interactions shape the
Trust (I5) relationship between the users and the different cloud stakeholders which is required when
users transfer data on cloud infrastructure [34]. Strong justifications are required to gain customers’ trust
in that regard. 
Computers 2014, 3 6
Table 2. Cloud Security Issues and Classifications.
Category Label Issues
Security Standards
I1 Lack of security standards
I2 Compliance risks
I3 Lack of auditing
I4 Lack of legal aspects (Service level agreement)
I5 Trust
Network
I6 Proper installation of network firewalls
I7 Network security configurations
I8 Internet protocol vulnerabilities
I9 Internet Dependence
Access
I10 Account and service hijacking
I11 Malicious insiders
I12 Authentication mechanism
I13 Privileged user access
I14 Browser Security
Cloud Infrastructure
I15 Insecure interface of API
I16 Quality of service
I17 Sharing technical flaws
I18 Reliability of Suppliers
I19 Security Misconfiguration
I20 Multi-tenancy
I21 Server Location and Backup
Data
I22 Data redundancy
I23 Data loss and leakage
I24 Data location
I25 Data recovery
I26 Data privacy
I27 Data protection
I28 Data availability
Network category (C2) related issues are deemed to be the biggest security challenges in clouds since
cloud computing is more prone to network related attacks compared to the traditional computing
paradigms [2]. In addition, cloud operations are tightly coupled and highly depend on networking.
Therefore, cloud network security issues receive more attention in this work compared to the other
security categories. The ratio of network attacks and fraud dramatically increases as people and
organizations migrate their data into clouds. Security experts anticipate that clouds will be the focus of
hackers in future due to the concentration of valuable “assets” (data and computation) within the clouds.
The possible lack of proper installations of network firewalls (I6) and the overlooked security
configurations (I7) within clouds and on networks, make it easier for hackers to access the cloud on
behalf of legitimate users [35]. Hackers can occupy resources (hardware/application) by generating
bogus data or they can run malicious code on the hijacked resources. Denial of service can be launched
by first identifying vulnerabilities in Internet protocols (I8) such as SIP (Session Initiation Protocol)
which could deem the Internet to be un-trusted [36]. Migrating to cloud will increase the Internet 
Computers 2014, 3 7
dependency (I9) as a main communication medium for cloud access. Therefore, if, due to some attacks,
the Internet is disabled and the cloud services become unavailable, this may cause production to become
severely crippled [37]. I9, therefore, implies all the network reliability issues.
Account and service hijacking (I10) involves phishing, fraud and software vulnerabilities where
attackers steal credentials and gain unauthorized access to servers [1]. This unauthorized access is a
threat to integrity, confidentiality and availability of data and services [1]. Unauthorized access can
be launched from within or outside the organization. Malicious insiders (I11) such as dishonest
administrators severely impact organizations’ security. Given their level of access, they infiltrate
corporate and cause brand damage, financial and productivity losses. Therefore, it is critical for
cloud customers to clearly determine the guarantees that the cloud providers use to detect and defend
against insider threats. The current authentication mechanisms (I12) may not be applicable in cloud
environments as customers no longer belong to or are able to access a single tightly controlled system
[4]. A single customer may access data and compose services from multiple cloud providers using a
mobile application or a browser. This kind of access brings in an inherent level of risk and this risk has
been called privileged user access (I13) [6]. Unauthorized access becomes possible through browser
vulnerabilities. Therefore, Internet browser (I14) is the first stage where security measures should be
considered because vulnerabilities in the browser open the door for many follow-on attacks.
The insecure interface of Application Programming Interface (API) (I15) issue covers the
vulnerabilities in the set of APIs in the cloud portal (customers use these APIs to connect to a cloud)
which can expose an organization to several threats such as unauthorized access, content transmission,
reusable token and logging capabilities [1]. Quality of service (QoS) (I16) is an unattended issue [32]
because many cloud service providers focus only on fast performance and low cost [31]. In this work,
we consider QoS in the domain of any function or activity that directly or indirectly affect security. A
simple error in the configuration of one or more of the cloud components may cause severe consequences
because cloud configurations could be shared by many services [4]. Technical flaws (I17), also known
as reputation fate sharing [38], in which errors transfer from a corrupted server to each virtual machine
created on that server becomes worse when the corruption transfers through the infected mobile VM to
other servers. Therefore, it is extremely important to identify and fix fate sharing incidents and
implement the best practices to prevent them from reoccurring. Reliability of suppliers (I18) is an
important factor that requires a background check on the staff to control data and hardware access [4].
It is highly recommended that companies should evaluate its staff in order to protect its assets and data
and provide this information to public to gain customer’s trust. Servers in the cloud are the backbone to
its infrastructure that provides numerous services such as directory service, data storage and mail.
Intruders can access the system if the security attributes of the servers are not configured properly
(security misconfiguration—I19) [39]. This misconfiguration could happen in the application stack, the
framework, the web server, the custom code as well as the platform. Note that this is different from
inadequate network security configuration (I7), which includes network level security
misconfigurations. Cloud serves serve multiple simultaneous users through virtualization, which allows
the sharing of the same software and hardware resources by different users. This multi-tenancy (I20)
capability could lead to information leakage from one tenant to other server mates [40]. Attacks such as
VM-to-VM and compromised VM are becoming hub for future attacks. In terms of server location (I21)
precautions, it is important to keep in mind that the floor should be anti-static, should have no window 
Computers 2014, 3 8
for security reasons, should have a rack with seismic bracings and should be properly grounded [41].
Cloud infrastructure cannot be completely trusted at this stage and it is critical to maintain backup
offline.
Data redundancy (I22) [6], data loss and leakage (I23) [40], data location (I24) [6], data recovery
(I25) [4], data privacy (I26) [42], data protection (I27) [43] and data availability (I28) [43] have been
marked as major and important issues in different case studies which require data to be properly
encrypted, transmitted, protected, controlled and available in the time of need.
Figure 2 shows the cloud components where security issues may be raised. Each component, such as
policies, clients, cloud infrastructure, and network, is prone to certain security attacks and requires attack
prevention/detection/response strategies.
Figure 2. Cloud components that are prone to security threats.
2.2. Dependencies among Cloud Security Categories and Issues
In addition to identifying cloud security issues and classifying them into several categories, we have
identified dependencies among these categories and the security issues they encompass. If one of the
categories is prone to certain attacks, other categories may also become prone to these attacks. For
example, issues I1–I4 (Table 2) fall under category C1 (Table 1). Security related issues under this
category might be entry doors through which other threats infiltrate into the cloud. Suitable management
and security precautions taken in one category (e.g., C1) may greatly minimize or even eliminate security
issues in the other categories (C2, C3, etc.). If proper policies are implemented at one category, then
fewer issues will arise in other categories (only those issues that are genuine to a particular category
rather than issues that take advantage of vulnerabilities in other categories). We have covered many
threats/vulnerabilities in this survey and will now investigate the dependency relationships among them.
We follow thematic analysis ([31,43]) to extract the dependency relationships among the cloud security
issues we surveyed. Initially, we extracted the appropriate text from the literature we surveyed (column
1 in Table 3). We then identified the security issues in the selected text and performed manual coding to
identify the particular features of that selected text. This coding process is essential for organizing the
data into meaningful groups. Table 3 presents an example, which contains textual description (text 
Computers 2014, 3 9
extraction), identified code, identified rule and the rule description. The symbol used in describing the
rules is represented as “→”. It simply means that the security issue on the left of the symbol leads to or
increases in the probability of occurrence of the issue(s) on the right of symbol.
Table 3. Data Extraction Example.
Text Extraction
(from Primary Studies)
Problems Coded Identified Rule Rule Description
Account and service hijacking
involves phishing, fraud and
software vulnerabilities where
attackers steal credentials and
gain an unauthorized access to
server [1].
 Account and service
hijacking (I10)
 Data Loss and
Leakage (I23)
Account and
service hijacking
→ Data Loss and
Leakage
Account and service
hijacking increase the
possibility of data loss
and leakage
Insecure interface of API
(customers use these APIs to
connect to cloud) which can
expose organization to several
threats such as unauthorized
access, content transmission [1]
 Insecure interface of
API’s (I15)
 Weak authentication
mechanisms (I13)
 Data Loss and
Leakage (I23)
Insecure interface
of API’s →
authentication
mechanism
weakness, Data
Loss and Leakage
Insecure interface of
API’s leads to increase
in the probability of
information leakage and
the weakness of the
authentication
mechanism.
The same procedure has been followed in order to determine dependencies among other cloud
security issues that we have identified in this survey. A sample of these dependencies has been presented
in the form of rules in Table 4. These rules aim at providing practitioners with deep insights about cloud
computing security issues to take suitable precaution measures. Practitioners can also trace the source
of any security issue through these rules. For example, the main cause of wrapping attacks can be tailored
to weak browser security as stated by Rule 7, whereas weak browser security can be linked to security
misconfiguration as stated by Rule 11. These rules could be helpful in protecting a cloud computing
environment against various attacks by providing a comprehensive view of the attacks’ map rather than
considering each attack in an isolated setup.
Figure 3 shows a directed graph representation of the dependencies among the surveyed cloud
security issues. In the figure, nodes represent security issues, a directed edge from node X to node Y
indicates that the occurrence of issue Y is facilitated by the occurrence of issue X. Finally, codes on
edges refer to the rules in Table 4, where Rn refers to rule number n.
 
Computers 2014, 3 10
Table 4. Rules that Capture Dependencies among Cloud Security Issues.
No. Rules Sample References
1
Lack of security standard (I1) → compliance risks (I2), account and service
hijacking (I10), internet protocol vulnerabilities (I8), malicious insider (I11),
authentication mechanisms weakness (I12)
[1,4,7,41,42]
2 Lack of auditing (I3) → malicious insider (I11) [7,37,39,41,44,45]
3 Lack of legal aspects (Service level agreement) (I4) → authentication
mechanism weakness (I12) [1,2,4,19,32,46]
4 Insecure interface of API (I15) → account and service hijacking (I10) [1,4]
5 Compliance risk (I2) → account and service hijacking (I10) [41]
6 Weak Browser security (I14) → account and service hijacking (I10) [4,41]
7 Internet protocol vulnerabilities (I8) → authentication mechanism weakness
(I12)
8 Security misconfiguration (I19) → insecure interfaces of API (I15), account
and service hijacking (I10) [4,41–43]
9 Malicious insider (I11) → Data loss and Leakage (123) [6,33]
10 Lack of quality of service (I16) → insecure interfaces of API (I15), Data loss
and Leakage (I23) [4,6,33,41,43]
11 Authentication mechanism weakness (I12) → Data loss and
Leakage (123) [6,33]
Figure 3. Dependencies among cloud security issues.
3. Known Attacks and Countermeasures: An Evaluation
“All the vulnerabilities and security issues that on-premise, non-virtualized and non-cloud
deployments have still remain in the cloud”, Lawrence Pingree, analyst for Gartner, said. “All that cloud
and virtualization does is enhancing the potential risks by introducing virtualization software and
potentially mass data breach issues, if an entire cloud provider’s infrastructure is breached [105]104.”
In this work, we classify cloud applicable attacks into nine groups; provide sample attack incidents from 
Computers 2014, 3 11
each group, and present comparative analysis of some of the famous security mitigation techniques.
Table 5 presents a summary of attack group names, known attack incidents in each group, attack
consequences, attack category (from Table 1), exploited vulnerabilities (from Table 2), and references
for further readings about each attack group. A description of each attack group along with evaluation
of the state-of-the-art countermeasures are presented in the following subsections.
3.1. Theft of Service Attacks
The Theft of Service attack [37] utilizes vulnerabilities in the scheduler of some hypervisors. The
attack is realized when the hypervisor uses a scheduling mechanism, which fails to detect and account
of Central Processing Unit (CPU) usage by poorly behaved virtual machines. This failure may further
allow malicious customers to obtain cloud services at the expense of others. This attack is more relevant
in the public clouds where customers are charged by the amount of time their VM is running rather
than by the amount of CPU time used. Since the Virtual Machine Manager (hypervisor) schedules and
manages virtual machines, vulnerabilities in the hypervisor scheduler may result in inaccurate and unfair
scheduling. These vulnerabilities mainly result from the use of periodic sampling or low-precision clock
to measure CPU usage: like a train passenger hiding whenever ticket checkers come for tickets. In the
Theft of Service attack, the hacker ensures that its process is never scheduled when a scheduling tick
occurs. The common incidents of this attack include: (1) using cloud computing services (e.g., Human
Resource, HR, systems) for long period of time while keeping it hidden from the vendor and (2) using
cloud computing resources (e.g., storage system or OS platform) for a long period without representing
it in a billing cycle.
A countermeasure to this attack has been provided by Zhou et al. in [37] by modifying the scheduler
to prevent the attack without sacrificing efficiency, fairness or I/O responsiveness. These modifications
do not affect the basic credit and priority boosting mechanisms. The modified schedulers are: (1) exact
scheduler; (2) uniform scheduler; (3) passion scheduler and (4) Bernoulli scheduler. The main
differences among these schedulers are in the scheduling and monitoring policies and in time-interval
calculations. The experiment conducted by authors with the modified schedulers provides accurate
and fair scheduling. The modifications in hypervisor are shown to be beneficial, as compared to Xen
hypervisor (currently running in Amazon Elastic Compute Cloud—EC2).
Another theoretical countermeasure has been provided by Gruschka et al. in [44]. They suggest using
a new instance of cloud-to-user surface in victim machine to monitor the scheduling of parallel instances.
Then, the outputs of both the attacker and the legitimate instances are compared. A significant difference
in results is reported to the responsible authorities as an attack. This solution has not been validated or
verified by authors and does not provide any guarantee for a beneficial result. There are other solutions
provided for hypervisor scheduling such as [45,47,48] but they are only limited to improving other
aspects of virtualized I/O performance and VM security such as CPU-bound issues. These studies do
not examine scheduling fairness and accuracy in presence of attackers, which is the backbone for the
Theft-of-Service attack. 
Computers 2014, 3 12
Table 5. Known Attacks against Clouds.
Sr.
#
Attack
Name
Attack
Incidents Consequences Category Vulnerability/
Caused by
Sample
References
1 Theft-ofservice
 Cloud service usage
without billing
 Cloud resource stealing
with less/no cost
Cloud
Infrastructure
I1, I3, I6, I8, I11,
I14, I19
[37,44]
2 Denial of
service
DDoS  Service/hardware
unavailability
 Wrapping a malicious
code in Xml signature
to gain unauthorized
access to information
 Accessing a browser
history or any other
private information
through unsecure Http
browsing
Network,
Cloud
Infrastructure
I1, I3, I10, I14,
I19
[34,49]
Http-Based
DDoS
Xml-Based
DDoS
RESTBased-DDoS
Shrew attack
(light traffic)
DoS)
3 Cloud
malware
injection
 Credential information
leakage
 User data leakage
 Cloud machine
abnormal behavior
Cloud
Infrastructure
I7, I11, I13, I15 [44,50–52]
4 Cross VM
side
channels
Timing side
channels
 User data/information
leakage
 Cloud
resources/infrastructure
information leakage
Cloud
Infrastructure
I15, I19 [53–55]
Energyconsumption
side
channels
5 Targeted
shared
memory
 Cloud resource’s
information leakage
 User information/data
leakage
 Provides open window
for other attacks such
as side channels and
cloud malware
injection
Cloud
Infrastructure
I1, I3, I10, I15,
I19,
[53,56,57]
 
Computers 2014, 3 13
Table 5. Cont.
Sr.
#
Attack
Name
Attack
Incidents Consequences Category Vulnerability/
Caused by
Sample
References
6 Phishing  Unauthorized access to
personal information
 Installing a malicious
code into user
computer
 Force cloud computing
structure to behave
abnormally
 Make server
unavailable for enduser
Cloud
Infrastructure,
Network, Access
I1, I6, I8, I10,
I12, I14
[58,59]
7 Botnets Stepping
stone attack
 Unauthorized access to
cloud resources
 Make cloud system
work abnormally
 Stealing sensitive
information
 Stealing user data
Network, Cloud
Infrastructure,
Access
I1, I6, I10, I12,
I14
[60,61]
8 Audio
Steganogra
phy
 Unavailability of cloud
storage system
 Accessing user data
 User data deletion
Cloud
infrastructure,
Access,
I1, I3, I6, I10,
I14, I19
[62,63]
9 VM
rollback
attack
 Launch brute force
attack
 Damage cloud
infrastructure
 Leakage of sensitive
information
Cloud
Infrastructure,
Access
I1, I3, I6, I10,
I14, I19
[64,65]
3.2. Denial of Service Attacks
Most of the serious attacks in cloud computing come from denial of service (DoS), particularly HTTP,
XML and Representational State Transfer (REST)-based DoS attacks. The cloud users initiate requests
in XML, then send requests over HTTP protocol and usually build their system-interface through REST
protocols such as those used in Microsoft Azure and Amazon EC2. Due to vulnerabilities in the systeminterface, DoS attacks are easier to implement and very difficult for security experts to countermeasure
[49]. XML-based distributed denial of service (DDoS) and HTTP-based DDoS attacks are more
destructive than traditional DDoS because these protocols are widely used in cloud computing with no
strong deterrence mechanisms available to avoid them. HTTP and XML are critical and important
elements of cloud computing, so security over these protocols becomes crucial to providing healthy
development of a cloud platform. 
Computers 2014, 3 14
Karnwal et al. in [49] provide a framework called “cloud defender” that is based on five stages:
(1) sensor filter; (2) hop count filter; (3) IP frequency divergence filter; (4) puzzle resolver filter and
(5) double signature filter. The first four filters detect HTTP-based DDoS attacks and the fifth filter
detects XML-based attacks. REST-based attacks are mentioned without providing a framework to
prevent it. One of the reasons could be that REST-based attacks are closely related with the user
interface, which may vary from user-level to system-level applications. These applications are different
in nature, based on different requirements, and there is no single hard and fast rule to implement the
security measurements at the interface level. The solution provided in this article consists of the following
modules:
 Sensor: It monitors the incoming request messages. If it identifies that there is hypothetical
increase in number of messages coming from same or particular consumer, it marks it as suspicious.
 HOP Count filter: It will count the hop count value (how many nodes, does message traverse
from source to destination) and compare it with pre-defined HOP count. If a difference is found,
it means that the header or the message has been modified on hacker machine and thus is
marked suspicious.
 IP Frequency Divergence: Marks a message suspicious, if there is same frequency of
IP messages.
 Double Signature: It doubles the XML signature: one in header and one in bottom. In case of
attack, both XML signatures need to be verified.
 Puzzle Solver: It deals with some intelligent puzzles, where results should be imbedded in some
Simple Object Access Protocol (SOAP) header. In case of attack (HTTP DDoS), the cloud
defender will send back the puzzle to IP, from which it is receiving messages. If the cloud defender
received back the solved puzzle then the request is deemed legitimate, otherwise it is marked as
HTTP DDoS attack.
The problem in this framework is that it lacks practical validation and is based on the assumption
that the number of modules in the system is directly proportional to the number of attacks expected.
Moreover, exhaustive monitoring of messages on each node would considerably slow the network
traffic. Finally, the framework lacks the proper mechanisms for node coordination in case of attack
incidence detection.
Riquet et al. [34] claim that “there is no strong solution available to prevent the DDoS attacks”. To
validate the claim, the authors conduct the experiment to evaluate the effectiveness of the actual security
solutions against distributed attacks. The security solutions involved in the experiment are SNORT and
commercial firewall. The authors conclude that the failure of security systems lies within two aspects:
either the security solution can be obsolete because it is not updated, or the solution can rely on
unsuitable methods. They did not propose any solution that can prevent distributed security attacks.
Other widely used DDoS countermeasures are firewalls. However, due to firewall location (at the border
of a network), it would not be able to detect distributed attacks once they are in the network [50]. 
Computers 2014, 3 15
3.3. Malware Injection Attacks
Cloud malware injection attack refers to a manipulated copy of the victim’s service instance,
uploaded by attacker to cloud, so that some service requests to the victim’s service are processed within
that malicious instance. An attacker can get access to user data through this attack. The attacker actually
exploits its privileged access capabilities in order to attack that service security domain. The incidents
of this attack include credential information leakage, user private-data leakage and unauthorized access
to cloud resources. The challenge does not only lie in the failure to detect the malware injection attack
but also in the inability to determine the particular node on which the attacker has uploaded the malicious
instance [44]. Retrospective detection (examination of hard-drive and memory) has been a widely
used technique to detect the host of malware instances. Liu et al. in [50] propose a new retrospective
detection approach based on portable executable (PE) format file relationship. This approach has been
implemented and validated in HADOOP platform. This approach proves higher detection rate as well
as lower false positive rate. The main drawback of this approach is that its success is based on
three assumptions (pre-requisites): (1) most legitimate programs and malware files are in PE format and
lie within a windows platform; (2) the number of legitimate files is greater than that of malware files in
user’s computer; and (3) creating/writing/reading PE format files seldom happen in a user’s computer.
However, an attacker could exploit any vulnerability in cloud to attack without following any of these
pre-requisites. The authors fail to discuss the consequences of the absence of these pre-requisites such
as (1) how efficient this approach would be if one or more of the assumptions are not fulfilled; (2) how
much damage and attacker could cause to system or data in absence of these assumptions.
Another countermeasure to the attack called “CloudAV” is provided by Oberheide et al. in [51].
CloudAV provides two main features that make it more efficient, accurate and fast as a malware
detection system:
 Antivirus as a network service: the detection capabilities by host-based antivirus can be more
efficiently and effectively provided as cloud-network-service. Each host runs a light weight
process to detect new files and then sends them to network service for quarantine and for further
analysis rather than running complex analysis software on each end-host.
 N-version protection: malicious software identification is determined by multiple heterogonous
detection engines in parallel similar to the idea of N-version programming. The notion of Nversion protection has been provided in this solution so that the malware detection system should
leverage detection capabilities of multiple heterogeneous detection engines to determine malicious
and unwanted files more effectively. However, the number of false positives encountered during
normal operations increase compared to 1-version engines. To manage the false positives, the
administrator has to set a trade-off between coverage (a single detector is enough to mark a file as
malicious) and false positives (a consensus of a number of detectors is required to mark a file as
malicious).
The authors prove the efficiency of CloudAV through validation in a cloud environment. CloudAV
also provides better detection of malicious software, enhanced forensics capabilities, new threat
detection through retrospective detection approach and improved deployability and management. The
validation experiment proves that CloudAV provides 35% better detection coverage against threats 
Computers 2014, 3 16
compared to single antivirus engines and 98% detection coverage of an entire data-set of a cloud.
However, cloud-based security solutions generally suffer from three problems, namely—security
coverage, scalability, and privacy. As malware can be embedded in a large number of file types, attackers
may be able to bypass cloud solutions as they are limited to few file types and hence degrade the
detection coverage. Additionally, exporting all binaries or PDF files to the cloud for investigation does
not scale and may create a single point of failure by flooding the cloud with benign binaries. Finally,
exporting the binaries and files into the cloud for inspection creates privacy issues since there is always
a risk that a sensitive file could be exported to the cloud as well.
In [52], the authors provide a framework based on behavior analysis to detect suspicious programs
in clouds. It allows end users to delegate security labs, the execution and the analysis of a potential
malicious program and force the program to behave as if it were executed directly in real end-user
environment. There are two advantages for this: (1) it allows security lab to monitor the execution of
potential malicious programs in realistic end user environment and (2) it allows end-users to raise their
level of protection by leveraging better computational resources [52].
3.4. Cross VM Side-Channel Attacks
VM side channel attack is an access-driven attack in which an attacker VM alternates execution
with the victim VM and leverages the processor cashes to infer the behavior of the victim. It requires
that the attacker resides on a different VM on the same physical hardware as that of the victim’s VM.
Ristenpart et al. in [57] discuss a comprehensive example on how to collect information from a target
VM through cross VM side channel attack. One incident of side channel attacks is the timing side
channel attack [54] which is based on measuring how much time various computations take to perform.
Successful modulation of this measured time may lead to leakage of sensitive information about the
owner of the computation or even the cloud provider. Timing channels are especially hard to control and
pervasive on clouds due to massive parallelism. Moreover, timing side channel attacks are hard to detect
since they do not leave trails or raise any alerts. Cloud customers may not have the authorization to
check for possible side channels from other cloud mates obviously due to privacy concerns. On the other
hand, cloud providers can thoroughly check and detect timing attack incidents but may not be willing to
report such breaches due to many considerations such as protecting company reputation. Another
incident of side channel attacks is the energy-consumption side channel attack [55]. Instead of directly
attacking the software stack (virtualization layer), attackers can indirectly collect sensitive information
about the cloud using energy consumption logs. This type of data (energy consumption log) is
maintained to monitor the infrastructure status and to provide computer energy efficient workload
mapping. In [55], authors investigate the potential of extracting valuable information from raw energy
consumption logs which may affect user’s privacy and security. Dozens of hypervisors could exist in a
cloud computing environment, each of which could be the host of the targeted VM. Therefore, it may
take a while for the attacker to determine which hypervisor is hosting the targeted VM. The more time
it takes an attacker to determine the host machine, the higher is the probability of attack detection.
However, if the attacker can somehow get the power consumption data, it may become possible for him
to narrow the possible set of servers that could be running the targeted VM. This gives attackers better 
Computers 2014, 3 17
chances to determine the correct server before being detected. Currently, no efficient solutions have been
provided against timing-side channel attacks and energy consumption side channel attacks.
3.5. Targeted Shared Memory Attacks
In this attack, attackers take advantage of shared memory (cache or main memory) of both physical
and virtual machines. It is an initial level attack in cloud computing that can lead up to several different
types of attacks such as side channel attacks and malware injection attacks [53]. For example, authors
in [57] perform cross-virtual-machine-side-channels attack on Amazon EC2 and measure the cache
activity of other users, which provides an example of activity-information leakage in cloud computing.
Attackers can get unauthorized access to information that reveals the internal structure of the cloud such
as the number of processes running, the number of users logged-in in a specific time and the temporary
cookies residing in memory. Another example of targeted shared memory attack is explored by Rochsa
and Correia in [56]. The goal is to access the memory dumps in virtual machines through malicious
insider attack. This access has led to the extraction of the current running processes in the system and
users’ private information.
Thus far, in the literature, no one has claimed to solve or prevent targeted shared memory attacks.
Researchers and practitioners are working to get more information about the attack and no strong
solution is available to prevent it except current anti-viruses or firewalls that limit users’ access to the
shared memory.
3.6. Phishing Attacks
Phishing is an attempt to access personal information from unsuspecting user through social
engineering techniques. It is commonly achieved by sending links of webpages in emails or through
instant messages. These links appear to be correct, leading to a legitimate site such as bank account login
or credit card information verification but they practically take users to fake locations. Through this
deception, the attacker can obtain sensitive information such as passwords and credit card information.
Phishing attacks can be classified into two categories: (1) an abusive behavior in which an attacker hosts
a phishing attack site on cloud by using one of the cloud services and (2) hijack accounts and services
in the cloud through traditional social engineering techniques [58].
Cloud security alliances (CSA) mentioned that cloud service providers do not maintain sufficient
control over systems in order to avoid being hacked or spammed. To prevent such attacks, CSA proposes
a few precaution measurements such as strict registration process, secure identity check procedure and
enhanced monitoring skills [58]. Privacy laws in cloud computing do not allow cloud service providers
to look at what customers are doing, so if a malicious individual or organization is performing something
nefarious (phishing attack or uploading malicious code) by using cloud services, it cannot be detected
until or unless notified by some security software [59]. Researchers in [58,59] discuss the fact that the
present cloud privacy laws restrict cloud providers to become the first to know about nefarious activities
in their clouds, regardless of the enhanced monitoring and comprehensive inspection of network traffic. 
Computers 2014, 3 18
3.7. Botnet Attacks (Stepping-Stone Attack)
In Stepping Stone, attackers try to achieve their goals (such as spying, DoS, damaging, etc.) while
avoiding revealing their identities and locations to minimize the possibility of detection and trace-back.
This is achieved by indirectly attacking the targeted victim through a sequence of other hosts (called
stepping stones). Stepping stone hosts can be recruited through illegal botnets. A bot-master, through
botnet attack, can setup command and control server and stepping-stones into clouds in order to steal
sensitive information and to gain unauthorized access to cloud resources in a bid to make it behave
abnormally. In recent years, botnet attacks have been reported in Amazon EC2, Google AppEngine and
Raytheon UK. A Zeus command and control was hosted on Amazon EC2 cloud [66]. A computer was
infected by using relay commands through Google AppEngine [67], which allowed attackers to steal
sensitive information from the Raytheon cloud [68]. Cloud computing is an ideal environment for botnet
attacks [60]. A cloud has rich and elastic computing resources (bandwidth, processing and storage),
which are easy to access. The attacker can either compromise a cloud-based server as their command
and control server or they can lease a high performance virtual machine with the help of fake or stolen
credit cards.
Many researches worked to countermeasure botnets and steeping stone attacks by identifying whether
a particular host is a stepping stone or not. Most of the detection work is based on the hypothesis of
strong correlation between the incoming and outgoing traffic of a possible stepping stone host. Such
correlation can be based on packet content, login behavior, frequency of network activity, timing
properties, and periodicity of network traffic. However, many of these techniques are easy to fool by
attackers using encrypted traffic and authentication forging or by introducing random delays (jitter),
while others are shown to be inefficient due the huge traffic that need to be monitored and analyzed.
One of the most notable detection techniques is presented by Lin et al. in [60]. They introduce what they
call a “pebble” trace scheme to trace-back the bot master. It first identifies the cryptographic keys of the
botnet communication in order to configure the botnet operations and then it traces back the bot master.
It involves the design and implementation of a new key identification scheme and an approach for
tracing-back bot master across stepping-stones beyond multiple clouds. The solution only considers
symmetric key cryptography with no discussion about asymmetric cryptography.
A different mechanism, based on self-protection, has been present by Kourai et al. in [61]. The
mechanism, dubbed xFilter, is a packet filter that runs in a virtual machine that monitors the underneath
VM and achieves pinpoint active response by using VM introspection. xFilter inspects the memory of
the VM being monitored, using VM introspection, and obtains information about guest operating
systems without interacting with them. xFilter can deny packets, by using sender process’s information,
from particular sender or process. When xFilter detects an outgoing attack, it automatically identifies
the attack source and generates a new filtering rule in order to stop the stepping-stone attack. This
mechanism is proved to be efficient because even if cloud server is compromised, this mechanism
will continue to provide other services as much as possible. For example, when the apache server is
compromised, only the privileges of user www-data are taken over at worst, while other applications
such as Postfix mail server will continue running legitimately. This solution has a limitation that can be
dangerous for the business of cloud providers. For example, the attacker may intentionally use local
SMTP server to mount SPAM attacks because other legitimate applications are also using SMPT server 
Computers 2014, 3 19
to send emails. If xFilter detects the SPAM attack, it will update the rule repository to deny all the traffic
coming from the SMTP server including that from legitimate applications or users.
Srivastava et al. in [69] provide a detection mechanism that inspects the Internet traffic. This solution,
named VMwall, is based on application-level firewall using VM introspection. One of the main
differences of this solution compared to xFilter is that it degrades the network performance considerably
when large number of packets and nodes are to be inspected. On the other hand, since xFilter inspects
the server memory, the degradation would be minimized [69].
3.8. Audio Steganography Attacks
Audio Steganography attack has been regarded as one of the most serious attack to cloud storage
systems. Audio Steganography helps users to hide their secret data within regular audio files. The
steganography user can transmit secret information through sending media files, which appear to be
normal sound files. Hackers utilize this feature to deceive the current security mechanisms or traditional
countermeasures (e.g., steg-analysis) for protecting cloud storage systems by hiding their malicious
code in sound files and sending it to victim servers [70]. Very little research has considered proposals to
thwart Audio Steganography attacks against cloud storage systems, which make it an open area that
requires practical solutions [71].
Liu et al. in [71] perform a careful analysis of Audio Steganography attack on cloud storage systems.
They design and implement a scheme called StegAD (steganography Active defense) to tackle the threat
of data leakage by using Audio Steganography attacks. The first step, in this solution, is to scan the
hiding place of audio files under cloud storage system through famous RS image gray scale steg-analysis
algorithm. After acquiring suspicious files, authors use SADI (Steganography Audio Dynamical
Interference) technique to interfere in all the possible places in those suspicious files. Authors try to
avoid damaging innocent files (which have been marked as suspicious during the scanning process)
though adopting an approach where an interference has to be in multiple hiding places or most significant
places. However, this solution does not provide any information about how to decide the significant
hiding places. Authors first use random noise to replace information including the most significant one
and then compare the previous unchanged information with the changed one. By doing so,
steganography and innocent files will have different consequences. This difference will determine
whether the audio file has appropriate content or some malicious code that can damage the cloud storage
system. There are many questions that have not been answered in this solution such as: (1) How is the
comparison between steganography and innocent file carried out? (2) What are the specific types of
audio files considered in this experiment?
3.9. VM Rollback Attacks
The virtualization environment in cloud computing is the most vulnerable area to attack. The
hypervisor can suspend a VM at any time during execution, take a snapshot of current CPU states, disk
and memory and resume a snapshot later without guest VM awareness. This feature has been widely
used for fault tolerance and VM maintenance; however, it also provides an open window to an attacker
to launch VM rollback attacks. In a rollback attack, a user can take advantage of previous snapshots and
run it without the user’s awareness and then clean the history and again run the same or different 
Computers 2014, 3 20
snapshot. By cleaning the history, the attacker will not be caught for his suspicious activities. For
example, an attacker can launch a brute force attack to guess a login password for VM, even if the guest
OS has a restriction on the number of attempts such as blocking the user after three failed attempts or
erasing all data after 10 times, the attacker can still rollback the VM to its initial state after each try. The
attacker will clear the counter inside the VM and bypass the restriction and run the brute-force attack
again [64].
Szefer et al. in [71] provide an architecture named “Hyperwall” in order to manage hypervisor
vulnerabilities. The solution to prevent VM rollback attack is based on disabling the suspend/resume
functionalities of the hypervisor. The suspend/resume feature is powerful for virtualization and disabling
it will not provide a better solution. Another limitation of this solution is the excessive user interaction
with the cloud system. It requires end users to get involved during VM booting, suspending and
resuming. This means that the system needs to ask for permission every time it reboots, migrates or
suspends a VM which makes it inconvenient and impractical [71]. Xia et al. in [64] provide a solution
that works without disabling any basic functionalities of the hypervisor as compared to the Hyperwall.
In this solution, only the end user can tell whether a rollback is malicious or not by auditing the log of
VM activities. Although this solution has minimized the user involvement compared to the Hyperwall,
the changing infrastructure of cloud computing still demands autonomous working of VM operation
with some user involvement.
4. Comparative Evaluation of Well-Known General Cloud Security Mechanisms
The European Union Agency for Network and Information Security (ENISA) has done significant
work in addressing many security issues related to the cloud. It provides stakeholders with information
that helps them to understand, assess, and manage the risks when migrating into the clouds. It also
provides advisory services on setting and monitoring SLAs to optimize security gains. ENISA also
provides cooperative studies with various stakeholders to identify the critical cloud services and analyze
the impact of the cloud service failure in such circumstances. In the following subsections, we present
the state-of-the-art general tools that are individually and collectively used to countermeasure cloud
security attacks.
4.1. Intrusion Detection Systems (IDS)
Intruders, through impersonating legitimate users, can access cloud infrastructures causing it to be
unavailable for legitimate users. It has been shown that attackers can easily get information regarding
victim machines in the IaaS component of the cloud [70]. This information can help in attacking cloud
users by co-locating the malicious virtual machine with the victim’s virtual machine. These attacks
include denial of service (DoS) and distributed denial of service (DDoS) attacks that mainly target data
confidentiality, integrity, and availability [72]. Such attacks can be avoided by implementing IDS which
offers additional security measures by investigating network traffic, log files and user behavior [73].
IDS is defined as a system that collects and analyzes information, from different key points, for security
auditing and monitoring in order to check whether this is a violation of network policies or not. Intrusion
detection can be classified into two categories (1) misuse detection (MD) and (2) anomaly detection
(AD) [74]. MD deals with information characteristics of users input and making a comparison with 
Computers 2014, 3 21
database results (previous inputs by the same user). On the other hand, anomaly detection stores user
behavior in feature database, which can be compared with current behavior. If there is a high rate of
difference in comparison, then the invasion occurred. IDS have two types (1) host based IDS (HIDS)
which monitors the behavior on a single host and (2) network based IDS (NIDS) which analyses traffic
flowing through a network [75]. Roschke et al. in [76] discuss a third type called hybrid IDS also known
as distributed IDS, which combines the functions of both NIDS and HIDS.
The authors in [73] propose an IDS system named Grid and Cloud Computing Intrusion Detection
System (GCCIDS) which is based on NIDS and HIDS. It consists of an audit system that detects and
covers attacks that have not been covered, previously, by other NIDS and HIDS systems. It works by
integrating knowledge and behavior analysis in order to detect intrusions. The main components of
GCCIDS include node, service, event auditor and storage system. The main limitations in GCCIDS
include the high communication overhead and redundancy. Each node identifies the local event and
alerts all other connected nodes. The overhead increases dramatically when the number of nodes
increases due to the massive computations and communications involved. Additionally, GCCIDS does
not provide any information as to whether a node should immediately alert other nodes as intrusion
occurs or at a certain predefined periodic time interval. Let us consider the case of immediate sharing
with a grid, for example, of 1000 nodes. Each time intrusion occurs, the detecting node will alert all the
other 999 nodes generating high overhead of communication exchange. Attackers can utilize this ‘alert
sharing’ as an open window to disrupt the network. Attackers behave as intruders in different intervals
of time, triggering certain nodes to detect these intrusions and hence notifying other nodes, which
considerably increases the communication overhead. If a node selects not to immediately alert other
nodes, inconsistency arises. A node that identifies an attack contains the information about the attack,
while other nodes are not aware of it. Each node, in this system, consists of a local database that has
information related to intrusions occurred previously. The local repository leads to redundancy.
GCCIDS uses both knowledge-based and behavior–based techniques for attack incident detection.
Knowledge-based techniques cannot detect new attacks because detection depends on pre-defined rules.
However, this limitation can be alleviated through regularly updating local repositories with information
about new attacks. For behavior-based technique, GCCIDS uses feed forward artificial neural network
(FFANN). However, FFANN is not useful at the starting phase due to little or no data availability.
However, as the time passes and more computations are done by FFANN, the results improve.
The redundancy of repository in GCCIDS has been removed in an IDS system called Distributed,
Collaborative and Data driven Intrusion Detection and Prevention framework (DCDIDP) [77]. DCDIDP
creates global database to be used for detection tasks by the ID prevention module. DCDIDP consists of
three level architectures, namely: network, host and global infrastructure. Network and host architecture
maintain local database of policy and rules and contribute to global database. The global database shares
information regarding intrusions among different clouds. The main features of DCDIDP include being
distributed (policies are distributed among hosts), collaborative (hosts collaborate with each other to stay
synchronized for information sharing) and data driven (dynamic evaluation of rules and access list).
DCDIDP can be implemented in IaaS, PaaS and SaaS and provides effective intrusion prevention.
However, the collaboration among different clouds requires an extensive trust management, which
does not exist in the current DCDIDP framework. It does not provide approaches to promote trust
among cloud users beyond what is stated in SLA. Information sharing among different clouds is also 
Computers 2014, 3 22
dependent on the structure of each cloud. Finally, DCDIDP has not been evaluated and verified through
practical implementations.
Dastjerdi et al. [78] propose a new IDS system by combining and extending the peer-to-peer IDS
based on mobile agents [79] and the distributed intrusion detection using mobile agent (DIDMA) [80].
It consists of four main components namely IDS control center (IDS CC), agency, application
specific static agent detector and specialized investigative mobile agent. IDS CC is central part of IDS
component administration. Dastjerdi et al. claim that their proposal reduces network load and provides
better trust management.
Figure 4 represents the overall view of IDS structure that consists of NIDS and HIDS. Each IDS
(regardless of being deployed on distributed networks, grid or cloud) requires some basic components
such as alert sharing, analyzer, technique to detect the suspicious behavior, etc. Researchers and
practitioners are providing solutions, in the form of IDS, DIDS or HIDS, by reducing the number of
components and by increasing the performance of IDS. Cloud infrastructure is changing so rapidly that
current intrusion detection systems are not flexible enough to cope with these changes. One solution can
be autonomous IDS that can update its policy as soon as cloud infrastructure changes. An unattended
area here is to develop mechanisms for distributed IDS (Network or host based), which involve both
inter and intra clouds considerations. Infrastructure heterogeneity, among clouds, and use of efficient
communication protocols poses another challenge in cloud security.
Figure 4. Basic architecture of Intrusion Detection Systems.
4.2. Autonomous Systems
An autonomous system is an IDS that works with pre-specified basic rules. These rules configure,
heal, optimize and protect themselves automatically, thereby reducing human efforts and involvement [81].
These rules are specified either by management or through artificial intelligence. It is impossible,
without autonomic computing, to manage next generation distributed-systems such as clouds and grids
effectively. Deolitzshcer et al. [82] present an intelligent autonomous agent for incident detection named
Security audit as a Service (SaaS). This agent is assumed to be aware of the underlying business flow of 
Computers 2014, 3 23
instances of the deployed clouds. SaaS collects data directly at the source, analyses it, aggregates
information and then distributes it. The central part of this system is based on data analysis that is
performed through security service level agreement (SSLA). SaaS addresses three main problems of
cloud computing namely: (1) abusing cloud resources; (2) missing security monitoring in cloud
infrastructure and (3) defective isolation of shared resources. SaaS involves the use of large number of
sensors that can capture many events. These sensors receive security policies from SSLA. Even though
SaaS is based on autonomous agent, its security policy is still based on pre-defined rules, which limits
the detection capabilities only to those attacks that are already known. Moreover, SaaS involves the use
of large number of agents and functions such as initiating agent, moving agent, killing agent, etc., which
creates high communication among agents and increases the computational overhead.
Balen et al. [83] provide a pure concept of autonomous system, as compared to SaaS [82], particularly
autonomic manager in grid and cloud computing. It provides a feature of self-configuration, self-healing,
self-optimization and self-protection. The autonomic system is one which includes the autonomic
manager, which is able to build and execute plans for implementation, based on sent and received
information. A pure autonomous system architecture is presented by Sodhi et al. in [84]. This
architecture is based on IaaS, where control of cluster nodes is fully autonomous. This architecture uses
real time information from cluster nodes and decentralizes the policy management from the master node
to other working nodes. It has several main components, namely: (1) cloud controller—a gateway for
clients into cloud which determines the suitable node to run VM that satisfies client needs; (2) cloud
agent—an intelligent software component that responds to the queries of the cloud controller regarding
the availability of VM configuration for a specific lease duration; (3) VM foundry—VM image
repository interface dedicated to answer queries for particular VM configurations and it creates the onetime-URLs for the VM image. The cloud agent is further based on several components including request
handler, VM manager, policy manager, capability manager and data store. The key point which
differentiates this system from other IaaS based systems is that it consists of decentralized policy
management rather than based on master–slave relationship architecture that provides a bottleneck issue.
If a problem occurs in the master, it may cause the system to function abnormally or even to shut down.
This issue has been avoided through decentralization of policies to other nodes. Workload distribution
mechanisms for IaaS are static. Decentralization needs to be an autonomous, due to rapid change in
cloud infrastructure. Decentralization of policy management among different nodes will increase
reliability and security (e.g., if one node is compromised, information leakage from other nodes can still
be controlled).
Non-functional requirements with respect to autonomous IaaS node structure is still not much
explored. Yazir et al. in [85] discuss an approach for dynamic and autonomous resource management
in cloud computing with respect to scalability, feasibility and flexibility. Similar to [84], Yazir et al.
present an approach that deals with decentralization of autonomous tasks, carried out by independent
agents. The authors’ contributions are based on two steps (1) resource management is decomposed
into independent tasks and each task is executed by autonomous node agent by adopting distributed
architecture and (2) configuration is carried out by node agent through multiple criteria decision analysis
(MCDA) using PROMETHEE method [86]. The simulation of this system proves to achieve scalability
through distributed approach which reduces computational complexity. The approach used in the system
is potentially feasible in large data centers as compared to centralized approaches. Dynamic resource 
Computers 2014, 3 24
allocation provides higher flexibility due to its ability to change/add configurations. The main purpose
of introducing an autonomous system in a cloud is to avoid wasting time and to utilize resources
efficiently. The authors conclude that the PROMETHEE approach is promising with respect to nonfunctional attributes such as scalability, feasibility and flexibility although there is no function for proper
resource management among virtual machines [87]. For example, HDD volume and memory volume
setting is done manually or by cost estimation. There is no flexible management system by number of
user access, at a given time or by load averages.
4.3. Federated Identity Management System
The backbone of cloud computing security is tightly coupled with identities used to access cloud
infrastructure. Management of identities (IDM) is about maintaining the integrity of identities,
throughout their life cycle, to make it and its related data (e.g., authentication and authorization results)
available to different services in secure and privacy-protected manner [88]. The concept of federated
identity management (FIM) is about managing identities by allowing an identity subject to establish
links between his/her identities, each of which can be used for a different service, across geographical
and organizational borders [88]. Establishing a logical link between identities is called identity
federation [88]. The federation is a group of organizations that establish trust among themselves in order
to cooperate safely in business [89]. The process to repeat authentication of user (Single Sign-On) can
be an example of federated identity [89]. The main issue with single Sign-On lies in the wider damage
that it causes in case of compromise. If a user identity is compromised, the illegitimate user will not be
verified again, which could create higher level of information leakage. Another issue is lacking
dynamic federation and agile mechanism in FIM systems [90]. It is an architectural concern and requires
further investigation.
Figure 5 represents the basic functionality of IDM that consists of eight steps: login, requesting
application or data, requesting token for ID verification, generating token, verifying it and
sending/accessing the data/application. The user logs in IDM through his login ID (step 1) and requests
to access application/data from the cloud (step 2) simultaneously. The cloud asks the user for a suitable
token to be generated by the IDM for further authentication (step 3). The user requests the token from
the IDM (step 4). The IDM generates the token and shares it with the user and the cloud (step 5). The
user sends the token to the cloud in order to complete the step for final authentication (step 6). The cloud
compares the token sent by the user and that sent by the IDM (step 7). Finally, if the verification
succeeds, the cloud grants access to the user. There are three major standards to generate tokens in IDM
namely—SAML, OpenID and Information Card. SAML consists of different sets of technical standards
in order to implement the FIM. The notable service designed by SAML is single sign-on. It has been
deployed widely and follows the strict security/privacy requirements, e.g., enterprise, governments and
telecom [91]. OpenID is similar to SAML except it provides a smaller set of functions together with
simple expressions of identity related data [91]. In Information Card standard, identities are managed as
a set of cards. In the real word, a person usually has a set of cards such as national ID and driving license
in order to represent her and all these cards are used for different purposes. The same mechanism has
been applied in Information Card standards.
 
Computers 2014, 3 25
Figure 1. Federated Identity Management System.
Leandro et al. [89] propose multi-tenancy authorization system for cloud computing using SAML
standards (Shibboleth [92]). They promote the use of Shibboleth as access control system without using
a trusted third party [89]. Shibboleth consists of four components (1) handle service—designated to
authenticate user and issue handle token to the user; (2) attribute authority—designated to handle
requests for software product attributes and apply corresponding privacy policy; (3) directory service—
attribute storage of local user and (4) authentication mechanism–designated for user authentication with
central service through login/password. It provides strong authorization but not authentication. In other
words, it is difficult to steal identity during the running session once the user is authenticated with
Shibboleth. However, Shibboleth does not provide a mechanism to ensure the legitimacy of the person
connected with the system. Illegitimate person with valid username and password can avail the services
without being double-checked. With this argument, the use of shibboleth does not guarantee complete
secure transactions. Moreover, the multi-tenancy authorization system generates separate identity
provider for each user/organization where each identity provider is using same policies. This particular
architecture design helps users to modify security policies according to their need. However, outsourcing
identity providers few concerns [93] including: (1) how to make sure that there will be no shift of data
and processes to another location; (2) how to delete data after expiration of contract and (3) how to avoid
both accidental and deliberate interference across the domain of clouds. In principle, there is no scheme
to match the access control requirements with those that are provided
by cloud providers. Organizations have no control over their data even after signing a contract with a
cloud provider because it is not an easy task to enforce that the cloud provider will always meet the
enterprise’s requirements.
Another concept of central approach in IDM systems is discussed in [94,95]. Angin et al. in [94]
propose entity-centric approach called Active Bundle Scheme for IDM with comparison of application-
Computers 2014, 3 26
centric approach. This approach allows the entity to (1) create/manage its digital identities in order to
authenticate in such a way that it does not reveal its actual identity and relationship between identities
to vendor/service providers and (2) to protect personally identifiable information from unauthorized
access. The same concept has been discussed in [89] except that Angin et al. do not implement or validate
the solution. Identity-centric IDM is rationale response for the need of trust
and security, generated by business explosion and social transaction, facilitating the exploit of an everincreasing amount of personal data. The work in [74] refers to a particular type of Internet where trust
and security are native, by design. This concept can be achieved through (1) total separation of storage
of personal data and their exploitation by organizations and (2) through disaggregating organization
centric data systems to re-aggregation around identity-centric systems.
5. Discussion
Cloud computing is an emerging paradigm that involves all the basic components of computing
such as end-user machines (PCs), communication networks, access management systems and cloud
infrastructures. To achieve comprehensive cloud security, the data and cloud infrastructure must be
protected against known/unknown attacks across all cloud components. The number of browser based
attacks in 2011 increased from 580,371,937 to 946,393,693 [96]. This notable increase is mainly due to
the wide adoption of cloud computing which makes the platform very attractive for attackers due to the
growing value of the data assets and resources available on the clouds. Unfortunately, we cannot protect
the cloud-computing infrastructure from all the known/unknown attacks because it requires additional
computational overhead and resources. Current security solutions like IDS, DIDS, firewalling,
outsourcing the identity management systems, installing antivirus, etc., [97-102] are expensive and
degrade performance. Therefore, the major cloud security research challenge lies not only in providing
high level security measures but also in doing so with minimum resources and reduced performance
degradation.
Most of cloud vendors falsely claim to provide secure data and computational environments for
cloud users. However, for such claims to be realistic, collective efforts are required at higher levels
(e.g., governing bodies) instead of leaving it to individual organizations. Our current work helps in
achieve that goal by providing a comprehensive study of the attacks against clouds, establishing
dependencies among various attacks, and correlating attacks to vulnerabilities across various cloud
components. This study can support the endeavors to provide preventive measures as well as proactive
tools in defending the clouds. Using this study, we found that data and system security should be
embedded in the design of cloud architecture to achieve better security. Moreover, security measures
should be dynamic and autonomous. Cloud computing infrastructure is changing fast requiring security
measures and policies to be updated regularly at the same pace to match the changing behavior of the
clouds. Furthermore, licensing is crucial to the security of clouds. Standard policies should be strictly
implemented in clouds and organizational/governing bodies should visit clouds’ staff and infrastructure
on regular bases to evaluate the efficiency of the security precautions adopted by the vendors. The
statistics for attacks, occurring in any cloud, should be publically available to determine the reliability
of cloud vendors. This type of sharing helps other cloud’s security experts to guard against new attacks.
Also, it is extremely important to holistically investigate the various cloud security related parameters 
Computers 2014, 3 27
including risks, threats, challenges, vulnerabilities, and attacks. The possibility of being attacked can be
reduced by deeply understanding the dependencies among these parameters. Finally, note that
virtualization is a backbone of cloud computing. However, the concept of using virtualization in cloud
computing is not yet mature as there are numerous number of attacks that target the virtualization
environment. Examples of these attacks include information leakage during VM migration, service theft
by manipulating VMs, uploading malicious VMs on cloud server, and rolling back VMs. Therefore, it
is extremely important to develop reliable schedulers that, by design, contain sufficient security
mechanisms.
We have identified a few areas that are still unattended in cloud computing security such as auditing,
and migration of data from one cloud to another. Emphasis in current research has always been on fast
performance and low cost services, but the quality (e.g., availability, scalability, reliability, etc.) of
service has not been seriously considered. Non-functional requirements with respect to autonomous IaaS
node structure is still not much explored. Another big concern is related with data. Data migration from
one cloud to another is not achievable, at this moment, because of the heterogeneous nature of clouds.
Moreover, clouds lack the tools that ensure that user data has been deleted from the cloud if the contract
has expired. These data privacy threats require researchers’ attention to provide some standards
for permanent data deletion. We plan in the future to explore the possibility of providing suitable
frameworks for DIDS for heterogeneous clouds together with scheduling algorithms for Green IT.
Other related research issues in the area of cloud infrastructure include mobile computing challenges
[103,104]. In mobile platforms, limited memory, low processor speed and higher computational
requirements create hurdles in the efforts to provide best performance on these platforms. In addition to
this, mobile applications provide higher level of threat, as there is a weak or even no security “check and
balance” on application’s development. It has been claimed in [91], that 20% of the 48,000 applications,
in android market, allow third party applications to access your sensitive data as well as allowing it to
make calls and send texts without user consents. Apple Inc. has implemented a security framework in
which each application should be submitted to Apple security team to determine the threat to user data
or system before including it in the App Store.
6. Conclusions
The adoption of cloud computing paradigm is continuously growing. In 2010, the IT spending in
America to migrate to cloud computing solutions was estimated at $20 billion. Analysts believe that the
cost reduction factor in cloud computing will further accelerate the adoption of cloud computing in the
public sectors. With the massive growth in cloud computing adoption, the security attracted the attention
of researchers and practitioners but still has not received enough attention.
In this work, we conduct a survey on the current cloud security issues and the state-of-the-art security
solutions. We identify 28 cloud security issues such as firewall misconfigurations, malicious insiders,
tampered binaries, multi-tenancy, side channels, weak browser security, and mobility. Then, we
classify these issues into five security categories, namely: security standards, network, access, cloud
infrastructure, and data. We also identify nine attack classes that target the clouds and present variable
incidents of each attack such phishing, fate sharing, botnet, and malware injection. For each attack class,
we present the state-of-the-art countermeasures and provide a comparative analysis of the effectiveness 
Computers 2014, 3 28
and the shortcomings of the proposed solutions. Finally, we present and evaluate the effectiveness of
the state-of-the-art general countermeasures for cloud security attacks including intrusion detection
systems, autonomous systems, and federated identity management systems. We also highlight the
shortcomings of these systems that include the high communication and computation overhead and the
detection efficiency and coverage.
Conflicts of Interest
The authors declare no conflict of interest.
References
1. Tripathi, A.; Mishra, A. Cloud computing security considerations. In Proceedings of the 2011
IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC),
Xi’an, China, 14–16 September 2011; pp. 1–5.
2. Wang, J.-J.; Mu, S. Security issues and countermeasures in cloud computing. In Proceedings of
the 2011 IEEE International Conference on Grey Systems and Intelligent Services (GSIS),
Nanjing, China, 15–18 September 2011; pp. 843–846.
3. Final Version of NIST Cloud Computing Definition Published. Available online:
http://www.nist.gov/itl/csd/cloud-102511.cfm (accessed on 25 August 2013).
4. Lv, H.; Hu, Y. Analysis and research about cloud computing security protect policy. In
Proceedings of the 2011 International Conference on Intelligence Science and Information
Engineering (ISIE), Wuhan, China, 20–21 August 2011; pp. 214–216.
5. Mell, P and Grance, T. The NIST Definition of Cloud Computing, NIST, USA. available at:
http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf, USA, 2009.
6. Jain, P.; Rane, D.; Patidar, S. A survey and analysis of cloud model-based security for
computing secure cloud bursting and aggregation in renal environment. In Proceedings of the 2011
World Congress on Information and Communication Technologies (WICT), Mumbai, India, 11–
14 December 2011; pp. 456–461.
7. Gowrigolla, B.; Sivaji, S.; Masillamani, M.R. Design and auditing of cloud computing security.
In Proceedings of the 2010 5th International Conference on Information and Automation for
Sustainability (ICIAFs), Colombo, Sri Lanka, 17–19 December 2010; pp. 292–297.
8. Houmansadr, A.; Zonouz, S.A.; Berthier, R. A cloud-based intrusion detection and response
system for mobile phones. In Proceedings of the 2011 IEEE/IFIP 41st International Conference on
Dependable Systems and Networks Workshops (DSN-W), Hong Kong, China, 27–30 June 2011;
pp. 31–32.
9. M. Taifi, J. Y. Shi, A. Khreishah, “SpotMPI: A Framework for Auction-based HPC Computing
Using Amazon Spot Instances”, in Proc. of the International Symposium on Advances of
Distributed Computing and Networking (ADCN), 2011.
10. Sabahi, F. Virtualization-level security in cloud computing. In Proceedings of the 2011 IEEE 3rd
International Conference on Communication Software and Networks (ICCSN), Xi’an, China, 27–
29 May 2011; pp. 250–254. 
Computers 2014, 3 29
11. Wang, C.; Wang, Q.; Ren, K.; Lou, W. Towards secure and dependable storage services in cloud
computing. IEEE Trans. Serv. Comput. 2012, 5, 220–232.
12. Lingfeng, C.; Hoang, D.B. Towards scalable, fine-grained, intrusion-tolerant data protection
models for healthcare cloud. In Proceedings of the 2011 IEEE 10th International Conference on
Trust, Security and Privacy in Computing and Communications (TrustCom), Changsha, China,
16–18 November 2011; pp. 126–133.
13. Morin, J.; Aubert, J.; Gateau, B. Towards cloud computing SLA risk management: Issues and
challenges. In Proceedings of the 2012 45th Hawaii International Conference on System Science
(HICSS), Maui, HI, USA, 4–7 January 2012; pp. 5509–5514.
14. Khalil, I.M. ELMO: Energy aware local monitoring in sensor networks. IEEE Trans. Dependable
Secur. Comput. 2011, 8, 523–536.
15. Khalil, I.; Bagchi, S. MISPAR: Mitigating stealthy packet dropping in locally-monitored multihop wireless Ad Hoc networks. In Proceedings of the 4th International Conference on Security and
Privacy in Communication Netowrks (SecureComm ’08), Istanbul, Turkey, 22–25 September
2008; ACM: New York, NY, USA, 2008; article 28, pp. 1–10.
16. Khalil, I. MCC: Mitigating colluding collision attacks in wireless sensor networks. In Proceedings
of the 2010 IEEE Global Telecommunications Conference (GLOBECOM 2010), Miami, FL,
USA, 6–10 December 2010; pp. 1–5.
17. M. Hayajneh, I. Khalil and Y. Gadallah, “An OFDMA-based MAC protocol for under water
acoustic wireless sensor network,” Proceedings of the 2009 ACM International Conference on
Wireless Communications and Mobile Computing (IWCMC’09), Leipzig, Germany, June 21 – 24
2009, pp. 810-814.
18. Khalil, I.; Hayajneh, M.; Awad, M. SVNM: Secure verification of neighborhood membership in
static multi-hop wireless networks. In Proceedings of the IEEE Symposium on Computers and
Communications, 2009, ISCC 2009, Sousse, 5–8 July 2009; pp. 368–373.
19. Sengupta, S.; Kaulgud, V.; Sharma, V.S. Cloud computing security—Trends and research
directions. In Proceedings of the 2011 IEEE World Congress on Services (SERVICES),
Washington, DC, USA, 4–9 July 2011; pp. 524–531.
20. Chow, R.; Golle, P.; Jakobsson, M.; Shi, E.; Staddon, J.; Masuoka, R.; Molina, J. Controlling data
in the cloud: Outsourcing computation without outsourcing control. In Proceedings of the 2009
ACM Workshop on Cloud Computing Security, Chicago, IL, USA, 13 November 2009; ACM
Press: New York, NY, USA, 2009; pp. 85–90.
21. Samarati, P.; di Vimercati, S.D.C. Data protection in outsourcing scenarios: Issues and directions.
In Proceedings of the 5th ACM Symposium on Information, Computer and Communications
Security (ASIACCS ’10), Chicago, IL, USA, 4–8 October 2010; ACM: New York, NY, USA,
2010; pp. 1–14.
22. Popovic, O.; Jovanovic, Z.; Jovanovic, N.; Popovic, R. A comparison and security analysis of the
cloud computing software platforms. In Proceedings of the 2011 10th International Conference on
Telecommunication in Modern Satellite Cable and Broadcasting Services (TELSIKS), Nis, Serbia,
5–8 October 2011; Volume 2, pp. 632–634. 
Computers 2014, 3 30
23. Gul, I.; ur Rehman, A.; Islam, M.H. Cloud computing security auditing. In Proceedings of the 2011
The 2nd International Conference on Next Generation Information Technology (ICNIT),
Gyeongju, Korea, 21–23 June 2011; pp. 143–148.
24. Kandukuri, B.R.; Paturi, V.R.; Rakshit, A. Cloud security issues. In Proceedings of the
IEEE International Conference on Services Computing, 2009 (SCC ’09), Bangalore, India,
21–25 September 2009; pp. 517–520.
25. Chen, Z.; Yoon, J. IT auditing to assure a secure cloud computing. In Proceedings of the 2010 6th
World Congress on Services (SERVICES-1), Miami, FL, USA, 5–10 July 2010; pp. 253–259.
26. Ryan, G.W.; Bernard, H.R. Data Management and Analysis Methods. Available online:
http://www.rand.org/pubs/external_publications/EP20000033.html (accessed on 25 August 2013).
27. Holloway, I.; Todres, L. The status of method: Flexibility, consistency and coherence. Qual. Res.
2003, 3, 345–357.
28. Hashizume, K.; Rosado, D.G.; Fernández-Medina, E.; Fernandez, E.B. An analysis of security
issues for cloud computing. J. Internet Serv. Appl. 2013, 4, 5.
29. Zissis, D.; Lekkas, D. Addressing cloud computing security issues. Future Gener. Comput. Syst.
2012, 28, 583–592.
30. Whaiduzzaman, M.; Sookhak, M.; Gani, A.; Buyya, R. A survey on vehicular cloud computing.
J. Netw. Comput. Appl. 2013, doi:10.1016/j.jnca.2013.08.004.
31. Braun, V.; Clarke, V. Using thematic analysis in psychology. Qual. Res. Psychol. 2006, 3, 77–101.
32. A Survey on Cloud Computing Security, Challenges and Threats|Whitepapers|TechRepublic.
Available online: http://www.techrepublic.com/whitepapers/a-survey-on-cloud-computingsecurity-challenges-and-threats/3483757 (accessed on 18 March 2012).
33. Thalmann, S.; Bachlechner, D.; Demetz, L.; Maier, R. Challenges in cross-organizational security
management. In Proceedings of the 2012 45th Hawaii International Conference on System Science
(HICSS), Maui, HI, USA, 4–7 January 2012; pp. 5480–5489.
34. Riquet, D.; Grimaud, G.; Hauspie, M. Large-scale coordinated attacks: Impact on the cloud
security. In Proceedings of the 2012 Sixth International Conference on Innovative Mobile and
Internet Services in Ubiquitous Computing (IMIS), Palermo, Italy, 4–6 July 2012; pp. 558–563.
35. Gonzalez, N.; Miers, C.; Redigolo, F.; Carvalho, T.; Simplicio, M.; Naslund, M.; Pourzandi, M.
A quantitative analysis of current security concerns and solutions for cloud computing. In
Proceedings of the 2011 IEEE Third International Conference on Cloud Computing Technology
and Science (CloudCom), Athens, Greece, 29 November–1 December 2011; pp. 231–238.
36. Rachel Suresh, N.; Mathew, S.V. Security concerns for cloud computing in aircraft data networks.
In Proceedings of the 2011 International Conference for Internet Technology and Secured
Transactions (ICITST), Abu Dhabi, United Arab Emirates, 11–14 December 2011; pp. 132–136.
37. Fangfei, Z.; Goel, M.; Desnoyers, P.; Sundaram, R. Scheduler vulnerabilities and coordinated
attacks in cloud computing. In Proceedings of the 2011 10th IEEE International Symposium on
Network Computing and Applications (NCA), Cambridge, MA, USA, 25–27 August 2011;
pp. 123–130.
38. Who Can You Trust in the Cloud? A Review of Security Issues within Cloud Computing.
Available online: http://www.drjeffdaniels.com/1/post/2011/10/who-can-you-trust-in-the-cloud
-a-review-of-security-issues-within-cloud-computing.html (accessed on 18 March 2012). 
Computers 2014, 3 31
39. Mollet, N.G. Cloud Computing Security. Bachelor of Engineering Degree Information Technology
Thesis, Helsinki Metropolia University of Applied Sciences, Helsinki, Finland,
11 April 2011.
40. Behl, A. Emerging security challenges in cloud computing: An insight to cloud security
challenges and their mitigation. In Proceedings of the 2011 World Congress on Information and
Communication Technologies (WICT), Mumbai, India, 11–14 December 2011; pp. 217–222.
41. Mathisen, E. Security challenges and solutions in cloud computing. In Proceedings of the 2011 5th
IEEE International Conference on Digital Ecosystems and Technologies Conference (DEST),
Daejeon, Korea, 31 May–3 June 2011; pp. 208–212.
42. Bhardwaj, A.; Kumar, V. Cloud security assessment and identity management. In Proceedings of
the 2011 14th International Conference on Computer and Information Technology (ICCIT),
Dhaka, Bangladesh, 22–24 December 2011; pp. 387–392.
43. Mahmood, Z. Data location and security issues in cloud computing. In Proceedings of the 2011
International Conference on Emerging Intelligent Data and Web Technologies (EIDWT), Tirana,
Albania, 7–9 September 2011; pp. 49–54.
44. Gruschka, N.; Jensen, M. Attack surfaces: A taxonomy for attacks on cloud services. In
Proceedings of the 2010 IEEE 3rd International Conference on Cloud Computing (CLOUD),
Miami, FL, USA, 5–10 July 2010; pp. 276–279.
45. Cherkasova, L.; Gupta, D.; Vahdat, A. Comparison of the three CPU schedulers in Xen.
ACM SIGMETERICS Perform. Eval. Rev. 2007, 35, 42–51.
46. Fu, W.; Li, X. The study on data security in cloud computing based on virtualization. In
Proceedings of the 2011 International Symposium on IT in Medicine and Education (ITME),
Cuangzhou, China, 9–11 December 2011; Volume 2, pp. 257–261.
47. Kim, H.; Lim, H.; Jeong, J.; Jo, H.; Lee, J. Task-aware virtual machine scheduling for I/O
Performance. In Proceedings of the 2009 ACM SIGPLAN/SIGOPS International Conference on
Virtual Execution Environments, Washington, DC, March 11-13, 2009; pp. 101–110.
48. Cherkasova, L.; Gupta, D.; Vahdat, A. When virtual is harder than real: Resource allocation
challenges in virtual machine based IT environments. Technical Report HPL-2007-25, HP
Laboratories Palo. Alto, Feb. 2007.
49. Karnwal, T.; Sivakumar, T.; Aghila, G. A comber approach to protect cloud computing against
XML DDoS and HTTP DDoS attack. In Proceedings of the 2012 IEEE Students’ Conference on
Electrical, Electronics and Computer Science (SCEECS), Bhopal, India, 1–2 March 2012; pp. 1–
5.
50. Liu, S.-T.; Chen, Y.-M. Retrospective detection of malware attacks by cloud computing. In
Proceedings of the 2010 International Conference on Cyber-Enabled Distributed Computing and
Knowledge Discovery (CyberC), Huangshan, China, 10–12 October 2010; pp. 510–517.
51. Oberheide, J.; Cooke, E.; Jahanian, F. CloudAV: N-version antivirus in the network cloud. In
Proceedings of the 17th Conference on Security Symposium (SS ’08); USENIX Association:
Berkeley, CA, USA, 2008; pp. 91–106.
52. Martignoni, L.; Paleari, R.; Bruschi, D. A framework for behavior-based malware analysis in the
cloud. In Proceedings of the 5th International Conference on Information Systems Security 
Computers 2014, 3 32
(ICISS ’09), Kolkata, India, 14–18 December 2009; Springer-Verlag: Berlin, Heidelberg, 2009;
pp. 178–192.
53. Khorshed, M.T.; Ali, A.B.M.S.; Wasimi, S.A. A survey on gaps, threat remediation challenges and
some thoughts for proactive attack detection in cloud computing. Future Gener. Comput. Syst.
2012, 28, 833–851.
54. Aviram, A.; Hu, S.; Ford, B.; Gummadi, R. Determinating timing channels in compute clouds. In
Proceedings of the 2010 ACM Workshop on Cloud Computing Security Workshop (CCSW ’10);
ACM: New York, NY, USA, 2010; pp. 103–108.
55. Hlavacs, H.; Treutner, T.; Gelas, J.; Lefevre, L.; Orgerie, A. Energy consumption side-channel
attack at virtual machines in a cloud. In Proceedings of the 2011 IEEE Ninth International
Conference on Dependable, Autonomic and Secure Computing (DASC), Sydney, NSW, Australia,
12–14 December 2011; pp. 605–612.
56. Rocha, F.; Correia, M. Lucy in the sky without diamonds: Stealing confidential data in the cloud.
In Proceedings of the 2011 IEEE/IFIP 41st International Conference on Dependable Systems and
Networks Workshops (DSNW ’11), Hong Kong, China, 27–30 June 2011; IEEE Computer
Society: Washington, DC, USA, 2011; pp. 129–134.
57. Ristenpart, T.; Tromer, E.; Shacham, H.; Savage, S. Hey, you, get off of my cloud: Exploring
information leakage in third-party compute clouds. In Proceedings of the 16th ACM Conference
on Computer and Communications Security (CCS ’09), Chicago, IL, USA, 9–13 November 2009;
ACM: New York, NY, USA, 2009; pp. 199–212.
58. Top Threats to Cloud Computing V1.0; Cloud Security Alliance: March 2010.
59. Grosse, E.; Howie, J.; Ransome, J.; Reavis, J.; Schmidt, S. Cloud computing roundtable.
IEEE Secur. Priv. 2010, 8, 17–23.
60. Lin, W.; Lee, D. Traceback attacks in cloud—Pebbletrace botnet. In Proceedings of the 2012 32nd
International Conference on Distributed Computing Systems Workshops (ICDCSW), Macau,
China, 18–21 June 2012; pp. 417–426.
61. Kourai, K.; Azumi, T.; Chiba, S. A self-protection mechanism against stepping-stone attacks for
IaaS clouds. In Proceedings of the UIC/ATC, 2012; pp. 539–546.
62. Liu, B.; Xu, E.; Wang, J.; Wei, Z.; Xu, L.; Zhao, B.; Su, J. Thwarting audio steganography attacks
in cloud storage systems. In Proceedings of the 2011 International Conference on Cloud and
Service Computing (CSC), Hong Kong, China, 12–14 December 2011; pp. 259–265.
63. Mazurczyk, W.; Szczypiorski, K. Is cloud computing steganography-proof? In Proceedings of the
2011 Third International Conference on Multimedia Information Networking and Security
(MINES ’11), Shanghai, China, 4–6 November 2011; IEEE Computer Society: Washington, DC,
USA, 2011; pp. 441–442.
64. Antunes, N.; Vieira, M. Defending against web application vulnerabilities. Computer 2012, 45,
66–72.
65. Parno, B.; Lorch, J.R.; Douceur, J.R.; Mickens, J.; McCune, J.M. Memoir: Practical state
continuity for protected modules. In Proceedings of the 2011 IEEE Symposium on Security and
Privacy (SP ’11), Oakland, CA, USA, 22–25 May 2011; IEEE Computer Society: Washington,
DC, USA, 2011; pp. 379–394. 
Computers 2014, 3 33
66. Zeus Bot Found Using Amazon’s EC2 as C&C Server. Available online:
http://www.theregister.co.uk/2009/12/09/amazon ec2 bot control channel/ (accessed on: Feb 1,
2014).
67. Google Cloud Platform Used for Botnet Control. Available online: http://www.infosecuritymagazine.com/view/5115/google-cloud-platform-used-for-botnet-control/ (accessed on: Feb 1,
2014).
68. Raytheon UK Targeted in Cloud-Based Attack. Available online:
http://www.zdnet.co.uk/news/security-threats/2011/10/12/raytheon-uk-targeted-in-cloud-basedattack-40094173/ (accessed on: Feb 1, 2014).
69. Srivastava, A.; Giffin, J. Tamper-resistant, application-aware blocking of malicious network
connections. In Proceedings of the 11th International Symposium, RAID 2008, Cambridge, MA,
USA, 15–17 September 2008; pp. 39–58.
70. Tupakula, U.; Varadharajan, V.; Akku, N. Intrusion detection techniques for infrastructure as a
service cloud. In Proceedings of the 2011 IEEE Ninth International Conference on Dependable,
Autonomic and Secure Computing (DASC), Sydney, Australia, 12–14 Dec. 2011; pp. 744–751.
71. Szefer, J.; Lee, R.B. Architectural support for hypervisor-secure virtualization.
SIGARCH Comput. Arch. News 2012, 40, 437–450.
72. Lo, C.-C.; Huang, C.-C.; Ku, J. A cooperative intrusion detection system framework for cloud
computing networks. In Proceedings of the 2010 39th International Conference on Parallel
Processing Workshops (ICPPW), San Diego, CA, USA, 13–16 September 2010; pp. 280–284.
73. Vieira, K.; Schulter, A.; Westphall, C.B.; Westphall, C.M. Intrusion detection for grid and cloud
computing. IT Prof. 2010, 12, 38–43.
74. Wang, D.; Zhou, Z. Application of cloud model in intrusion detection. In Proceedings of the 2010
2nd International Conference on e-Business and Information System Security (EBISS), Wuhan,
China, 22–23 May 2010; pp. 1–4.
75. Van athi, R.; Gunasekaran, S. Comparison of network intrusion detection systems in cloud
computing environment. In Proceedings of the 2012 International Conference on Computer
Communication and Informatics (ICCCI), Coimbatore, India, 10–12 January 2012; pp. 1–6.
76. Roschke, S.; Cheng, F.; Meinel, C. Intrusion detection in the cloud. In Proceedings of the
Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing, 2009
(DASC ’09), Chengdu, China, 12–14 December 2009; pp. 729–734.
77. Zargar, S.T.; Takabi, H.; Joshi, J.B.D. DCDIDP: A distributed, collaborative, and data-driven
intrusion detection and prevention framework for cloud computing environments. In Proceedings
of the 2011 7th International Conference on Collaborative Computing: Networking, Applications
and Worksharing (CollaborateCom), Orlando, FL, USA, 15–18 October 2011; pp. 332–341.
78. Dastjerdi, A.V.; Bakar, K.A.; Tabatabaei, S.G.H. Distributed intrusion detection in clouds using
mobile agents. In Proceedings of the Third International Conference on Advanced Engineering
Computing and Applications in Sciences, 2009 (ADVCOMP ’09), Sliema, Malta, 11–16 October
2009; pp. 175–180.
79. Ye, D.; Bai, Q.; Zhang, M.; Ye, Z. P2P distributed intrusion detections by using mobile agents. In
Proceedings of the Seventh IEEE/ACIS International Conference on Computer and Information
Science, 2008 (ICIS 08), Portland, OR, USA, 14–16 May 2008; pp. 259–265. 
Computers 2014, 3 34
80. Kannadiga, P.; Zulkernine, M. DIDMA: A distributed intrusion detection system using mobile
agents. In Proceedings of the Sixth International Conference on Software Engineering, Artificial
Intelligence, Networking and Parallel/Distributed Computing, and First ACIS International
Workshop on Self-Assembling Wireless Networks, 23–25 May 2005; pp. 238–245.
81. Erdil, D.C. Dependable autonomic cloud computing with information proxies. In Proceedings of
the 2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and
Phd Forum (IPDPSW), Shanghai, China, 16–20 May 2011; pp. 1518–1524.
82. Doelitzscher, F.; Reich, C.; Knahl, M.; Clarke, N. An autonomous agent based incident
detection system for cloud environments. In Proceedings of the 2011 IEEE Third International
Conference on Cloud Computing Technology and Science (CloudCom), Athens, Greece,
29 November–1 December 2011; pp. 197–204.
83. Balen, D.; Westphall, C.; Westphall, C. Experimental assessment of routing for grid and cloud.
In Proceedings of the Tenth International Conference on Networks (ICN 2011); St. Maarten, The
Netherlands Antilles, January 23-28, 2011, pp. 341–346.
84. Sodhi, B.; Prabhakar, T.V. A cloud architecture using smart nodes. In Proceedings of the
2011 IEEE Asia-Pacific Services Computing Conference (APSCC), Jeju Island, Korea,
12–15 December 2011; pp. 116–123.
85. Yazir, Y.O.; Matthews, C.; Farahbod, R.; Neville, S.; Guitouni, A.; Ganti, S.; Coady, Y. Dynamic
resource allocation in computing clouds using distributed multiple criteria decision analysis. In
Proceedings of the 2010 IEEE 3rd International Conference on Cloud Computing (CLOUD),
Miami, FL, USA, 5–10 July 2010; pp. 91–98.
86. Mareschal, B. Aide a la Decision Multicritere: Developpements Recents des Methodes
PROMETHEE; Cahiers du Centre d’Etudes en Recherche Operationelle: Bruxelles, Belgium,
1987; pp. 175–241.
87. Uchida, N.; Takahata, K.; Shibata, Y. Proposal of overlay cloud computing system by virtual
autonomous network configuration. In Proceedings of the 2011 International Conference on P2P,
Parallel, Grid, Cloud and Internet Computing (3PGCIC), Barcelona, Spain, 26–28 October 2011;
pp. 307–310.
88. Bishop, M. Computer Security: Art and Science; Addison-Wesley Professional: Reading, MA,
USA, 2002.
89. Leandro, M.A.P.; Nascimento, T.J.; dos Santos, D.R.; Westphall, C.M.; Westphall, C.B. Multitenancy authorization system with federated identity for cloud-based environments using
shibboleth. In Proceedings of the Eleventh International Conference on Networks, 2012;
pp. 88–93.
90. Sanchez, R.; Almenares, F.; Arias, P.; Diaz-Sanchez, D.; Marin, A. Enhancing privacy and
dynamic federation in IdM for consumer cloud computing. IEEE Trans. Consum. Electron. 2012,
58, 95–103.
91. Revealed: Why Android Beats iPhone for Organized Crime. Available online:
http://blogs.computerworld.com/16392/security_android_beats_iphone_for_crime (accessed on
13 January 2013).
92. Oxford English Dictionary; In Shibboleth; 1989. 
Computers 2014, 3 35
93. Albeshri, A.; Caelli, W. Mutual protection in a cloud computing environment. In Proceedings
of the 2010 12th IEEE International Conference on the High Performance Computing and
Communications (HPCC), Melbourne, VIC, Australia, 1–3 September 2010; pp. 641–646.
94. Angin, P.; Bhargava, B.; Ranchal, R.; Singh, N.; Linderman, M.; Othmane, L.B.; Lilien, L.
An entity-centric approach for privacy and identity management in cloud computing. In
Proceedings of the 2010 29th IEEE Symposium on Reliable Distributed Systems, New Delhi,
India, 31 October–3 November 2010; pp. 177–183.
95. Ates, M.; Ravet, S.; Ahmat, A.M.; Fayolle, J. An identity-centric internet: Identity in the cloud,
identity as a service and other delights. In Proceedings of the 2011 Sixth International Conference
on Availability, Reliability and Security (ARES), Vienna, Austria, 22–26 August 2011; pp. 555–560.
96. Kaspersky Security Bulletin. Statistics 2011. Available online: http://www.securelist.com/en/
analysis/204792216/Kaspersky_Security_Bulletin_Statistics_2011 (accessed on 13 January 2013).
97. You, P.; Peng, Y.; Liu, W.; Xue, S. Security issues and solutions in cloud computing. In
Proceedings of the 2012 32nd International Conference on Distributed Computing Systems
Workshops (ICDCSW), Macau, China, 18–21 June 2012; pp. 573–577.
98. Bhadauria, R.; Chaki, R.; Chaki, N.; Sanyal, S. A Survey on Security Issues in Cloud Computing;
Cornell University Library, USA, 2013. Available at: http://arxiv.org/abs/1109.5388. (Accessed
on: Feb 1, 2014).
99. Kanday, R. A survey on cloud computing security. In Proceedings of the 2012 International
Conference on Computing Sciences (ICCS), Phagwara, India, 14–15 September 2012; pp. 302–311.
100. Zhou, M.; Zhang, R.; Xie, W.; Qian, W.; Zhou, A. Security and privacy in cloud computing: A
survey. In Proceedings of the 2010 Sixth International Conference on Semantics Knowledge and
Grid (SKG), Beijing, China, 1–3 November 2010; pp. 105–112.
101. Khalil, I.; Khreishah, A.; Bouktif, A.; Ahmad, A. Security Concerns in Cloud Computing. In
Proceedings of the 10th International Conference on Information Technology: New Generations,
April 15-17, 2013, Las Vegas, USA; pp. 412-416.
102. Ren, K.; Wang, C.; Wang, Q. Security challenges for the public cloud. IEEE Internet Comput.
2012, 16, 69–73.
103. R. K. Panta, S. Bagchi and I. Khalil, “Efficient wireless reprogramming through reduced
bandwidth usage and opportunistic sleeping,” Ad Hoc Networks (an Elsevier Journal), Volume 7,
Issue 1, January 2009, pp. 42-62.
104. I. Khalil, “MCC: Mitigating colluding collision attacks in wireless sensor networks,” Proceedings
of the IEEE Global Communications Conference (IEEE GLOBECOM’10), December 6 – 10,
2010, Miami, Florida, USA, pp. 1-5..
105. http://blog.scalar.ca/Blog/bid/87248/Mitigating-common-cloud-computing-risks. (Accessed on:
Feb 1, 2014).
© 2014 by the authors; licensee MDPI, Basel, Switzerland. This article is an open access article
distributed under the terms and conditions of the Creative Commons Attribution license
(http://creativecommons.org/licenses/by/3.0/). 
200
Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter 14
INTRODUCTION
Cloud Service Providers offer an opportunity for
organisations to make resources available online.
These resources can range from extensive customer relationship management (CRM) software
to the relatively widespread online email access.
Cloud computing allows these companies to
benefit from porting their existing systems to an
online environment where they can be accessed by
anyone with the required privileges (NIST, 2010).
The most appealing advantage of this is that the
cloud service provider takes care of the required
hardware, software and networking including
the associated costs. The cloud service provider
will then be able to ‘rent out’ what the company
requires; this means that the company will only
ever use the resources necessary. The service provider will have the hardware and software setup
to enable them to scale far and beyond what any
company will require, this means that they can
offer a ‘pay-as-you-go’ type service. The service
Kevin Curran
University of Ulster, Northern Ireland
Sean Carlin
University of Ulster, Northern Ireland
Mervyn Adams
University of Ulster, Northern Ireland
Security Issues in
Cloud Computing
ABSTRACT
Cloud Computing is a distributed architecture that centralizes server resources on a scalable platform
so as to provide on demand computing resources and services. Cloud computing has become a variable platform for companies to build their infrastructures upon. If companies are to consider taking
advantage of cloud based systems, they will be faced with the task of seriously re-assessing their current
security strategy, as well as the cloud-specific aspects that need to be assessed. The authors outline in
this chapter what cloud computing is, the various cloud deployment models, and the main security risks
and issues that are currently present within the cloud computing industry.
DOI: 10.4018/978-1-4666-0957-0.ch014
201
Security Issues in Cloud Computing
provider will be able to offer similar resources to
multiple companies, meaning that they can offer
this at a reduced price (Sheriff, 2011).
Cloud computing is not a new technology but
rather a new delivery model for information and
services using existing technologies. It uses the
internet infrastructure to allow communication
between client side and server side services/applications (Weiss, 2007). Cloud service providers
(CSP’s) offer cloud platforms for their customers
to use and create their web services, much like
internet service providers offer costumers high
speed broadband to access the internet. CSPs
and ISPs both offer services. The cloud provides
a layer of abstraction between the computing resources and the low level architecture involved.
The customers do not own the actual physical
infrastructure but merely pay a subscription fee
and the cloud service provider grants them access to the cloud resources and infrastructure.
A key concept is that the customers can reduce
expenditure on resources like software licenses,
hardware and other services (e.g. email) as they
can obtain all these things from one source, the
cloud service provider (Rangan, 2008; Siegele,
2008; Vogels, 2008). Recent studies have found
that disciplined companies achieved on average
an 18% reduction in their IT budget from cloud
computing and a 16% reduction in data centre
power costs (McFedries, 2008).
There are two initial forms of cloud computing, Public Cloud and Private Cloud. Within
Public Cloud computing companies pay a yearly
subscription to an external company such as
Amazon’s Elastic Compute Cloud (EC2) toward
storing data and the providing and facilitating the
running of application programs. Many companies
share the same infrastructure within the Public
Cloud, and the term given to this is Multitenant
Architectures. This term is significant because
a server is split up into virtual servers software
controlled slices allocated to customers, in essence
one server becomes many with many customers.
The Private Cloud would be the next progression
for many companies as the Private Cloud is in-part
managed in-house and is considered Hosted or
Corporate cloud. The cloud is managed within the
company’s domain and data storage is centralized
replacing the company’s previous infrastructure
as the network becomes virtualized. Most data
storage is handled in-house because of its sensitivity which must be protected. This is the most
secure option and the most expensive but still
cost effective compared to their older structures
in which the companies maintained themselves.
As Public Cloud is considered a multitenant
architecture, the Private Cloud is considered a
Proprietary Architecture which provides hosted
services to a limited number of people behind a
firewall. This firewall is located at the network
gateway server. Physical hardware resources such
as Servers are only allocated to one customer.
The fire wall allows public internet access also
accommodating VPN Virtual Private Networks
allowing company employees to connect to the
company intranet safely and securely from their
homes. The added feature of a VPN is the ability
to use public networks like the Internet and rely
on private leased lines. These restricted access
networks utilize the same cabling and routers as
a public network, and is categorized within a wide
area network. Virtualization toward this extent is
a relatively new concept within the IT industry,
which has really taken off since 2005, the three
main areas where virtualization is showing greatest
significance is within Virtual Networks, Storage
Virtualization and Server Virtualization. The combination of these three important elements provides
autonomic computing within the IT environment.
Within Network Virtualization, a methodology is
used to combine the availability of resources into
a network by splitting up the available bandwidth
into channels, and each is independent from one
another. This helps toward performance as each
one can be assigned and reassigned to a different device or server in real-time. Virtualization
disguises the true complexity of a network as it
breaks it up into manageable parts.
202
Security Issues in Cloud Computing
Storage Virtualization is the pooling of physical
storage from multiple network storage devices into
what could be considered as one singular storage
device. This pooling storage device is managed
by a central console. Server Virtualization is the
masking of server resources including the number and identity of individual physical servers,
processors, and operating systems from server
users. Designed and implemented in a way that
the user does not have to manage the complexity of server settings, while increasing resource
sharing and maintaining the capacity to expand
later. The combination of these three important
elements provides autonomic computing in which
the IT environment would manage itself. Within
a private cloud there would be an administrator
who would oversee the running of the Virtual
Network. We provide here an overview of the
key aspects of Cloud Computing.
THE CLOUD
Cloud computing has five key attributes which
grant it some advantages over similar technologies and these attributes include:
• Multitenancy (shared resources): Unlike
previous computing models, which assumed
dedicated resources dedicated to a single
user or owner, cloud computing is based
on a business model in which resources are
shared at the network, host and application
level.
• Massive scalability: Cloud computing provides the ability to scale to tens of thousands
of systems, as well as the ability to massively
scale bandwidth and storage space.
• Elasticity: Users can rapidly increase and decrease their computing resources as needed,
as well as release resources for other uses
when they are no longer required.
• Pay as you go: Users pay for only the resources they actually use and for only the
time they require them.
• Self-provisioning of resources: Users
self-provision resources, such as additional
systems (processing capability, software &
storage) and network resources (Mather et
al., 2009).
There is a buzz around cloud computing, as
users of the cloud services only have to pay for
what they use and the resources that they need to
cope with demanding situations can be adjusted
depending on the demand (Hamilton, 2008; Hosangar et al., 2008). This is recognized as the
cloud delivery model (SPI – see Figure 1) which
consists of three services known as Software-asa-service (SaaS), Platform-as-a-service (PaaS)
and Infrastructure-as-a-service (IaaS).
Software-as-a-service allows the users to
utilize various applications from the cloud rather
than using applications on their own computer
(Krebs, 2008). The cloud service provider would
usually provide some sort of software development environment to allow applications to be
developed for use within the cloud. The application programming interface (API) which the users
use to access and interact with the software allows
the user to use the software without having to
worry about how or where the data is being stored
or how much disk space is available as the cloud
service provider will manage this for them.
Platform-as-a-service operates at a lower level
than the SaaS. It is responsible for the management of the storage space, bandwidth allocation
and computing resources available for the applications. It retrieves the resources needed to
run the software and dynamically scales up these
resources when more is needed. This service holds
a key attribute of the cloud mentioned above as
self-provisioning of resources. Infrastructure-asa-service dynamically scales bandwidth allocation
and server resources for the cloud. This service 
203
Security Issues in Cloud Computing
allows the cloud to operate during high traffic/
demanding situations as resources are dynamically increased as they are needed. The pay as
you go attribute plays a large role in this service
as the user is charged for how much bandwidth
or server resources are needed.
There are three main types of cloud deployment models - public, private and hybrid clouds.
• Public Clouds: are the most common type
of cloud. This is where multiple customers
can access web applications and services
over the internet. Each individual customer
has their own resources which are dynamically provisioned by a third party vendor.
This third party vendor hosts the cloud for
multiple customers from multiple data centers, manages all the security, and provides
the hardware and infrastructure for the
cloud to operate. The customer has no control or insight into how the cloud is managed or what infrastructure is available.
• Private Clouds: emulate the concept of
cloud computing on a private network.
They allow users to have the benefits of
cloud computing without some of the pitfalls. Private clouds grant complete control
over how data is managed and what security measures are in place. This can lead
to users having more confidence and control. The major issue with this deployment
model is that the users have large expenditures as they have to buy the infrastructure
to run the cloud and also have to manage
the cloud themselves.
• Hybrid Clouds: incorporate both public
and private clouds (see figure 2) within the
same network. It allows the organisations
to benefit from both deployment models.
For example, an organisation could hold
sensitive information on their private cloud
and use the public cloud for handling large
traffic and demanding situations.
SECURITY IN THE CLOUD
One of the risks that people perceive concerning
the cloud is that cloud service providers may not
be able to scale their systems properly with large
amounts of usage (Ohlman et al., 2009). Privacy
is important for organisations, especially when
individual’s personal information or sensitive
information is being stored but it is not yet completely understood whether the cloud computing
infrastructure will be able support the storing of
Figure 1. Showing layers of the cloud delivery model
204
Security Issues in Cloud Computing
sensitive information without making organisations liable from breaking privacy regulations.
Many believe that cloud authorisation systems are
not robust enough with as little as a password and
username to gain access to the system. In many
private clouds, usernames can be very similar,
degrading the authorisation measures further.
If there was private/sensitive information being
stored on a private cloud, then there is a high
chance that someone could view the information
easier than many might believe. The customer is
advised to only give their data or use the cloud
provider’s system if they trust them.
As companies move onto Cloud Computing
with the incentive of low cost by the aggregation of
servers and data into a centralized location which
in turn can translate to severity toward aggregation
of risk. There have been significant incidents of
successful disruption on Cloud Networks due to
hackers. Google were the target of attacks aimed at
stealing intellectual property and identifying that
human-rights activists were targeted seeking reforms in China. The incident prompted the Internet
search giant to re-evaluate whether it will continue
doing business in the country (MarketWatch,
2010). Google’s infrastructure is mainly on the
Cloud and companies with high profiles become
bigger targets. The resources such companies
have toward security investment is considerable
and Google supply software security also more
so to business. Attacks to date have not just been
on Google but companies from a wide range of
businesses–including the Internet, finance, technology, media and chemical sectors–have been
similarly targeted (Everiss, 2010).
Cloud service providers believe encryption
is the key and can help with a lot of the security
issues but what comes along with the benefits
of encryption are the pitfalls as encryption can
be processor intensive. Encrypting is not always
full proof for protecting data; there can be times
when little glitches occur and the data cannot be
decrypted leaving the data corrupt and unusable
for customers and the cloud service provider.
The cloud resources can also be abused as cloud
providers reassign IP addresses when a customer
no longer needs the IP address. Once an IP address is no longer needed by one customer after
a period of time, it then becomes available for
another customer to use. Cloud providers save
money and do not need as many IP addresses
by reusing them, so it is in the cloud provider’s
interest to reuse them. Too many of these idle/
used IP addresses can leave the cloud provider
open to abuse of its resources. There is a period
between an IP address being changed in DNS and
the DNS caches holding the IP address getting
cleared. If these old/used IP addresses are being
Figure 2. Showing hybrid cloud deployment model
205
Security Issues in Cloud Computing
held in the cache, then they can be accessed which
would grant a user access to the resources that are
available at the IP address. Also another customer
of the same cloud provider could potentially gain
access to another customer’s resources by navigating through the cloud provider’s networks, if no/
little security measures are put in place. Data and
information is like a currency for cyber terrorists/
crooks and clouds can hold enormous amounts of
data so clouds are becoming an a attractive target
for these crooks, which is why cloud security
must be top notch and should not be overlooked
(Wayner, 2008).
Clouds API’s and software-as-a-service are still
evolving, which means updates can be frequent
but some clouds do not inform their customers that
these changes have been made. Making changes to
the API means changing the cloud configuration
which affects all instances within the cloud (see
Figure 3). The changes could affect the security
of the system as one change could fix one bug
but create another. The customers of the cloud
provider should enquire if any updates are made
and should ask about what security implementations have been put into place to secure their data
and what exactly has changed with the system.
Some ways to verify if the company is right for
your information is to ask is there a third party
auditing their cloud or do they have any security
certificates.
If a cyber criminal hacks into the cloud provider and data which belongs to the customer has
been copied off the server, then the customer may
not know. The cloud provider will have access to
the server logs and the customer will not. Multiple customers may be sharing the resources of
the same servers and one customer could be using
multiple hosts potentially every day. This would
make tracking of the unauthorised access of the
data to be nearly impossible for the cloud service
provider as the data can be very widely spread
throughout the cloud provider’s networks. Unless
the cloud provider has developed some sort of
monitoring software which can group/sort processes which have occurred for each user, then
this could be a large security risk and make attacking clouds even more attractive for cyber
criminals. Most customers will not know where
their data is being stored by the cloud provider.
This poses a number of issues especially if the
information is important or valuable. Customers
who are worried about security should ask their
cloud provider where the physical servers are
held, how often are they maintained and what sort
of physical security measures have been taken
(e.g. biometrics or PIN access) to restrict access
to the server resources. There is a chance that the
Figure 3. Showing relationships of the cloud API and other key cloud components
206
Security Issues in Cloud Computing
data will be held in another country, which means
the local law and jurisdiction would be different
and could create a different security risk, as data
that might be secure in one country may not be
secure in another (Staten, 2009). By looking at
the different views on data privacy between the
US and the EU, this security risk becomes more
evident as the US has a very open view on the
privacy of data. The US Patriot Act grants government and other agencies with virtually limitless
powers to access information including that belonging to companies whereas in the EU this type
of data would be much more secure, so local laws
and jurisdiction can have a large effect on the
security and privacy of data within a cloud (Mikkilineni and Sarathy, 2009).
CONCLUSION
One of the biggest security worries with the cloud
computing model is the sharing of resources.
Cloud service providers need to inform their
existing customers on the level of security that
they provide on their cloud. The cloud service
providers need to educate potential customers
about the cloud deployment models such as public,
private and hybrids along with the pros and cons
of each. They need to show their customers that
they are providing appropriate security measures
that will protect their customer’s data and build
up confidence for their service. One way they
can achieve this is through the use of third party
auditors. New security techniques need to be developed and older security techniques needed to
be radically tweaked to be able to work with the
cloud architecture. Plugging in existing security
technology will not work because this new delivery model introduces new changes to the way
in which we access and use computer resources.
We must remember that when a corporation
loses sensitive data, it is quite often an inside job
therefore organisations must consider carefully
who they are handing their sensitive data to. In
the standard model of data remaining in-house,
they can monitor closely the use of data and irregularities within staff. They can also set and
unset the credentials required to access this data,
enabling them to remain in control. However,
in the cloud, they must place a lot of trust in the
service provider, in their abilities to employ reliable members of staff and only offer the required
security privileges to those who it deems necessary.
A degree of trust will always remain, however
there are external security standards (ISO27001),
and if a cloud service provider conforms to this
standard, they will be able to be audited to ensure
the compliance. This will give considering companies an added boost of trust as they can ask to
view any previous audits.
REFERENCES
Everiss, B. (2010, January 13). Google hacked
by Chinese. Bruce on Games Blog. Retrieved
from http://www.bruceongames.com/2010/01/13/
google-hacked-by-chinese
Hamilton, J. (2008). Internet-scale service efficiency. In Large-Scale Distributed Systems and
Middleware (LADIS) Workshop, September 2008
Hosangar, K., Krisnan, R., Smith, M., & Chuang,
J. (2004) Optimal pricing of content delivery network (CDN) services. The 37th Annual Hawaii
International Conference on System Sciences,
(pp. 205-214).
Krebs, B. (2008, July 1). Amazon: Hey spammers,
get off my cloud! Washington Post.
MarketWatch. (2010, February 22). US reportedly
track down Google hacking-code writer. MarketWatch. Retrieved from http://www.marketwatch.
com/story/us-reportedly-finds-google-hackingcode-writer-2010-02-22
Mather, T., Kumaraswamy, S., & Latif, S. (2009).
Cloud security and privacy. O’Reilly.
207
Security Issues in Cloud Computing
McFedries, P. (2008, August). The cloud is the
computer. IEEE Spectrum.
Mikkilineni, R., & Sarathy, V. (2009). Cloud
computing and the lessons from the past. The
18th IEEE International Workshops on Enabling
Technologies: Infrastructures for Collaborative
Enterprises, Groningen, The Netherlands, June
29 - July 1, 2009
NIST. (2010). NIST cloud computing program.
National Institute Standards and Technology.
Retrieved from http://www.nist.gov/itl/cloud/
index.cfm
Ohlman, B., Eriksson, A., & Rembarz, R. (2009).
What networking of information can do for cloud
computing. The 18th IEEE International Workshops on Enabling Technologies: Infrastructures
for Collaborative Enterprises, Groningen, The
Netherlands, June 29 - July 1, 2009
Rangan, K. (2008). The cloud wars: $100+ billion
at stake. Tech. rep., Merrill Lynch, May 2008.
Sherriff, L. (2011, April 11). The risky business of
assessing the public cloud. The Register. Retrieved
from http://www.theregister.co.uk/2011/04/08/
risk_assessment_cloud/
Siegele, L. (2008, October). Let it rise: A special
report on corporate IT. The Economist.
Staten, J. (2009, March 7). Is cloud computing
ready for the enterprise? Forrester Report.
Vogels, W. (2008). A head in the clouds- The power
of infrastructure as a service. In First Workshop on
Cloud Computing and in Applications (CCA’08),
October2008
Wayner, P. (2008,, July 21). Cloud versus cloud
- A guided tour of Amazon, Google, AppNexus
and GoGrid. InfoWorld.
Weiss, A. (2007). Computing in the clouds. Networker, 11(4), 16–25. doi:10.1145/1327512.1327513
KEY TERMS AND DEFINITIONS
Bandwidth: the amount of data that can be
transferred from one point to another, usually
between a Web server and a Web Browser; It is a
measure of the range of frequencies a transmitted
signal occupies. In digital systems, bandwidth is
the data speed in bits per second. In analog systems,
bandwidth is measured in terms of the difference
between the highest-frequency signal component
and the lowest-frequency signal component.
Cloud Computing: Cloud computing describes a new supplement, consumption, and
delivery model for IT services based on Internet
protocols, and it typically involves provisioning
of dynamically scalable and often virtualized
resources.
Cloud Service Providers: Cloud Service
Providers offer an opportunity for organisations to
make resources available online. These resources
can range from extensive customer relationship
management (CRM) software to the relatively
widespread online email access.
Hybrid Clouds: incorporate both public and
private clouds (see Figure 2) within the same
network. It allows the organisations to benefit
from both deployment models. For example, an
organisation could hold sensitive information on
their private cloud and use the public cloud for
handling large traffic and demanding situations.
Multitenant Architectures: Many companies
share the same infrastructure within the Public
Cloud, and the term given to this is Multitenant
Architectures.
Private Clouds: These allow users to have the
benefits of cloud computing without some of the
pitfalls. Private clouds grant complete control over
how data is managed and what security measures
are in place. This can lead to users having more
confidence and control. The major issue with this
deployment model is that the users have large
expenditures as they have to buy the infrastructure to run the cloud and also have to manage the
cloud themselves.
208
Security Issues in Cloud Computing
Public Clouds: Public Cloud computing
companies typically pay a yearly subscription to
an external company toward storing data and the
providing and facilitating the running of application programs.
Quality of Service: This is a measure of
network performance that reflects the network’s
transmission quality and service availability. QoS
can come in the form of traffic policy in which the
transmission rates are limited which guarantees
a certain amount of bandwidth will be available
to applications.
Router: A device or setup that finds the best
route between any two networks, even if there
are several networks to traverse. Like bridges,
remote sites can be connected using routers over
dedicated or switched lines to create WANs.
Switch: A network device that selects a path
or circuit for sending a unit of data to its next
destination. A switch may also include the function of a router (see above). In general, a switch
is a simpler and faster mechanism than a router,
which requires knowledge about the network and
how to determine the route.
Universal Resource Identifier (URI): The
string (often starting with http) comprises a name
or address that can be used to refer to a resource.
It is a fundamental component of the World Wide
Web.
S Ssymmetry
Article
Blockchain Security in Cloud Computing: Use Cases,
Challenges, and Solutions
Jin Ho Park 1 and Jong Hyuk Park 2,*
ID
1 Department of Computer Science, School of Software, SoongSil University, Seoul 06978, Korea;
j.park@ssu.ac.kr
2 Department of Computer Science and Engineering, Seoul National University of
Science and Technology, (SeoulTech) Seoul 01811, Korea
* Correspondence: jhpark1@seoultech.ac.kr; Tel.: +82-2-970-6702
Received: 29 June 2017; Accepted: 1 August 2017; Published: 18 August 2017
Abstract: Blockchain has drawn attention as the next-generation financial technology due to its
security that suits the informatization era. In particular, it provides security through the authentication
of peers that share virtual cash, encryption, and the generation of hash value. According to the
global financial industry, the market for security-based blockchain technology is expected to grow to
about USD 20 billion by 2020. In addition, blockchain can be applied beyond the Internet of Things
(IoT) environment; its applications are expected to expand. Cloud computing has been dramatically
adopted in all IT environments for its efficiency and availability. In this paper, we discuss the concept
of blockchain technology and its hot research trends. In addition, we will study how to adapt
blockchain security to cloud computing and its secure solutions in detail.
Keywords: blockchain; computer security; bitcoin; authentication; cloud computing
1. Introduction
With the need for next-generation financial technology recently increasing, there have been active
studies on blockchain for the secure use of electronic cash by communicating solely between peers
and without the involvement of third parties. A blockchain is the public ledger for transactions and it
prevents hacking during transactions involving virtual cash. As a type of distributed database and
a data record list that continuously grows, it is designed to disable arbitrary tampering by the operator
of distributed peers. Transaction records are encrypted according to a rule and operated in computers
that run the blockchain software. Bitcoin is an electronic currency using blockchain technology [1].
Using blockchain can provide higher security compared to storing all data in a central database.
In the data storage and management aspect, damage from attacks on a database can be prevented.
Moreover, since the blockchain has an openness attribute, it can provide transparency in data when
applied to an area requiring the disclosure of data. Due to such strengths, it can be utilized in diverse
areas including the financial sector and the Internet of Things (IoT) environment and its applications
are expected to expand [2–6].
The blockchain finalizes a transaction record through the work authentication process, when a
person who loans electronic cash forms a block by combining the transactions over the network.
The hash value is then generated by verifying it and connecting the previous block. This block is
periodically updated and reflected on the electronic cash transaction details to share the latest
transaction detail block. This process provides security for the transaction of electronic cash and
allows the use of a reliable mechanism [7–9].
Cloud computing has been applied to many IT environments due to its efficiency and availability.
Moreover, cloud security and privacy issues have been discussed in terms of important security
elements: confidentiality, integrity, authentication, access control, and so on [10].
Symmetry 2017, 9, 164; doi:10.3390/sym9080164 www.mdpi.com/journal/symmetry
Symmetry 2017, 9, 164 2 of 13
In this paper, we seek to investigate the definition and base technology of blockchain and survey
the trend of studies to date to discuss areas to be studied, considering cloud computing environments.
In addition, we discuss the considerations for blockchain security and secure solutions in detail.
This paper studies the blockchain technology and surveys the blockchain by analyzing generic
technology and research trends and discusses the solution for using bitcoin safely as well as future
study areas. The results of this research can serve as important base data in studying blockchain and
will aid in understanding the known security problems thus far. We can foster the development of
future blockchain technology by understanding the trend of blockchain security.
The rest of this paper is organized as follows. In Section 2, we discuss related works including
the basic concept of blockchain and bitcoin as a use case. Section 3 presents a detailed discussion
and survey on the security considerations for blockchain including the settlement of blockchain, the
security of transaction, the security of wallet, and the security of software. In Section 4, we discuss
blockchain security case studies—authentication, security incidents, and 51% attack—and improve
the blockchain. Section 5 proposes secure solutions for the blockchain in cloud computing in detail.
Finally, we conclude our study in Section 6.
2. Related Works
In this section, we discuss the basic concept of blockchain and the existing research. We also study
the specific use of blockchain in bitcoin.
2.1. Blockchain
A blockchain is the technology that allows all members to keep a ledger containing all transaction
data and to update their ledgers to maintain integrity when there is a new transaction. Since the
advancement of the Internet and encryption technology has made it possible for all members to verify
the reliability of a transaction, the single point of failure arising from the dependency on an authorized
third party has been solved.
The blockchain has broker-free (P2P-based) characteristics, thereby doing away with unnecessary
fees through p2p transactions without authorization by a third party. Since ownership of the transaction
information by many people makes hacking difficult, security expense is saved, transactions are
automatically approved and recorded by mass participation, and promptness is assured. Moreover,
the system can be easily implemented, connected, and expanded using an open source and transaction
records can be openly accessed to make the transactions public and reduce regulatory costs [11].
The blockchain is a structured list that saves data in a form similar to a distributed database
and is designed to make arbitrarily manipulating it difficult since the network participants save and
verify the blockchain. Each block is a structure consisting of a header and a body. The header includes
the hash values of the previous and current blocks and nonce. The block data are searched in the
database using the index method. Although the block does not contain the hash value of the next
block, it is added as a practice (Figure 1) [12].
Since the hash values stored in each peer in the block are affected by the values of the previous
blocks, it is very difficult to falsify and alter the registered data. Although data alteration is possible if
51% of peers are hacked at the same time, the attack scenario is realistically very difficult.
Public, key-based verification and a hash function that can be decrypted are both used to provide
security in the blockchain. The ECDSA (Elliptic Curve Digital Signature Algorithm) electronic signature
algorithm, which verifies the digital signature generated during a transaction between individuals,
is used to prove that the transaction data have not been altered.
Although using an anonymous public key as account information enables one to know who sent
how much to another peer, it still ensures anonymity since there is no way of finding information
pertaining to the owner [13–15].
The hash function is used to verify that the block data containing the transaction details are
not altered and to find the nonce value to get a new block, as well as to guarantee the integrity of
Symmetry 2017, 9, 164 3 of 13
transaction data during a bitcoin transaction. The integrity of the transaction details can be verified
through the public key-based encryption of the hash value of the transaction data. Moreover, using
the root hash value, which accumulates the hash value of each of the transaction details, enables easy
determination of whether the bitcoin data were altered since the root hash value is changed when the
value is changed in the process [16,17].
Symmetry 2017, 9, 164 3 of 13
Figure 1. Blockchain connection structure.
The hash function is used to verify that the block data containing the transaction details are not
altered and to find the nonce value to get a new block, as well as to guarantee the integrity of
transaction data during a bitcoin transaction. The integrity of the transaction details can be verified
through the public key-based encryption of the hash value of the transaction data. Moreover, using
the root hash value, which accumulates the hash value of each of the transaction details, enables easy
determination of whether the bitcoin data were altered since the root hash value is changed when the
value is changed in the process [16,17].
There are many ongoing studies to strengthen security using these characteristics of blockchain.
The most important part of the blockchain is security related to the personal key used in encryption
and there are studies on how to protect the personal key. An attacker attempts a “reuse attack” and
other attacks to obtain the personal key stored in a peer’s device in order to hack the bitcoin. The
attacker can hack the bitcoin since the data may be leaked if the attacker can obtain the personal key.
To solve this problem, studies on applying both hardware and software securities for approving
transactions are ongoing [18].
Bitcoin is very vulnerable to infection by malware since it is often traded in widely used devices
such as peers’ PCs or smartphones. The malware penetrating through various paths such as e-mail,
USB, or apps with poor security must be detected and treated since it can infect a peer’s device. The
need for security is growing, particularly in trades of items used in games since many of them use
bitcoins. As such, there have been studies on detecting and treating malware in the game
environment [19].
One of the strengths of bitcoin is that it is difficult to falsify and alter the ledger because so many
peers share the transaction ledger. Since it takes the data recorded in the majority of ledgers, hacking
is practically impossible unless the attacker alters and falsifies 51% of all peers’ ledgers, even if the
data of some ledgers are altered. Still, there are concerns that 51% of the ledgers can be falsified and
altered simultaneously considering increasing computing power and there are studies suggesting the
intermediate verification process or design of the verification process in order to solve the problem.
2.2. Bitcoin
Bitcoin is the digital currency proposed by Satoshi Nakamoto in 2009 to allow transactions
between peers without a central authority or a server to issue and manage the currency. Bitcoins are
traded with the P2P-based distributed databases based on public-key cryptology. Bitcoin is one of
the first implementations of cryptocurrency in 1998 [20].
The bitcoin transaction information is disclosed over the network such that all peers can verify
it and so currency issuance is limited. The peers participating in the network have the same
blockchain and the transaction data are stored in blocks in the same way as the distribution storage
of transaction data. Although there are many threats involved in electronic transactions, bitcoin can
be technically implemented to cope with them. For example, a person attempting to generate a
Figure 1. Blockchain connection structure.
There are many ongoing studies to strengthen security using these characteristics of blockchain.
The most important part of the blockchain is security related to the personal key used in encryption and
there are studies on how to protect the personal key. An attacker attempts a “reuse attack” and other
attacks to obtain the personal key stored in a peer’s device in order to hack the bitcoin. The attacker
can hack the bitcoin since the data may be leaked if the attacker can obtain the personal key. To solve
this problem, studies on applying both hardware and software securities for approving transactions
are ongoing [18].
Bitcoin is very vulnerable to infection by malware since it is often traded in widely used
devices such as peers’ PCs or smartphones. The malware penetrating through various paths such
as e-mail, USB, or apps with poor security must be detected and treated since it can infect a peer’s
device. The need for security is growing, particularly in trades of items used in games since many
of them use bitcoins. As such, there have been studies on detecting and treating malware in the
game environment [19].
One of the strengths of bitcoin is that it is difficult to falsify and alter the ledger because so many
peers share the transaction ledger. Since it takes the data recorded in the majority of ledgers, hacking
is practically impossible unless the attacker alters and falsifies 51% of all peers’ ledgers, even if the
data of some ledgers are altered. Still, there are concerns that 51% of the ledgers can be falsified and
altered simultaneously considering increasing computing power and there are studies suggesting the
intermediate verification process or design of the verification process in order to solve the problem.
2.2. Bitcoin
Bitcoin is the digital currency proposed by Satoshi Nakamoto in 2009 to allow transactions
between peers without a central authority or a server to issue and manage the currency. Bitcoins are
traded with the P2P-based distributed databases based on public-key cryptology. Bitcoin is one of the
first implementations of cryptocurrency in 1998 [20].
The bitcoin transaction information is disclosed over the network such that all peers can verify it
and so currency issuance is limited. The peers participating in the network have the same blockchain
and the transaction data are stored in blocks in the same way as the distribution storage of transaction
Symmetry 2017, 9, 164 4 of 13
data. Although there are many threats involved in electronic transactions, bitcoin can be technically
implemented to cope with them. For example, a person attempting to generate a falsified receipt
record from another person’s account to his or her own account can be blocked by verifying it with the
sender’s personal key. If multiple parties intend to use a bitcoin at the same time, the chain that loses
in the competition between peers will be eliminated.
The most basic components of a bitcoin are the bitcoin address where the bitcoin belongs, the
transaction showing the flow of bitcoin between the addresses, and the block where the transaction is
confirmed by the bitcoin peers. The key to the bitcoin process is the bitcoin transaction, which shows
the input containing the bitcoin and the bitcoin address as the output. While banking is the process
wherein some of the money in an account moves to another account, a bitcoin transaction requires all
bitcoins in an input to be transferred to the output and the inputs and outputs need not be singular.
The electronic currency used in bitcoins consists of a chain of electronic signatures (Figure 2).
The coins of an owner are transferred to the next chain with the hash value of the previous transaction
and the electronic signature is transmitted to the public key of the next owner. The recipient can check
the signature to confirm the ownership chain. In the process, a problem arises: the recipient is not able
to ensure that one of the owners has not used the coin(s) multiple times. A reliable central authority is
introduced to check all transactions of double use to address this problem [21].
Symmetry 2017, 9, 164 4 of 13
falsified receipt record from another person’s account to his or her own account can be blocked by
verifying it with the sender’s personal key. If multiple parties intend to use a bitcoin at the same time,
the chain that loses in the competition between peers will be eliminated.
The most basic components of a bitcoin are the bitcoin address where the bitcoin belongs, the
transaction showing the flow of bitcoin between the addresses, and the block where the transaction
is confirmed by the bitcoin peers. The key to the bitcoin process is the bitcoin transaction, which
shows the input containing the bitcoin and the bitcoin address as the output. While banking is the
process wherein some of the money in an account moves to another account, a bitcoin transaction
requires all bitcoins in an input to be transferred to the output and the inputs and outputs need not
be singular.
The electronic currency used in bitcoins consists of a chain of electronic signatures (Figure 2).
The coins of an owner are transferred to the next chain with the hash value of the previous transaction
and the electronic signature is transmitted to the public key of the next owner. The recipient can check
the signature to confirm the ownership chain. In the process, a problem arises: the recipient is not
able to ensure that one of the owners has not used the coin(s) multiple times. A reliable central
authority is introduced to check all transactions of double use to address this problem [21].
Figure 2. A bitcoin transaction.
3. Consideration for Blockchain Security: Challenges
Blockchain technology has been implemented or realized as cyber money and is actually used.
Note, however, that various security issues occurring in blockchain agreement, transaction, wallet,
and software have been reported. This paper checks the trends of security issues raised to date and
the security level of the current blockchain. We think this attempt is very important as the results can
serve as base data for developing future blockchain technology and supplementing security.
3.1. Settlement of Blockchain
Although there should only be one blockchain since it is the sequential connection of generated
blocks, a blockchain may be divided into two because the two latest blocks can be generated temporarily
if two different peers succeed in mining the answerfor generating the block at the same time. In such case,
the block that is not chosen as the latest block by the majority of peers in the bitcoin network to continue
mining will become meaningless. In other words, the bitcoin will follow the majority of peers who have
50% or more mining capability (operating capability). Therefore, if an attacker has 51% mining capability,
a “51% Attack”, wherein the attacker has control of the blockchain and he/she can include falsified
transactions, can be a problem. According to a study, an attacker can realize illegal gain with only 25%
operating capability through a malicious mining process instead of 51%. Since the current operating
capability of the whole bitcoin network is already high gaining meaningful operating capability is
considered to be difficult. Nonetheless, mining pools—the associations of mining peers—have been
actively mining to increase the probability of mining. Thus, this risk has become an issue. Recently,
Figure 2. A bitcoin transaction.
3. Consideration for Blockchain Security: Challenges
Blockchain technology has been implemented or realized as cyber money and is actually used.
Note, however, that various security issues occurring in blockchain agreement, transaction, wallet,
and software have been reported. This paper checks the trends of security issues raised to date and
the security level of the current blockchain. We think this attempt is very important as the results can
serve as base data for developing future blockchain technology and supplementing security.
3.1. Settlement of Blockchain
Although there should only be one blockchain since it is the sequential connection of generated
blocks, a blockchain may be divided into two because the two latest blocks can be generated temporarily
if two different peers succeed in mining the answer for generating the block at the same time. In such
case, the block that is not chosen as the latest block by the majority of peers in the bitcoin network
to continue mining will become meaningless. In other words, the bitcoin will follow the majority of
peers who have 50% or more mining capability (operating capability). Therefore, if an attacker has
51% mining capability, a “51% Attack”, wherein the attacker has control of the blockchain and he/she
can include falsified transactions, can be a problem. According to a study, an attacker can realize
illegal gain with only 25% operating capability through a malicious mining process instead of 51%.
Since the current operating capability of the whole bitcoin network is already high gaining meaningful
operating capability is considered to be difficult. Nonetheless, mining pools—the associations of
Symmetry 2017, 9, 164 5 of 13
mining peers—have been actively mining to increase the probability of mining. Thus, this risk has
become an issue. Recently, GHash, a leading mining pool, temporarily exceeded the 50% threshold,
forcing the bitcoin community to go through internal and external adjustments to cope with the risk.
In particular, the possibility of dominating the blockchain is related to the basic security of the bitcoin
and such security threats have temporarily affected the economic factors because of the characteristics
of the bitcoin, which is always closely related to the market price [22,23].
3.2. Security of Transaction
Since the script used in inputs and outputs is a programming language with flexibility, different
transaction forms can be created using such. A bitcoin contract [11] is a method of applying bitcoin for
the existing authentication and financial service. A widely used method involves creating the contract
using the script that includes a multiple-signature technique called multisig. Although the scripts are
used to solve a wide range of bitcoin problems, the possibility of an improperly configured transaction
has also increased as the complexity of the script increases. A bitcoin using an improperly configured
locking script is discarded since nobody can use it as the unlocking script cannot be generated. To this
end, there are studies that suggest models of bitcoin contract-type transactions to verify the accuracy
of a script used in a transaction [24].
3.3. Security of Wallet
The bitcoin address is the hash value of a public key encoded with a pair of public and personal
keys. Therefore, the locking script of a bitcoin transaction with an address as output can be unlocked
with an unlocking script that has the value signed with the public key of the address and the personal
key. The bitcoin wallet stores information such as the personal key of the address to be used for the
generation of the unlocking script. It means that loss of information in the wallet leads to a loss of
bitcoin since the information is essential for using the bitcoin. Therefore, the bitcoin wallet has become
the main subject of bitcoin attack through hacking [25].
To assure the security of the bitcoin wallet, services have introduced multisig for multiple
signatures. Since multisig only allows a transaction when there is more than one signature, depending
on the setting, it can be used as the redundant security feature of the wallet. For example, if multisig
is set in an online bitcoin wallet and is configured to require the owner’s signature in addition to
the signature of the online wallet site whenever a transaction is executed from the wallet, malicious
bitcoin withdrawal can be prevented since the owner’s personal key is not stored, even when the
online wallet site is taken over by a hacking attack. Moreover, multisig is evolving into services that
allow withdrawal from the bitcoin wallet only through biometric data or separate equipment using
a two-factor authentication and other measures [26].
As the fundamental solution to hacking attacks of a bitcoin wallet, offline, cold storage-type
wallets such as a physical bitcoin coin or a paper bitcoin wallet that is not connected to the
Internet, are available. Similar approaches include the hardware-type bitcoin wallets to reduce
the risk associated with online transactions. The hardware wallet, such as Trezor, stores the key
in a tamper-proof storage unit connected to the computer through USB, that is, only when used
and the signed transaction is transferred using the internally stored key and only when the user is
authenticated. In other words, the storage unit is connected only when there is a need to establish
a bitcoin transaction, remaining in cold storage-like status the rest of the time. Although it is more
secure than cold storage because there is one more authentication process, problems such as loss of
cold storage and lack of user-friendliness also plague the hardware wallet [27].
3.4. Security of Software
The bug of the software used in bitcoin can be critical. Although the official Bitcoin Developer
Documentation [28] site clearly explains all bitcoin processes, the bitcoin core software is still effective
Symmetry 2017, 9, 164 6 of 13
as the reference since the detailed processes of the early bitcoin system have been determined through
the software implemented by Satoshi Nakamoto.
Nonetheless, even the bitcoin core software, which must be more reliable than anything, is not
free from the problem of software malfunction such as bug. The most famous software bug is the
CVE-2010-5139 vulnerability that occurred in August 2010. Due to the bug caused by integer overflow,
an invalid transaction wherein 0.5 bitcoin was delivered as 184 trillion bitcoin was included in a normal
block, and the problem was not resolved until 8 h later. Moreover, there was a bug where a block
processed in version 0.8 was not processed in version 0.7 as the database was changed from BerkeleyDB
to LevelDB since the bitcoin version of the bitcoin core was upgraded from 0.7 to 0.8. It caused the peers
of version 0.7 and peers of version 0.8 to have different blockchains for 6 h. Both of these problems are
cases showing that the general confidence in the security of bitcoin transactions of a block as having
significant depth after a period of time and can be threatened by a software bug [29].
4. Blockchain Security Case Studies
The demand for the security of bitcoins based on blockchain has increased since hacking cases
were reported. Mt. Gox, a bitcoin exchange based in Tokyo, Japan, reported losses of USD 8.75 million
due to hacking in June 2011 and bitcoin wallet service InstaWallet reported losses of USD 4.6 million
due to hacking in April 2013. In November of the same year, anonymous marketplace Sheep
Marketplace was forced to shut down after somebody stole USD 100 million worth of bitcoins. Mt. Gox,
which had already suffered losses due to hacking, again reported losses of USD 470 million due to
hacking in February 2014 and subsequently filed for bankruptcy. The problems continued, with the
Hong Kong-based bitcoin exchange Bitfinex reporting losses of USD 65 million due to hacking in
August 2016. These problems have raised awareness of the need for security.
There have been academic studies on the security of blockchain to overcome such security
problems and many papers have been published [30]. In particular, since blockchain is the generic
technology of cyber money, the damages can be serious in cases of misuse and attempts to steal cyber
money occur frequently. Therefore, it seems very meaningful to understand the attack cases known so
far and to carry out investigations to draw up countermeasures.
4.1. Authentication
An important part of blockchain security is security related to the personal key used in encryption.
An attacker carries out various attempts to access a user’s personal key stored in the user’s computer
or smartphone in order to hack the bitcoin. The attacker will install malware on the computer or
smartphone to leak the user’s personal key and use it to hack the bitcoin. Some studies have proposed
a hardware token for the approval of a transaction to protect the personal key.
Other studies suggested strengthened authentication measures for the storage unit containing
the bitcoin. A two-factor authentication is considered to be the leading method for strengthening
authentication. For bitcoin, the two-party signature protocol by ECDSA can be used for authentication
(Figure 3) [31,32].
Symmetry 2017, 9, 164 6 of 13
Nonetheless, even the bitcoin core software, which must be more reliable than anything, is not free
from the problem of software malfunction such as bug. The most famous software bug is the CVE-2010-
5139 vulnerability that occurred in August 2010. Due to the bug caused by integer overflow, an invalid
transaction wherein 0.5 bitcoin was delivered as 184 trillion bitcoin was included in a normal block, and
the problem was not resolved until 8 h later. Moreover, there was a bug where a block processed in version
0.8 was not processed in version 0.7 as the database was changed from BerkeleyDB to LevelDB since the
bitcoin version of the bitcoin core was upgraded from 0.7 to 0.8. It caused the peers of version 0.7 and
peers of version 0.8 to have different blockchains for 6 h. Both of these problems are cases showing that
the general confidence in the security of bitcoin transactions of a block as having significant depth after a
period of time and can be threatened by a software bug [29].
4. Blockchain Security Case Studies
The demand for the security of bitcoins based on blockchain has increased since hacking cases
were reported. Mt. Gox, a bitcoin exchange based in Tokyo, Japan, reported losses of USD 8.75 million
due to hacking in June 2011 and bitcoin wallet service InstaWallet reported losses of USD 4.6 million
due to hacking in April 2013. In November of the same year, anonymous marketplace Sheep
Marketplace was forced to shut down after somebody stole USD 100 million worth of bitcoins. Mt.
Gox, which had already suffered losses due to hacking, again reported losses of USD 470 million due
to hacking in February 2014 and subsequently filed for bankruptcy. The problems continued, with
the Hong Kong-based bitcoin exchange Bitfinex reporting losses of USD 65 million due to hacking in
August 2016. These problems have raised awareness of the need for security.
There have been academic studies on the security of blockchain to overcome such security
problems and many papers have been published [30]. In particular, since blockchain is the generic
technology of cyber money, the damages can be serious in cases of misuse and attempts to steal cyber
money occur frequently. Therefore, it seems very meaningful to understand the attack cases known
so far and to carry out investigations to draw up countermeasures.
4.1. Authentication
An important part of blockchain security is security related to the personal key used in
encryption. An attacker carries out various attempts to access a user’s personal key stored in the
user’s computer or smartphone in order to hack the bitcoin. The attacker will install malware on the
computer or smartphone to leak the user’s personal key and use it to hack the bitcoin. Some studies
have proposed a hardware token for the approval of a transaction to protect the personal key.
Other studies suggested strengthened authentication measures for the storage unit containing
the bitcoin. A two-factor authentication is considered to be the leading method for strengthening
authentication. For bitcoin, the two-party signature protocol by ECDSA can be used for
authentication (Figure 3) [31,32].
Figure 3. ECDSA two-party signature.
4.2. Security Incidents Figure 3. ECDSA two-party signature.
Symmetry 2017, 9, 164 7 of 13
4.2. Security Incidents
With more people using bitcoins, cases of malware and malicious codes targeting bitcoins
have also been reported. Malware can hack the bitcoins by infecting computers. To solve such
a problem, a PC security solution must be installed to detect malicious code [17]. One recently found
malicious code looted game accounts and can be applied for looting the bitcoin accounts. With more
bitcoins being used for the cash transaction of online game items, security measures to cope with it
are needed [33].
The Distributed Denial of Service (DDoS) attack floods the targeted server with superfluous
requests to overload the system and prevent the provision of normal service to other users.
Thus, it can prevent the users of blockchain from receiving the service. DDoS attacks include the
bandwidth-consuming attack that exceeds the bandwidth of all systems using the same network
and the PPS (Packet Per Second)-consuming attack that causes internal system failure or the denial
of service to other servers in the same network. The http-flooding attack transfers a large amount
of http packets to a targeted server to cause the denial of service. Since the bitcoin service must be
continuously provided to the users, countermeasures to DDoS attacks are needed [34].
4.2.1. 51% Attack
In a bitcoin environment, a 51% attack alters and falsifies 51% of the ledgers simultaneously.
Thus, it is a very difficult attack to coordinate. The attacker must have 51% or more calculating
capability of all users, intentionally generate two branches, and set the targeted branch as the legitimate
blockchain. To solve the problem, an intermediate verification process must be provided to prevent
such tampering [35,36].
In a bitcoin environment, a 51% attack consists of five steps.
1. Publish mining software with a higher EV (Expected Value).
(1) Mine on new headers (but validate it as soon as possible)
(2) More “flexible” 2-h rule
(3) Decide on fork with own block version number
(4) Make miner aware of the “Goldfinger” reward
(5) “Members only” functionality
2. Create a pool with stickiness.
(1) New members will receive only 90% of shares in the first 2 weeks and 110% after 2 weeks
(Ponzi scheme)
3. Create unwanted coalitions (timestamp attack).
4. Attack other pools with cannibalizing pools.
5. Eventually switch to members only.
A race attack generates hundreds of transactions and sends them to multiple users when
a legitimate transaction is sent. Since many users are likely to presume the transferred transaction to
be legitimate, losses can be sustained if 51% of users change the ledger.
In a Finney attack, an attacker generates a block containing altered data and carries out the attack
with it. Such attacks can be prevented when the attack target sets the transaction in standby mode
until block confirmation.
4.2.2. Improved Blockchain
Since the current payment system is very complex and transaction facilitators are scattered,
the points targeted by security attacks are increasing. A user intending to trade money will pay
an annual membership fee to receive a card and use it to purchase goods or use services. The customer’s
Symmetry 2017, 9, 164 8 of 13
bank and the merchant’s bank interact with each other to settle the fee and a shop intending to use the
card receives it from a bank and uses it for the purchase of goods and services. A simplification of
transaction is required since more people use smartphones to purchase goods or services (Figure 4) [37].
Symmetry 2017, 9, 164 8 of 13
Figure 4. General payment process system.
As for the benefits of executing a conventional transaction as a peer-to-peer transaction using
blockchain, the transaction is not only reliable and verifiable but also cost-efficient since there are no
third parties involved. In addition, a transaction using blockchain can be completed very quickly
since physical distance does not affect the transaction, whereas conventional transactions across the
border can be very slow. Moreover, conventional, centrally managed transactions are vulnerable to
leaks of important data when the managing server is hacked since all the valuable data is managed
in the central server. In contrast, it is very difficult to attack blockchain-based transactions since all
important data is distributed and an attacker must hack and alter 51% of the peer-to-peer
transactions. Therefore, the improved blockchain must be used for transactions to solve the problems
of conventional transactions [1].
One of the biggest problems of bitcoin using the blockchain is the possibility of a double
transaction. A double transaction is the act of sending the bitcoin to two or more accounts for
malicious purposes and “total currency” and “longest chain wins” are used as mechanisms for
preventing it. The total currency mechanism means that the transaction can be terminated if the total
currency exceeds 21 million by double transaction. The longest chain wins mechanism creates the
next block first when a blockchain is forked by double transaction and the longest chain with the
most work will always win.
If a user double-spends a bitcoin and the transaction details are consequently sent to two
different peers, two blocks will be generated. The peers will generate the next blocks using two blocks
in competition. As a result, the chain that loses in the competition, such as the red block in the Figure
3, is naturally eliminated and the longer chain wins. The double spending problem can be addressed
through such a mechanism (Figure 5) [38].
Figure 4. General payment process system.
As for the benefits of executing a conventional transaction as a peer-to-peer transaction using
blockchain, the transaction is not only reliable and verifiable but also cost-efficient since there are no
third parties involved. In addition, a transaction using blockchain can be completed very quickly
since physical distance does not affect the transaction, whereas conventional transactions across the
border can be very slow. Moreover, conventional, centrally managed transactions are vulnerable to
leaks of important data when the managing server is hacked since all the valuable data is managed
in the central server. In contrast, it is very difficult to attack blockchain-based transactions since all
important data is distributed and an attacker must hack and alter 51% of the peer-to-peer transactions.
Therefore, the improved blockchain must be used for transactions to solve the problems of conventional
transactions [1].
One of the biggest problems of bitcoin using the blockchain is the possibility of a double
transaction. A double transaction is the act of sending the bitcoin to two or more accounts for malicious
purposes and “total currency” and “longest chain wins” are used as mechanisms for preventing it.
The total currency mechanism means that the transaction can be terminated if the total currency
exceeds 21 million by double transaction. The longest chain wins mechanism creates the next block
first when a blockchain is forked by double transaction and the longest chain with the most work will
always win.
If a user double-spends a bitcoin and the transaction details are consequently sent to two different
peers, two blocks will be generated. The peers will generate the next blocks using two blocks in
competition. As a result, the chain that loses in the competition, such as the red block in the Figure 3,
is naturally eliminated and the longer chain wins. The double spending problem can be addressed
through such a mechanism (Figure 5) [38].
Symmetry 2017, 9, 164 9 of 13 Symmetry 2017, 9, 164 9 of 13
Figure 5. Double-spending prevention mechanism.
5. Secure Blockchain Solutions in Cloud Computing
The security factors for using bitcoin with blockchain were introduced in Section 3 and security
cases of bitcoins using blockchain were reviewed in Section 4.
If the user data is disclosed in the cloud computing environment, monetary and psychological
damages can occur due to the leak of users’ sensitive information. The security of the saving and
transmitting data, such as confidentiality and integrity, in the cloud computing environment is
mainly studied. Note, however, that studies on privacy protection and anonymity are not sufficient.
Blockchain is a representative technology for ensuring anonymity. If combined with the cloud
computing environment, blockchain can be upgraded to a convenient service that provides stronger
security. User anonymity can be ensured if the blockchain method is used when saving the user
information in the cloud computing environment. An electronic wallet is installed when using the
blockchain technology. If the electronic wallet is not properly deleted, the user information can be
left behind. The remaining user information can be used to guess the user information. To solve this
problem, we propose a solution that installs and deletes the electronic wallet securely.
Cases of falsifying the ledger or bitcoin and double transactions of blockchain pose the biggest
problem. A secure wallet is needed to solve such security problems. Although the electronic wallet
installed in the PC is generally used, the security of electronic wallets in mobile devices must be
verified as mobile devices have become very popular. Since a transaction occurs based on the time
value of a mobile device, the security of a transaction can be confirmed only when both the integrity
and accuracy of a time stamp generated in a mobile device are guaranteed [28].
Moreover, the base technology must also be verified since vulnerabilities differ according to the
programming language and platform used for the development of the electronic wallet environment.
A secure electronic wallet must be developed by minimizing and verifying problems that can occur
at each step of planning, requirement analysis, implementation, QA (Quality Assurance), and
maintenance.
The electronic wallet must have measures for secure restoration if infringed by an attacker,
verification of a binary installed for self-protection, and protection of the remaining data for
restoration. It must provide security for the data stored in the electronic wallet as well as the settings
needed for the utilization of the electronic wallet. It must also be able to delete the remaining data
securely when the electronic wallet is no longer used and must consequently be discarded.
To use an electronic wallet securely, a user installs it on his or her PC and the platform sends the
electronic wallet and data to establish a secure environment. The user downloads and installs the
Figure 5. Double-spending prevention mechanism.
5. Secure Blockchain Solutions in Cloud Computing
The security factors for using bitcoin with blockchain were introduced in Section 3 and security
cases of bitcoins using blockchain were reviewed in Section 4.
If the user data is disclosed in the cloud computing environment, monetary and psychological
damages can occur due to the leak of users’ sensitive information. The security of the saving and
transmitting data, such as confidentiality and integrity, in the cloud computing environment is mainly
studied. Note, however, that studies on privacy protection and anonymity are not sufficient. Blockchain
is a representative technology for ensuring anonymity. If combined with the cloud computing
environment, blockchain can be upgraded to a convenient service that provides stronger security.
User anonymity can be ensured if the blockchain method is used when saving the user information
in the cloud computing environment. An electronic wallet is installed when using the blockchain
technology. If the electronic wallet is not properly deleted, the user information can be left behind.
The remaining user information can be used to guess the user information. To solve this problem,
we propose a solution that installs and deletes the electronic wallet securely.
Cases of falsifying the ledger or bitcoin and double transactions of blockchain pose the biggest
problem. A secure wallet is needed to solve such security problems. Although the electronic wallet
installed in the PC is generally used, the security of electronic wallets in mobile devices must be
verified as mobile devices have become very popular. Since a transaction occurs based on the time
value of a mobile device, the security of a transaction can be confirmed only when both the integrity
and accuracy of a time stamp generated in a mobile device are guaranteed [28].
Moreover, the base technology must also be verified since vulnerabilities differ according to the
programming language and platform used for the development of the electronic wallet environment.
A secure electronic wallet must be developed by minimizing and verifying problems that can
occur at each step of planning, requirement analysis, implementation, QA (Quality Assurance),
and maintenance.
The electronic wallet must have measures for secure restoration if infringed by an attacker,
verification of a binary installed for self-protection, and protection of the remaining data for restoration.
It must provide security for the data stored in the electronic wallet as well as the settings needed for
Symmetry 2017, 9, 164 10 of 13
the utilization of the electronic wallet. It must also be able to delete the remaining data securely when
the electronic wallet is no longer used and must consequently be discarded.
To use an electronic wallet securely, a user installs it on his or her PC and the platform sends
the electronic wallet and data to establish a secure environment. The user downloads and installs
the electronic wallet software to use the bitcoin with blockchain and the public key of the platform
is sent to the electronic wallet when the installation is completed. The electronic wallet sends the
certificate distributed during development to the platform, which then verifies the validity of the
certificate in the electronic wallet. The platform and the electronic wallet exchange the key using
the Diffie–Hellman method, with each owning the shared key. When a user requests a transaction
involving the use of a bitcoin, the ledger data containing the time stamp data between the electronic
wallet and the platform are encrypted with the shared key and sent. When a request for disposal is
executed, the user’s certificate is found and deleted from the electronic wallet and the finished message
is sent to confirm that it has been securely discarded. In addition, all the relevant files are deleted so
that the remaining data are securely removed (Figure 6).
Symmetry 2017, 9, 164 10 of 13
electronic wallet software to use the bitcoin with blockchain and the public key of the platform is sent
to the electronic wallet when the installation is completed. The electronic wallet sends the certificate
distributed during development to the platform, which then verifies the validity of the certificate in
the electronic wallet. The platform and the electronic wallet exchange the key using the Diffie–
Hellman method, with each owning the shared key. When a user requests a transaction involving the
use of a bitcoin, the ledger data containing the time stamp data between the electronic wallet and the
platform are encrypted with the shared key and sent. When a request for disposal is executed, the
user’s certificate is found and deleted from the electronic wallet and the finished message is sent to
confirm that it has been securely discarded. In addition, all the relevant files are deleted so that the
remaining data are securely removed (Figure 6).
Figure 6. Secure bitcoin protocol.
This method uses a blockchain-based electronic wallet in the cloud computing environment. The
blockchain method is used to remove the information of the user who uses cloud computing. This
method installs and uses an electronic wallet and removes it normally. The electronic wallet is
securely removed by sending the finished message. Leak of user information can be prevented only
when the electronic wallet is completely removed. Even though many existing studies have been
performed on the blockchain protocol, a method for removing the electronic wallet completely is
presented to ensure user anonymity and privacy protection.
We compared the method with existing studies in terms of confidentiality, integrity, anonymity,
privacy protection, and residual information protection (Table 1). Confidentiality checks if the
information is leaked to unauthorized peers, whereas integrity checks if the data used in transactions
are altered or falsified without sanction during transfer or storage. Anonymity must assure that the
peer involved in a transaction is not identifiable. Privacy protection protects the personal information
of peers participating in the transaction, whereas residual information protection checks the safe
removal of user data at the time of transaction termination and program removal.
Table 1. Comparison of related studies.
Authentication
Case [31]
Security Incidents
Case [34]
51% Attack
Case [35]
Improved Blockchain
Case [38]
Secure Blockchain
Solution
Confidentiality √ √ √ √
Integrity √ √ √
Anonymity √ √ √ √ √
Availability √ √
Privacy
Protection √ √ √ √ √
Figure 6. Secure bitcoin protocol.
This method uses a blockchain-based electronic wallet in the cloud computing environment.
The blockchain method is used to remove the information of the user who uses cloud computing.
This method installs and uses an electronic wallet and removes it normally. The electronic wallet is
securely removed by sending the finished message. Leak of user information can be prevented only
when the electronic wallet is completely removed. Even though many existing studies have been
performed on the blockchain protocol, a method for removing the electronic wallet completely is
presented to ensure user anonymity and privacy protection.
We compared the method with existing studies in terms of confidentiality, integrity, anonymity,
privacy protection, and residual information protection (Table 1). Confidentiality checks if the
information is leaked to unauthorized peers, whereas integrity checks if the data used in transactions
are altered or falsified without sanction during transfer or storage. Anonymity must assure that the
peer involved in a transaction is not identifiable. Privacy protection protects the personal information
of peers participating in the transaction, whereas residual information protection checks the safe
removal of user data at the time of transaction termination and program removal.
Symmetry 2017, 9, 164 11 of 13
Table 1. Comparison of related studies.
Authentication
Case [31]
Security Incidents
Case [34]
51% Attack
Case [35]
Improved Blockchain
Case [38]
Secure Blockchain
Solution
Confidentiality √ √ √ √
Integrity √ √ √
Anonymity √ √ √ √ √
Availability √ √
Privacy Protection √ √ √ √ √
Residual Information
Protection
√
The authentication case [31] does not provide integrity since it has the problem of leaking the key
by hacking the personal key to attack the blockchain. Also, it does not provide residual information
protection since it does not verify the complete removal of the electronic wallet. The security incidents
case [34] does not provide availability since the service becomes unavailable due to infection by
malware and does not provide residual information protection since it does not verify the complete
removal of the electronic wallet. The 51% attack case [35] can have problems of infringed integrity
of the transaction ledger and unavailability following an attack that alters 51% of the transaction
ledger. Additionally, it does not provide residual information protection since it does not verify the
complete removal of the electronic wallet. The improved blockchain case [38] neither assures integrity
nor provides availability since the vulnerability of double transaction remains. Moreover, it does not
provide residual information protection since it does not verify the complete removal of the electronic
wallet. The secure blockchain solution improves security by providing residual information protection
since it encrypts the data using a public key and verifies the complete removal of the electronic wallet.
6. Conclusion
A blockchain has done away with the server to exclude the involvement of the central authority
and has facilitated transactions through the participants who jointly store the transaction records and,
finally, approve the transactions using P2P network technology. The blockchain has a distributed
structure and utilizes the peer network and the computing resources of peers. Technical measures such
as proof of work and proof of stack have been implemented to improve the security of blockchain.
Although the security of blockchain is continuously enhanced, problems have continued to be
reported and there are active studies on security. An attacker makes various attempts to access a user’s
personal key stored in the user’s computer or smartphone in order to hack the bitcoin. There are
studies on using a secure token or saving it securely to protect the personal key.
In this study, we discussed the blockchain technology and related core technologies and surveyed
the trend of studies to date to discuss further areas to be studied. Various current issues should be
taken into account to use blockchain in the cloud computing environment. Blockchain gives rise
to many problems even now, such as the security of transactions, wallet, and software and various
studies have been conducted to solve these issues. The anonymity of user information should be
ensured when using blockchain in the cloud computing environment and the user information should
be completely deleted when removing the service. If the user information is not deleted but instead
left behind, the user information can be guessed from the remaining information. Therefore, this study
discussed the method of providing security by presenting a method of secure blockchain use and
removal protocol. It seems that studies on efficiency are also needed beside security, considering the
environment wherein a massive amount of information is transmitted.
Acknowledgments: This research was supported by MSIP (Ministry of Science, ICT, and Future Planning) Korea
under the ITRC (Information Technology Research Center) support program (IITP-2017-2014-0-00720) supervised
by IITP (Institute for Information & communications Technology Promotion).
Author Contributions: Jin Ho Park: Research for related works, analysis, design, amelioration of the proposed
model and drafting of the article. Jong Hyuk Park: Total supervision of paperwork, review, comments,
assessment, etc.
Symmetry 2017, 9, 164 12 of 13
Conflicts of Interest: The authors declare no conflict of interest.
References
1. Il-Kwon, L.; Young-Hyuk, K.; Jae-Gwang, L.; Jae-Pil, L. The Analysis and Countermeasures on
Security Breach of Bitcoin. In Proceedings of the International Conference on Computational Science
and Its Applications, Guimarães, Portugal, 30 June–3 July 2014; Springer International Publishing:
Cham, Switzerland, 2014.
2. Beikverdi, A.; JooSeok, S. Trend of centralization in Bitcoin’s distributed network. In Proceedings of the 2015
16th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and
Parallel/Distributed Computing (SNPD), Takamatsu, Japan, 1–3 June 2015.
3. Bonneau, J.; Miller, A.; Clark, J.; Narayanan, A.; Kroll, J.A.; Felten, E.W. Sok: Research perspectives and
challenges for bitcoin and cryptocurrencies. In Proceedings of the 2015 IEEE Symposium on Security and
Privacy (SP), San Jose, CA, USA, 17–21 May 2015. [CrossRef]
4. Christidis, K.; Michael, D. Blockchains and Smart Contracts for the Internet of Things. IEEE Access 2016, 4,
2292–2303. [CrossRef]
5. Huang, H.; Chen, X.; Wu, Q.; Huang, X.; Shen, J. Bitcoin-based fair payments for outsourcing computations
of fog devices. Future Gener. Comput. Syst. 2016. [CrossRef]
6. Huh, S.; Sangrae, C.; Soohyung, K. Managing IoT devices using blockchain platform. In Proceedings of the
2017 19th International Conference on Advanced Communication Technology (ICACT), Bongpyeong, Korea,
19–22 February 2017.
7. Armknecht, F.; Karame, G.; Mandal, A.; Youssef, F.; Zenner, E. Ripple: Overview and Outlook. In Trust and
Trustworthy Computing; Conti, M., Schunter, M., Askoxylakis, I., Eds.; Springer International Publishing:
Cham, Switzerland, 2015; pp. 163–180.
8. Vasek, M.; Moore, T. There’s No Free Lunch, Even Using Bitcoin: Tracking the Popularity and Profits of
Virtual Currency Scams. In Proceedings of the International Conference on Financial Cryptography and
Data Security, San Juan, Puerto Rico, 26–30 January 2015; Springer: Berlin/Heidelberg, Gemany, 2015.
9. Zhang, J.; Nian, X.; Xin, H. A Secure System For Pervasive Social Network-based Healthcare. IEEE Access
2016, 4, 9239–9250. [CrossRef]
10. Singh, S.; Jeong, Y.-S.; Park, J.H. A survey on cloud computing security: Issues, threats, and solutions.
J. Netw. Comput. Appl. 2016, 75, 200–222. [CrossRef]
11. Kaskaloglu, K. Near zero Bitcoin transaction fees cannot last forever. In Proceedings of the International
Conference on Digital Security and Forensics (DigitalSec2014), The Society of Digital Information and
Wireless Communication, Ostrava, Czech Republic, 24–26 June 2014.
12. Ziegeldorf, J.H.; Matzutt, R.; Henze, M.; Grossmann, F.; Wehrle, K. Secure and anonymous decentralized
Bitcoin mixing. Future Gener. Comput. Syst. 2016. [CrossRef]
13. Aitzhan, N.Z.; Davor, S. Security and Privacy in Decentralized Energy Trading through Multi-signatures,
Blockchain and Anonymous Messaging Streams. IEEE Trans. Dependable Secur. Comput. 2016, 99. [CrossRef]
14. Heilman, E.; Foteini, B.; Sharon, G. Blindly signed contracts: Anonymous on-blockchain and off-blockchain
bitcoin transactions. In Proceedings of the International Conference on Financial Cryptography and Data
Security, Christ Church, Barbados, 22–26 February 2016; Springer: Berlin/Heidelberg, Gemany, 2016.
15. Natoli, C.; Gramoli, V. The blockchain anomaly. In Proceedings of the 2016 IEEE 15th International Symposium
on Network Computing and Applications (NCA), Cambridge, MA, USA, 31 October–2 November 2016.
16. Shi, N. A new proof-of-work mechanism for bitcoin. Financ. Innov. 2016, 2, 31. [CrossRef]
17. Swan, M. Blockchain: Blueprint for a New Economy; O’Reilly Media, Inc.: Sebastopol, CA, USA, 2015.
18. Tschorsch, F.; Scheuermann, B. Bitcoin and beyond: A technical survey on decentralized digital currencies.
IEEE Commun. Surv. Tutor. 2015, 18, 2084–2123. [CrossRef]
19. Wressnegger, C.; Freeman, K.; Yamaguchi, F.; Rieck, K. Automatically Inferring Malware Signatures for
Anti-Virus Assisted Attacks. In Proceedings of the 2017 ACM on Asia Conference on Computer and
Communications Security, Abu Dhabi, UAE, 02–06 April 2017.
20. Decker, C.; Roger, W. Information propagation in the bitcoin network. In Proceedings of the 2013 IEEE
Thirteenth International Conference on Peer-to-Peer Computing (P2P), Trento, Italy, 9–11 September 2013.
Symmetry 2017, 9, 164 13 of 13
21. Nakamoto, S. Bitcoin: A peer-to-peer electronic cash system. Available online: https://bitcoin.org/en/
bitcoin-paper (accessed on 29 June 2017).
22. Bozic, N.; Guy, P.; Stefano, S. A tutorial on blockchain and applications to secure network control-planes.
SCNS IEEE 2016. [CrossRef]
23. Bradbury, D. The problem with Bitcoin. Comput. Fraud Secur. 2013, 11, 5–8. [CrossRef]
24. Paul, G.; Sarkar, P.; Mukherjee, S. Towards a more democratic mining in bitcoins. In Proceedings of
the International Conference on Information Systems Security, Hyderabad, India, 16–20 December 2014;
Springer International Publishing: Cham, Switzerland, 2014.
25. Bamert, T.; Decker, C.; Wattenhofer, R.; Welten, S. BlueWallet: The Secure BitcoinWallet. In Security and
Trust Management; Mauw, S., Jensen, C., Eds.; Springer International Publishing: Cham, Switzerland, 2014;
pp. 65–80.
26. Anceaume, E.; Lajoie-Mazenc, T.; Ludinard, R.; Sericola, B. Safety analysis of Bitcoin improvement proposals.
In Proceedings of the 2016 IEEE 15th International Symposium on Network Computing and Applications
(NCA), Cambridge, MA, USA, 31 Octomber–2 November 2016.
27. Upadhyaya, R.; Jain, A. Cyber ethics and cybercrime: A deep dwelved study into legality, ransomware,
underground web and bitcoin wallet. In Proceedings of the 2016 International Conference on Computing,
Communication and Automation (ICCCA), Noida, India, 29–30 April 2016.
28. Haber, S.; Stornetta, W.S. How to time-stamp a digital document. In Proceedings of the Conference
on the Theory and Application of Cryptography, Sydney, NSW, Australia, 8–11 January 1990; Springer:
Berlin/Heidelberg, Gemany, 1990.
29. Eyal, I.; Emin, G.S. Majority is not enough: Bitcoin mining is vulnerable. In Proceedings of the International
Conference on Financial Cryptography and Data Security, Christ Church, Barbados, 3–7 March 2014; Springer:
Berlin/Heidelberg, Gemany, 2014.
30. Petersen, K.; Feldt, R.; Mujtaba, S.; Mattsson, M. Systematic Mapping Studies in Software Engineering.
In Proceedings of the 12th International Conference on Evaluation and Assessment in Software Engineering
(EASE), Bari, Italy, 26–27 June 2008.
31. Mann, C.; Loebenberger, D. Two-factor authentication for the Bitcoin protocol. In International Workshop on
Security and Trust Management; Springer International Publishing: Cham, Switzerland, 2015.
32. Yuan, Y.; Wang, F.-Y. Towards blockchain-based intelligent transportation systems. In Proceedings of the
2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC), Rio de Janeiro, Brazil,
1–4 November 2016.
33. Kogias, E.K.; Jovanovic, P.; Gailly, N.; Khoffi, I.; Gasser, L.; Ford, B. École Polytechnique Fédérale de
Lausanne (EPFL). Enhancing bitcoin security and performance with strong consistency via collective
signing. In Proceedings of the 25th USENIX Security Symposium (USENIX Security 16), Austin, TX, USA,
10–12 August 2016.
34. Vasek, M.; Thornton, M.; Moore, T. Empirical analysis of denial-of-service attacks in the Bitcoin ecosystem.
In Proceedings of the International Conference on Financial Cryptography and Data Security, Christ Church,
Barbados, 3–7 March 2014; Springer: Berlin/Heidelberg, Gemany, 2014.
35. Bastiaan, M. Preventing the 51%-Attack: A Stochastic Analysis of Two Phase Proof of Work in Bitcoin.
Available online: http://referaat.cs.utwente.nl/conference/22/paper/7473/preventingthe-51-attack-astochastic-analysis-of-two-phase-proof-of-work-in-bitcoin.pdf (accessed on 29 June 2017).
36. Kroll, J.A.; Davey, I.C.; Felten, E.W. The economics of Bitcoin mining, or Bitcoin in the presence of adversaries.
Proc. WEIS. 2013, 2013.
37. Eyal, I.; Gencer, A.E.; Sirer, E.G.; van Renesse, R. Bitcoin-ng: A scalable blockchain protocol. In Proceedings
of the 13th USENIX Symposium on Networked Systems Design and Implementation (NSDI 16), Santa Clara,
CA, USA, 2 February 2016.
38. Karame, G.O.; Elli, A.; Srdjan, C. Double-spending fast payments in bitcoin. In Proceedings of the 2012 ACM
Conference on Computer and Communications Security, Raleigh, CA, USA, 16–18 October 2012.
© 2017 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).